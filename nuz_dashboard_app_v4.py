# –ó–∞–ø—É—Å–∫: streamlit run nuz_dashboard_app_v4.py
from __future__ import annotations

import re
from dataclasses import dataclass
from enum import Enum
from io import BytesIO
from pathlib import Path
from typing import Any, Dict, List, Tuple
from uuid import uuid4
from collections import defaultdict

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.colors import qualitative as qcolors
from plotly.subplots import make_subplots
import streamlit as st
import requests

# A) –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ–ª–∞–≥–∏
APP_VERSION = "v24.56-heatmap-fix"
# –†–µ–∂–∏–º: —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª –∏–∑ —Ñ–∞–π–ª–∞, –±–µ–∑ —Ñ–æ—Ä–º—É–ª/–¥–æ—Å—á—ë—Ç–æ–≤
SIMPLE_MODE = True
# –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç–æ–ª—å–∫–æ –ø–æ –ù–Æ–ó
NUZ_ONLY = True

# A) –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≥–æ–¥–∞
YEAR_RE = re.compile(r"(?<!\d)(20\d{2})(?!\d)")

# –ü—Ä–∏–±–ª–∏–∂—ë–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è –∫–∞—Ä—Ç Plotly (—à–∏—Ä–æ—Ç–∞, –¥–æ–ª–≥–æ—Ç–∞)
REGION_COORDS: Dict[str, Tuple[float, float]] = {
    "–ú–æ—Å–∫–≤–∞": (55.7558, 37.6176),
    "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥": (59.9391, 30.3158),
    "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫": (55.0084, 82.9357),
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥": (56.8389, 60.6057),
    "–ö–∞–∑–∞–Ω—å": (55.7903, 49.1347),
    "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥": (56.3269, 44.0059),
    "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä": (45.0355, 38.9753),
    "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É": (47.2357, 39.7015),
    "–°–∞–º–∞—Ä–∞": (53.1959, 50.1008),
    "–ß–µ–ª—è–±–∏–Ω—Å–∫": (55.1644, 61.4368),
    "–£—Ñ–∞": (54.7388, 55.9721),
    "–í–æ—Ä–æ–Ω–µ–∂": (51.6608, 39.2003),
    "–ü–µ—Ä–º—å": (58.0105, 56.2502),
    "–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫": (56.0153, 92.8932),
    "–û–º—Å–∫": (54.9885, 73.3242),
    "–ò—Ä–∫—É—Ç—Å–∫": (52.2869, 104.3050),
    "–¢—é–º–µ–Ω—å": (57.1530, 65.5343),
    "–°–æ—á–∏": (43.6028, 39.7342),
    "–•–∞–±–∞—Ä–æ–≤—Å–∫": (48.4808, 135.0928),
    "–í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫": (43.1155, 131.8855),
}
REGION_COORDS_INDEX = {name.lower(): coords for name, coords in REGION_COORDS.items()}
REGION_GEOCODER_URL = "https://nominatim.openstreetmap.org/search"

def guess_year_from_filename(name: str) -> int | None:
    s = str(name).lower().replace("–≥.", " ").replace("–≥", " ")
    m = YEAR_RE.search(s)
    return int(m.group(1)) if m else None


def _resolve_region_coordinates_static(name: str) -> tuple[float, float] | None:
    if not name:
        return None
    raw = str(name).strip()
    candidates = {raw}
    if ":" in raw:
        candidates.add(raw.split(":", 1)[-1].strip())
    simplified = re.sub(r"\s*\(.*?\)", "", raw).strip()
    candidates.add(simplified)
    for candidate in candidates:
        key = candidate.lower()
        coords = REGION_COORDS_INDEX.get(key)
        if coords:
            return coords
        titled = candidate.title()
        coords = REGION_COORDS_INDEX.get(titled.lower())
        if coords:
            return coords
    return None


def _geocode_region(name: str) -> tuple[float, float] | None:
    if not name:
        return None
    try:
        headers = {"User-Agent": f"NUZ-Dashboard/{APP_VERSION}"}
        params = {"q": name, "format": "json", "limit": 1, "addressdetails": 0}
        resp = requests.get(REGION_GEOCODER_URL, params=params, headers=headers, timeout=8)
        if resp.status_code != 200:
            return None
        payload = resp.json()
        if not payload:
            return None
        lat = float(payload[0]["lat"])
        lon = float(payload[0]["lon"])
        return lat, lon
    except Exception:
        return None


def resolve_region_coordinates(name: str) -> tuple[float, float] | None:
    cached = _resolve_region_coordinates_static(name)
    if cached:
        return cached
    cache = st.session_state.setdefault("region_coords_dynamic", {})
    if name in cache:
        return cache[name]
    coords = _geocode_region(name)
    if coords:
        cache[name] = coords
        REGION_COORDS_INDEX[name.lower()] = coords
    return coords

# ------------------------- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã -------------------------
st.set_page_config(page_title=f"–ù–Æ–ó ‚Äî –î–∞—à–±–æ—Ä–¥ {APP_VERSION}", layout="wide", page_icon="üìä")
st.markdown("""
<style>
:root { --text-base: 15px; }
html, body, [class*="css"]  {
    font-size: var(--text-base);
    background: linear-gradient(180deg, #f5f7fb 0%, #eef1f6 35%, #e6ebf4 100%) !important;
    color: #0f172a;
}
section[data-testid="stSidebar"] {
    min-width: 330px !important;
    background: rgba(248, 250, 255, 0.82) !important;
    backdrop-filter: blur(18px);
    border-right: 1px solid rgba(255,255,255,0.6);
}
h1, h2, h3 { font-weight: 700; }
h2 { margin-top: .6rem; }
.block-container { padding-top: 1rem; padding-bottom: 3rem; }
[data-testid="stMetricValue"] { font-weight: 800; }
[data-testid="stMetricDelta"] { font-size: 0.95rem; }
.dataframe th, .dataframe td { padding: 6px 10px !important; }
[data-testid="stTable"] td, [data-testid="stTable"] th { padding: 8px 10px !important; }
code, .number-cell { font-variant-numeric: tabular-nums; }
.gtitle, .xtitle, .ytitle { font-weight: 700 !important; }
.badge { display:inline-block; padding:2px 8px; border-radius:10px; background:#EEF5FF; color:#1d4ed8; font-size:12px; margin-left:6px; }
.small { color:#6b7280; font-size:12px; }
div[data-testid="stMetric"] {
    background: rgba(255, 255, 255, 0.78);
    border-radius: 22px;
    padding: 1.2rem;
    margin-bottom: 1rem;
    border: 1px solid rgba(255, 255, 255, 0.6);
    box-shadow: 0 18px 40px rgba(15, 23, 42, 0.12);
    backdrop-filter: blur(20px);
}

div[data-testid="stDataFrame"] > div {
    border-radius: 18px;
    background: rgba(255,255,255,0.85);
    border: 1px solid rgba(226,232,240,0.7);
    box-shadow: 0 12px 30px rgba(15,23,42,0.08);
}

.stButton > button {
    border-radius: 14px;
    padding: 0.6rem 1.2rem;
    background: linear-gradient(135deg, #2563eb, #60a5fa);
    color: #fff;
    border: none;
    box-shadow: 0 10px 20px rgba(37, 99, 235, 0.25);
}

.stButton > button:hover {
    background: linear-gradient(135deg, #1d4ed8, #3b82f6);
}

.stRadio > div { gap: .6rem; }
.sidebar-title {
    font-size: 0.72rem;
    font-weight: 600;
    letter-spacing: 0.08em;
    text-transform: uppercase;
    color: #64748b;
    margin: 1.4rem 0 0.5rem;
}
.sidebar-divider {
    margin: 1.2rem 0;
    height: 1px;
    background: linear-gradient(90deg, rgba(148,163,184,0), rgba(148,163,184,0.45), rgba(148,163,184,0));
    border: none;
}
section[data-testid="stSidebar"] .stTextInput input,
section[data-testid="stSidebar"] .stSelectbox div[data-baseweb="select"] > div,
section[data-testid="stSidebar"] .stMultiSelect div[data-baseweb="select"] > div {
    border-radius: 16px;
    background: rgba(255,255,255,0.65);
    border: 1px solid rgba(148,163,184,0.35);
    backdrop-filter: blur(12px);
}
section[data-testid="stSidebar"] .stRadio > div > label {
    background: rgba(255,255,255,0.55);
    border-radius: 20px;
    padding: 0.25rem 0.9rem;
    border: 1px solid rgba(148,163,184,0.25);
    color: #334155;
    font-weight: 600;
}
section[data-testid="stSidebar"] .stRadio > div > label[data-baseweb="radio"]:has(input[checked]) {
    background: linear-gradient(135deg, #2563eb, #60a5fa);
    color: white;
    border-color: transparent;
}
.hero {
    display: flex;
    flex-direction: column;
    gap: 6px;
    padding: 18px 22px;
    border-radius: 26px;
    background: rgba(255, 255, 255, 0.75);
    box-shadow: 0 22px 50px rgba(15, 23, 42, 0.12);
    backdrop-filter: blur(30px);
    border: 1px solid rgba(148, 163, 184, 0.20);
    margin-bottom: 1.2rem;
}
.hero__title {
    font-size: 1.55rem;
    font-weight: 700;
    letter-spacing: -.01em;
    color: #0f172a;
}
.hero__meta {
    color: #64748b;
    font-size: 0.92rem;
}
.hero-pill {
    display: inline-flex;
    align-items: center;
    width: fit-content;
    padding: 0.25rem 0.8rem;
    border-radius: 999px;
    background: linear-gradient(120deg, rgba(37,99,235,0.12), rgba(59,130,246,0.18));
    color: #1d4ed8;
    font-weight: 600;
    font-size: 0.75rem;
    letter-spacing: 0.04em;
    text-transform: uppercase;
}
</style>
""", unsafe_allow_html=True)

# ------------------------- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ —Å–ª–æ–≤–∞—Ä–∏ ---------------------------
class Metrics(str, Enum):
    REVENUE = "–í—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—Ä—É–±)"
    LOAN_ISSUE = "–í—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ –ù–Æ–ó (—Ä—É–±)"
    BELOW_LOAN = "–¢–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –ù–Æ–ó (—Ä—É–±)"
    LOAN_VALUE_OF_SOLD = "–°—Å—É–¥–∞ –≤—ã—à–µ–¥—à–∏—Ö –∏–∑–¥–µ–ª–∏–π –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω –ù–Æ–ó (—Ä—É–±)"
    AUCTIONED_ITEMS_COUNT = "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—à–µ–¥—à–∏—Ö –∏–∑–¥–µ–ª–∏–π –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω –ù–Æ–ó"
    PENALTIES_RECEIVED = "–ü–æ–ª—É—á–µ–Ω–æ % –∏ –ø–µ–Ω–∏ –ù–Æ–ó (—Ä—É–±)"
    MARKUP_AMOUNT = "–ü–æ–ª—É—á–µ–Ω–æ –Ω–∞—Ü–µ–Ω–∫–∏ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—Ä—É–±)"
    PENALTIES_PLUS_MARKUP = "–ü–æ–ª—É—á–µ–Ω–æ % –∏ –ø–µ–Ω–∏ + –Ω–∞—Ü–µ–Ω–∫–∞ –Ω–∞ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂—É –ù–Æ–ó (—Ä—É–±)"
    LOAN_ISSUE_UNITS = "–í—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ –ù–Æ–ó (—à—Ç)"
    BELOW_LOAN_UNITS = "–¢–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –ù–Æ–ó (—à—Ç)"
    DEBT = "–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å (—Ä—É–±)"
    DEBT_UNITS = "–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—à—Ç)"
    DEBT_NO_SALE = "–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—Ä—É–±)"
    DEBT_NO_SALE_TOTAL = "–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ (—Ä—É–±)"
    DEBT_NO_SALE_YUZ = "–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Æ–ó (—Ä—É–±)"
    MARKUP_PCT = "–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏ –ù–Æ–ó"
    AVG_LOAN = "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –∑–∞–π–º–∞ –ù–Æ–ó (—Ä—É–±)"
    AVG_LOAN_TERM = "–°—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –∑–∞–π–º–∞ –ù–Æ–ó (–¥–Ω–µ–π)"
    ILLIQUID_BY_COUNT_PCT = "–î–æ–ª—è –Ω–µ–ª–∏–∫–≤–∏–¥–∞ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (%)"
    ILLIQUID_BY_VALUE_PCT = "–î–æ–ª—è –Ω–µ–ª–∏–∫–≤–∏–¥–∞ –æ—Ç –æ—Ü–µ–Ω–∫–∏ (%)"
    YIELD = "–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"
    ISSUE_SHARE = "–î–æ–ª—è –ù–Æ–ó –ø–æ –≤—ã–¥–∞—á–µ"
    DEBT_SHARE = "–î–æ–ª—è –ù–Æ–ó –ø–æ —Å—Å—É–¥–Ω–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏"
    RISK_SHARE = "–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %"
    CALC_MARKUP_PCT = "–†–∞—Å—á–µ—Ç–Ω–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥, %"

    # –ü–ª–∞–Ω—ã (–ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
    PLAN_ISSUE_PCT = "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –≤—ã–¥–∞–Ω–Ω—ã—Ö –∑–∞–π–º–æ–≤ –ù–Æ–ó"
    PLAN_PENALTIES_PCT = "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º % –∏ –ø–µ–Ω—è–º –ù–Æ–ó"
    PLAN_REVENUE_PCT = "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó"

    # –ö–ª–∏–µ–Ω—Ç—ã / —Ñ–∏–ª–∏–∞–ª—ã
    UNIQUE_CLIENTS = "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"
    NEW_UNIQUE_CLIENTS = "–ù–æ–≤—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"
    BRANCH_COUNT = "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤"
    BRANCH_NEW_COUNT = "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –ª–æ–º–±–∞—Ä–¥–æ–≤"
    BRANCH_CLOSED_COUNT = "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ª–æ–º–±–∞—Ä–¥–æ–≤"

    # –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ
    REDEEMED_ITEMS_COUNT = "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∫—É–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞–ª–æ–≥–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ –ù–Æ–ó (—à—Ç)"
    LOAN_REPAYMENT_SUM = "–°—É–º–º–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è —Å—É–º–º—ã –∑–∞–π–º–∞ –ù–Æ–ó (—Ä—É–±)"
    LOSS_BELOW_LOAN = "–£–±—ã—Ç–æ–∫ –æ—Ç —Ç–æ–≤–∞—Ä–∞ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –ù–Æ–ó (—Ä—É–±)"

    # –î–æ–ª–∏
    INTEREST_SHARE = "–î–æ–ª—è –ù–Æ–ó –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º % –∏ –ø–µ–Ω–∏"

    # –ù–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    REDEEMED_SUM = "–°—É–º–º–∞ –≤—ã–∫—É–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ –ù–Æ–ó (—Ä—É–±)"
    REDEEMED_SHARE_PCT = "–î–æ–ª—è –≤—ã–∫—É–ø–æ–≤ –∑–∞–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ –ù–Æ–ó (%)"

# ‚ö™Ô∏è –ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫: –±–µ—Ä—ë–º –∏–∑ —Ñ–∞–π–ª–∞ —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (–ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–º–µ–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏)
ACCEPTED_METRICS_CANONICAL = {
    Metrics.DEBT_NO_SALE.value,
    Metrics.LOAN_ISSUE.value,
    Metrics.PLAN_ISSUE_PCT.value,
    Metrics.LOAN_ISSUE_UNITS.value,
    Metrics.PENALTIES_RECEIVED.value,
    Metrics.PLAN_PENALTIES_PCT.value,
    Metrics.REVENUE.value,
    Metrics.PLAN_REVENUE_PCT.value,
    Metrics.MARKUP_AMOUNT.value,
    Metrics.PENALTIES_PLUS_MARKUP.value,
    Metrics.BRANCH_COUNT.value,
    Metrics.BRANCH_NEW_COUNT.value,
    Metrics.BRANCH_CLOSED_COUNT.value,
    Metrics.LOAN_VALUE_OF_SOLD.value,
    Metrics.AUCTIONED_ITEMS_COUNT.value,
    Metrics.DEBT_SHARE.value,
    Metrics.ISSUE_SHARE.value,
    Metrics.INTEREST_SHARE.value,
    Metrics.AVG_LOAN.value,
    Metrics.MARKUP_PCT.value,
    Metrics.REDEEMED_SUM.value,
    Metrics.REDEEMED_ITEMS_COUNT.value,
    Metrics.REDEEMED_SHARE_PCT.value,
    Metrics.AVG_LOAN_TERM.value,
    Metrics.LOAN_REPAYMENT_SUM.value,
    Metrics.BELOW_LOAN_UNITS.value,
    Metrics.BELOW_LOAN.value,
    Metrics.LOSS_BELOW_LOAN.value,
    Metrics.DEBT_UNITS.value,
    Metrics.ILLIQUID_BY_COUNT_PCT.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
    Metrics.RISK_SHARE.value,
    Metrics.YIELD.value,
}
ACCEPTED_METRICS_CANONICAL |= {Metrics.DEBT.value}


def _normalize_metric_label(raw: str) -> str:
    if raw is None:
        return ""
    s = str(raw).lower()
    s = s.replace("—ë", "–µ")
    s = re.sub(r"[\"'¬´¬ª]", " ", s)
    s = re.sub(r"\s+", " ", s)
    return s.strip(" :;.")


METRIC_ALIASES_RAW: Dict[str, List[str]] = {
    Metrics.REVENUE.value: [
        "–≤—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.LOAN_ISSUE.value: [
        "–≤—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.LOAN_ISSUE_UNITS.value: [
        "–≤—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ –Ω—é–∑ (—à—Ç)",
    ],
    Metrics.PLAN_ISSUE_PCT.value: [
        "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –≤—ã–¥–∞–Ω–Ω—ã—Ö –∑–∞–π–º–æ–≤ –Ω—é–∑",
    ],
    Metrics.PENALTIES_RECEIVED.value: [
        "–ø–æ–ª—É—á–µ–Ω–æ % –∏ –ø–µ–Ω–∏ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.PLAN_PENALTIES_PCT.value: [
        "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º % –∏ –ø–µ–Ω—è–º –Ω—é–∑",
    ],
    Metrics.PLAN_REVENUE_PCT.value: [
        "% –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω—é–∑",
    ],
    Metrics.MARKUP_AMOUNT.value: [
        "–ø–æ–ª—É—á–µ–Ω–æ –Ω–∞—Ü–µ–Ω–∫–∏ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.PENALTIES_PLUS_MARKUP.value: [
        "–ø–æ–ª—É—á–µ–Ω–æ % –∏ –ø–µ–Ω–∏ + –Ω–∞—Ü–µ–Ω–∫–∞ –Ω–∞ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂—É –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.MARKUP_PCT.value: [
        "–ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏ –Ω—é–∑",
    ],
    Metrics.AVG_LOAN.value: [
        "—Å—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –∑–∞–π–º–∞ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.AVG_LOAN_TERM.value: [
        "—Å—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –∑–∞–π–º–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ –Ω—é–∑ (–¥–Ω–µ–π)",
        "—Å—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –∑–∞–π–º–∞ –∑–∞ –ø–µ—Ä–æ–¥ –Ω—é–∑ (–¥–Ω–µ–π)",
    ],
    Metrics.LOAN_VALUE_OF_SOLD.value: [
        "—Å—Å—É–¥–∞ –≤—ã—à–µ–¥—à–∏—Ö –∏–∑–¥–µ–ª–∏–π –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω –Ω—é–∑ (—Ä—É–±)",
        "—Å—Å—É–¥–∞  –≤—ã—à–µ–¥—à–∏—Ö –∏–∑–¥–µ–ª–∏–π –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.AUCTIONED_ITEMS_COUNT.value: [
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—à–µ–¥—à–∏—Ö –∏–∑–¥–µ–ª–∏–π –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω –Ω—é–∑",
    ],
    Metrics.DEBT_NO_SALE.value: [
        "—Å—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.DEBT_UNITS.value: [
        "—Å—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω—é–∑ (—à—Ç)",
    ],
    Metrics.BELOW_LOAN.value: [
        "—Ç–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑ (—Ä—É–±)",
        "—Ç–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑  (—Ä—É–±)",
    ],
    Metrics.BELOW_LOAN_UNITS.value: [
        "—Ç–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑ (—à—Ç)",
        "—Ç–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑  (—à—Ç)",
    ],
    Metrics.LOSS_BELOW_LOAN.value: [
        "—É–±—ã—Ç–æ–∫ –æ—Ç —Ç–æ–≤–∞—Ä–∞ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.REDEEMED_ITEMS_COUNT.value: [
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∫—É–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞–ª–æ–≥–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ –Ω—é–∑ (—à—Ç)",
        "–≤—ã–∫—É–ø –∑–∞–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω—é–∑",
    ],
    Metrics.REDEEMED_SUM.value: [
        "—Å—É–º–º–∞ –≤—ã–∫—É–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.REDEEMED_SHARE_PCT.value: [
        "–¥–æ–ª—è –≤—ã–∫—É–ø–æ–≤ –∑–∞–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ –Ω—é–∑ (%)",
    ],
    Metrics.LOAN_REPAYMENT_SUM.value: [
        "—Å—É–º–º–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω—é–∑ (—Ä—É–±)",
    ],
    Metrics.ISSUE_SHARE.value: [
        "–¥–æ–ª—è –Ω—é–∑ –ø–æ –≤—ã–¥–∞—á–µ",
    ],
    Metrics.INTEREST_SHARE.value: [
        "–¥–æ–ª—è –Ω—é–∑ –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º % –∏ –ø–µ–Ω–∏",
    ],
    Metrics.DEBT_SHARE.value: [
        "–¥–æ–ª—è –Ω—é–∑ –ø–æ —Å—Å—É–¥–Ω–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏",
    ],
    Metrics.UNIQUE_CLIENTS.value: [
        "—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã",
    ],
    Metrics.NEW_UNIQUE_CLIENTS.value: [
        "–Ω–æ–≤—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã",
    ],
    Metrics.BRANCH_COUNT.value: [
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤",
    ],
    Metrics.BRANCH_NEW_COUNT.value: [
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –ª–æ–º–±–∞—Ä–¥–æ–≤",
    ],
    Metrics.BRANCH_CLOSED_COUNT.value: [
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ª–æ–º–±–∞—Ä–¥–æ–≤",
    ],
    Metrics.ILLIQUID_BY_COUNT_PCT.value: [
        "–¥–æ–ª—è –Ω–µ–ª–∏–∫–≤–∏–¥–∞ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (%)",
    ],
    Metrics.ILLIQUID_BY_VALUE_PCT.value: [
        "–¥–æ–ª—è –Ω–µ–ª–∏–∫–≤–∏–¥–∞ –æ—Ç –æ—Ü–µ–Ω–∫–∏ (%)",
    ],
    Metrics.YIELD.value: [
        "–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å",
    ],
}

METRIC_ALIAS_MAP: Dict[str, str] = {}
for canonical, variants in METRIC_ALIASES_RAW.items():
    for candidate in [canonical, *variants]:
        key = _normalize_metric_label(candidate)
        if not key:
            continue
        existing = METRIC_ALIAS_MAP.get(key)
        if existing and existing != canonical:
            continue
        METRIC_ALIAS_MAP[key] = canonical

METRIC_CATEGORY_OVERRIDES: Dict[str, str] = {
    Metrics.YIELD.value: "–ù–Æ–ó",
    Metrics.ILLIQUID_BY_COUNT_PCT.value: "–ù–Æ–ó",
    Metrics.ILLIQUID_BY_VALUE_PCT.value: "–ù–Æ–ó",
    Metrics.BRANCH_COUNT.value: "–ù–Æ–ó",
    Metrics.BRANCH_NEW_COUNT.value: "–ù–Æ–ó",
    Metrics.BRANCH_CLOSED_COUNT.value: "–ù–Æ–ó",
    Metrics.UNIQUE_CLIENTS.value: "–ù–Æ–ó",
    Metrics.NEW_UNIQUE_CLIENTS.value: "–ù–Æ–ó",
}

HIDDEN_METRICS = {
    Metrics.DEBT.value,
    Metrics.DEBT_NO_SALE.value,
    Metrics.DEBT_UNITS.value,
}


def append_risk_share_metric(df: pd.DataFrame) -> pd.DataFrame:
    needed = {Metrics.BELOW_LOAN.value, Metrics.REVENUE.value, Metrics.DEBT_NO_SALE.value}
    present = set(df["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
    if not (needed & present):
        return df

    cols = ["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–¥", "–ú–µ—Å—è—Ü", "–ì–æ–¥"]
    subset = df[df["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].isin(needed)].copy()
    if subset.empty:
        return df
    subset["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(subset["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
    pivot = subset.pivot_table(index=cols, columns="–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="sum")
    if pivot.empty:
        return df

    derived_frames: List[pd.DataFrame] = []

    revenue = pivot.get(Metrics.REVENUE.value)
    below = pivot.get(Metrics.BELOW_LOAN.value)
    if revenue is not None and below is not None:
        denominator = revenue.replace(0, np.nan)
        ratio = (below / denominator) * 100.0
        ratio = ratio.replace([np.inf, -np.inf], np.nan).dropna()
        if not ratio.empty:
            risk_df = ratio.reset_index().rename(columns={0: "–ó–Ω–∞—á–µ–Ω–∏–µ"})
            risk_df["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] = Metrics.RISK_SHARE.value
            derived_frames.append(risk_df)

    if not derived_frames:
        return df

    derived = pd.concat(derived_frames, ignore_index=True)
    derived["–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞"] = "DERIVED"
    order = ["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–¥", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ú–µ—Å—è—Ü", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ì–æ–¥", "–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞"]
    for col in order:
        if col not in derived:
            derived[col] = pd.NA

    key_cols = ["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–¥", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ú–µ—Å—è—Ü", "–ì–æ–¥"]
    existing_keys = set(tuple(row) for row in df[df["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == Metrics.RISK_SHARE.value][key_cols].itertuples(index=False, name=None))
    derived = derived[~derived[key_cols].apply(tuple, axis=1).isin(existing_keys)]
    return pd.concat([df, derived[order]], ignore_index=True)


ORDER = ["–Ø–Ω–≤–∞—Ä—å","–§–µ–≤—Ä–∞–ª—å","–ú–∞—Ä—Ç","–ê–ø—Ä–µ–ª—å","–ú–∞–π","–ò—é–Ω—å","–ò—é–ª—å","–ê–≤–≥—É—Å—Ç","–°–µ–Ω—Ç—è–±—Ä—å","–û–∫—Ç—è–±—Ä—å","–ù–æ—è–±—Ä—å","–î–µ–∫–∞–±—Ä—å"]
ORDER_WITH_TOTAL = ORDER + ["–ò—Ç–æ–≥–æ"]

NUZ_ACTIVITY_METRICS = {
    Metrics.LOAN_ISSUE.value,
    Metrics.LOAN_ISSUE_UNITS.value,
    Metrics.PENALTIES_RECEIVED.value,
    Metrics.REVENUE.value,
    Metrics.MARKUP_AMOUNT.value,
    Metrics.PENALTIES_PLUS_MARKUP.value,
    Metrics.LOAN_VALUE_OF_SOLD.value,
    Metrics.AUCTIONED_ITEMS_COUNT.value,
    Metrics.AVG_LOAN.value,
    Metrics.MARKUP_PCT.value,
    Metrics.REDEEMED_SUM.value,
    Metrics.REDEEMED_ITEMS_COUNT.value,
    Metrics.AVG_LOAN_TERM.value,
    Metrics.LOAN_REPAYMENT_SUM.value,
    Metrics.BELOW_LOAN_UNITS.value,
    Metrics.BELOW_LOAN.value,
    Metrics.LOSS_BELOW_LOAN.value,
    Metrics.ILLIQUID_BY_COUNT_PCT.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
    Metrics.YIELD.value,
    Metrics.ISSUE_SHARE.value,
    Metrics.INTEREST_SHARE.value,
    Metrics.PLAN_ISSUE_PCT.value,
    Metrics.PLAN_PENALTIES_PCT.value,
    Metrics.PLAN_REVENUE_PCT.value,
}

FORECAST_METRICS = [
    Metrics.REVENUE.value,
    Metrics.LOAN_ISSUE.value,
    Metrics.PENALTIES_RECEIVED.value,
    Metrics.MARKUP_PCT.value,
    Metrics.PLAN_ISSUE_PCT.value,
    Metrics.PLAN_PENALTIES_PCT.value,
    Metrics.PLAN_REVENUE_PCT.value,
]

TAB_METRIC_SETS: Dict[str, List[str]] = {
    "issuance": [
        Metrics.LOAN_ISSUE.value,
        Metrics.LOAN_ISSUE_UNITS.value,
        Metrics.AVG_LOAN.value,
        Metrics.PLAN_ISSUE_PCT.value,
        Metrics.REDEEMED_ITEMS_COUNT.value,
        Metrics.REDEEMED_SUM.value,
    ],
    "interest": [
        Metrics.PENALTIES_RECEIVED.value,
        Metrics.YIELD.value,
        Metrics.LOAN_REPAYMENT_SUM.value,
        Metrics.PLAN_PENALTIES_PCT.value,
        Metrics.REDEEMED_SHARE_PCT.value,
    ],
    "sales": [
        Metrics.REVENUE.value,
        Metrics.MARKUP_PCT.value,
        Metrics.PENALTIES_PLUS_MARKUP.value,
        Metrics.BELOW_LOAN.value,
        Metrics.RISK_SHARE.value,
        Metrics.PLAN_REVENUE_PCT.value,
    ],
    "risk": [
        Metrics.RISK_SHARE.value,
        Metrics.ILLIQUID_BY_VALUE_PCT.value,
        Metrics.ILLIQUID_BY_COUNT_PCT.value,
        Metrics.BELOW_LOAN.value,
    ],
}

def _month_sort_key(m: str) -> int:
    return ORDER.index(m) if m in ORDER else len(ORDER) + 1

@st.cache_data
def get_monthly_totals_from_file(df_raw: pd.DataFrame, regions: Tuple[str, ...], metric: str) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–º–µ—Å—è—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ¬ª –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É."""
    base = df_raw[
        df_raw["–†–µ–≥–∏–æ–Ω"].isin(regions) &
        (df_raw["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric) &
        (df_raw["–ú–µ—Å—è—Ü"].astype(str) != "–ò—Ç–æ–≥–æ") &
        df_raw["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].str.contains(r"^\s*–∏—Ç–æ–≥–æ\b", case=False, na=False)
    ].copy()
    if not base.empty:
        priority_map = {"RECALC_TOTAL": 0, "TOTALS_FILE": 1}
        src = base.get("–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞", pd.Series(index=base.index, dtype=object))
        prio = src.map(priority_map).fillna(2).astype(int)
        base["__prio__"] = prio

        def _select_best(g: pd.DataFrame) -> pd.Series:
            priority_zero = g[g["__prio__"] == 0]
            if not priority_zero.empty:
                return priority_zero.iloc[0]
            priority_one = g[g["__prio__"] == 1]
            if not priority_one.empty:
                return priority_one.iloc[0]
            result = g.iloc[0].copy()
            numeric_values = pd.to_numeric(g["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
            result["–ó–Ω–∞—á–µ–Ω–∏–µ"] = float(numeric_values.sum(skipna=True))
            return result

        return (base.groupby(["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"], observed=True)
                    .apply(_select_best)
                    .reset_index(drop=True)[["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü", "–ó–Ω–∞—á–µ–Ω–∏–µ"]])

    # Fallback: —Å—É–º–º–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º
    subset = df_raw[
        df_raw["–†–µ–≥–∏–æ–Ω"].isin(regions) &
        (df_raw["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric) &
        (df_raw["–ú–µ—Å—è—Ü"].astype(str) != "–ò—Ç–æ–≥–æ")
    ].copy()
    if subset.empty:
        return pd.DataFrame()

    agg_type = aggregation_rule(metric)

    def _aggregate_values(values: pd.Series) -> float:
        numeric = pd.to_numeric(values, errors="coerce")
        if agg_type == "mean":
            return float(numeric.mean(skipna=True))
        # –¥–ª—è —Å—É–º–º –∏ —Å–Ω–∏–º–∫–æ–≤ –±–µ—Ä—ë–º —Å—É–º–º—É –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º
        return float(numeric.sum(skipna=True))

    aggregated = (
        subset.groupby(["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        .apply(_aggregate_values)
        .reset_index()
    )
    return aggregated

@st.cache_data(show_spinner=False, max_entries=256)
def month_series_from_file(df_all, regions, metric, months):
    months_tuple = tuple(months)
    dfm = get_monthly_totals_from_file(df_all, tuple(regions), metric)
    if dfm.empty:
        return pd.Series(dtype=float)
    s = (dfm[dfm["–ú–µ—Å—è—Ü"].astype(str).isin(months_tuple)]
            .groupby("–ú–µ—Å—è—Ü", observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum())
    # —Å—Ç—Ä–æ–≥–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—é
    s = s.reindex([m for m in months_tuple if m in s.index])
    return s

@st.cache_data
def sorted_months_safe(_values) -> list[str]:
    """–ë–µ–∑ –∫–µ—à–∞: –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–∞–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–∞—à–µ–º—É ORDER."""
    if _values is None:
        return []
    s = pd.Series(_values)
    if isinstance(s.dtype, pd.CategoricalDtype):
        s = s.astype(str)
    seq = [str(x) for x in s.dropna().astype(str)]
    seq = [m for m in seq if m in ORDER]
    seq = list(dict.fromkeys(seq))
    return sorted(seq, key=_month_sort_key)

# --- –ê–≥—Ä–µ–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª
# SUM: –ø–æ—Ç–æ–∫–æ–≤—ã–µ —Å—É–º–º—ã –∑–∞ –º–µ—Å—è—Ü (—Ä—É–±/—à—Ç) ‚Äî —Å–∫–ª–∞–¥—ã–≤–∞–µ–º.
AGG_SUM = {
    Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value, Metrics.PENALTIES_RECEIVED.value,
    Metrics.MARKUP_AMOUNT.value, Metrics.PENALTIES_PLUS_MARKUP.value,
    Metrics.LOAN_ISSUE_UNITS.value, Metrics.BELOW_LOAN.value, Metrics.BELOW_LOAN_UNITS.value,
    Metrics.LOAN_VALUE_OF_SOLD.value, Metrics.AUCTIONED_ITEMS_COUNT.value,
    Metrics.REDEEMED_ITEMS_COUNT.value, Metrics.REDEEMED_SUM.value,
    Metrics.LOAN_REPAYMENT_SUM.value, Metrics.LOSS_BELOW_LOAN.value,
    Metrics.BRANCH_NEW_COUNT.value, Metrics.BRANCH_CLOSED_COUNT.value,
    Metrics.UNIQUE_CLIENTS.value, Metrics.NEW_UNIQUE_CLIENTS.value,
}

# MEAN: –ø—Ä–æ—Ü–µ–Ω—Ç—ã/–¥–æ–ª–∏ –∏ —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ ‚Äî —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º.
AGG_MEAN = {
    Metrics.MARKUP_PCT.value, Metrics.YIELD.value,
    Metrics.ILLIQUID_BY_COUNT_PCT.value, Metrics.ILLIQUID_BY_VALUE_PCT.value,
    Metrics.ISSUE_SHARE.value, Metrics.DEBT_SHARE.value, Metrics.INTEREST_SHARE.value,
    Metrics.PLAN_ISSUE_PCT.value, Metrics.PLAN_PENALTIES_PCT.value, Metrics.PLAN_REVENUE_PCT.value,
    Metrics.AVG_LOAN.value,      # –µ—Å–ª–∏ –±–µ—Ä–µ—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞ –∫–∞–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª
    Metrics.AVG_LOAN_TERM.value, # ‚¨ÖÔ∏è –í–ê–ñ–ù–û: —Å—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –º–µ—Å—è—Ü–∞–º
    Metrics.REDEEMED_SHARE_PCT.value,
}

# LAST (—Å–Ω–∏–º–æ–∫ –Ω–∞ –∫–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞) ‚Äî –±–µ—Ä—ë–º –ü–û–°–õ–ï–î–ù–ò–ô –º–µ—Å—è—Ü –ø–µ—Ä–∏–æ–¥–∞.
AGG_LAST = {
    Metrics.DEBT.value,
    Metrics.DEBT_NO_SALE.value,
    Metrics.DEBT_UNITS.value,
    Metrics.BRANCH_COUNT.value,  # ¬´–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤¬ª ‚Äî —Å–Ω–∏–º–æ–∫
}

# (–æ—Å—Ç–∞–≤–∏–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)
METRICS_SUM  = AGG_SUM.copy()
METRICS_MEAN = AGG_MEAN.copy()
METRICS_LAST = AGG_LAST.copy()

def aggregation_rule(metric: str) -> str:
    if metric in AGG_SUM:  return "sum"
    if metric in AGG_MEAN: return "mean"
    if metric in AGG_LAST: return "last"
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø—Ä–æ—Ü–µ–Ω—Ç—ã ‚Äî mean, –¥–µ–Ω—å–≥–∏/—à—Ç ‚Äî sum
    return "mean" if is_percent_metric(metric) else "sum"

@st.cache_data(show_spinner=False, max_entries=512)
def period_value_from_itogo(df_all: pd.DataFrame, regions: list[str], metric: str, months: list[str]) -> float | None:
    months_tuple = tuple(months)
    s = month_series_from_file(df_all, regions, metric, months_tuple)
    if s.empty:
        return None
    rule = aggregation_rule(metric)
    vals = pd.to_numeric(s, errors="coerce")
    result: float | None = None
    if rule == "sum":
        result = float(vals.sum())
    elif rule == "mean":
        result = float(vals.mean())
    elif rule == "last":
        # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞
        last_months = sorted_months_safe(vals.dropna().index)
        if not last_months:
            result = None
        else:
            v = vals.get(last_months[-1], np.nan)
            result = float(v) if pd.notna(v) else None
    else:
        result = float(vals.mean())
    return _maybe_scale_percent(metric, result)

@st.cache_data(show_spinner=False, max_entries=1024)
def period_value_from_itogo_for_region(df_all: pd.DataFrame, region: str, metric: str,
                                       months: list[str], *, snapshots_mode: str = "last") -> float | None:
    months_tuple = tuple(months)
    # –ë–µ—Ä—ë–º —Ä–æ–≤–Ω–æ —Å—Ç—Ä–æ–∫–∏ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
    dfm = get_monthly_totals_from_file(df_all, (region,), metric)
    if dfm.empty:
        return None
    part = dfm[dfm["–ú–µ—Å—è—Ü"].astype(str).isin(months_tuple)]
    if part.empty:
        return None

    vals = pd.to_numeric(part["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").dropna()
    if vals.empty:
        return None

    rule = aggregation_rule(metric)

    if rule == "sum":
        return float(vals.sum())
    if rule == "mean":
        return float(vals.mean())

    # rule == "last" ‚Üí —Å–Ω–∏–º–æ–∫: —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Å–≤–æ–¥–∫–∏ –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ, –µ—Å–ª–∏ —Ç–∞–∫ –ø–æ–ø—Ä–æ—Å–∏–ª–∏
    if rule == "last":
        if snapshots_mode == "mean":
            return float(vals.mean())
        else:
            # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—é
            part = part.copy()
            part["–ú–µ—Å—è—Ü"] = pd.Categorical(part["–ú–µ—Å—è—Ü"].astype(str), categories=ORDER, ordered=True)
            part = part.sort_values("–ú–µ—Å—è—Ü")
            return float(pd.to_numeric(part["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").iloc[-1])

    # –¥–µ—Ñ–æ–ª—Ç
    return float(vals.mean())


@st.cache_data(show_spinner=False, max_entries=256)
def period_values_by_region_from_itogo(df_all, regions, metric, months) -> dict[str, float]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {–†–µ–≥–∏–æ–Ω: –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞ –ø–µ—Ä–∏–æ–¥} —Å—Ç—Ä–æ–≥–æ –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª.
    –°—É–º–º–∞/—Å—Ä–µ–¥–Ω–µ–µ/–ø–æ—Å–ª–µ–¥–Ω–∏–π ‚Äî –∫–∞–∫ –∑–∞–¥–∞–Ω–æ aggregation_rule(metric).
    """
    months_tuple = tuple(months)
    dfm = get_monthly_totals_from_file(df_all, tuple(regions), metric)
    if dfm.empty:
        return {}

    dfm = dfm[dfm["–ú–µ—Å—è—Ü"].astype(str).isin(months_tuple)].copy()
    if dfm.empty:
        return {}

    rule = aggregation_rule(metric)
    out = {}
    for reg, t in dfm.groupby("–†–µ–≥–∏–æ–Ω"):
        # Ensure months are sorted before taking the last value for 'last' rule
        t = t.copy()
        t['–ú–µ—Å—è—Ü'] = pd.Categorical(t['–ú–µ—Å—è—Ü'], categories=ORDER, ordered=True)
        t = t.sort_values("–ú–µ—Å—è—Ü")
        vals = pd.to_numeric(t["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").dropna()
        if vals.empty:
            continue

        if rule == "sum":
            result = float(vals.sum())
        elif rule == "mean":
            result = float(vals.mean())
        elif rule == "last":
            result = float(vals.iloc[-1])
        else:
            result = float(vals.mean())  # –¥–µ—Ñ–æ–ª—Ç
        out[str(reg)] = _maybe_scale_percent(metric, result)
    return out


MANDATORY_COLUMNS = {"–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ú–µ—Å—è—Ü", "–ó–Ω–∞—á–µ–Ω–∏–µ"}
COHORT_REQUIRED_METRICS = {Metrics.UNIQUE_CLIENTS.value, Metrics.NEW_UNIQUE_CLIENTS.value}
RISK_REQUIRED_METRICS = {Metrics.RISK_SHARE.value, Metrics.ILLIQUID_BY_VALUE_PCT.value}
SALES_REQUIRED_METRICS = {Metrics.REVENUE.value, Metrics.MARKUP_PCT.value}
TAB_METRIC_DEPENDENCIES: Dict[str, set[str]] = {
    "–†–∏—Å–∫–∏": RISK_REQUIRED_METRICS,
    "–ö–æ–≥–æ—Ä—Ç—ã": COHORT_REQUIRED_METRICS,
    "–†–∞—Å–ø—Ä–æ–¥–∞–∂–∞": SALES_REQUIRED_METRICS,
}


def compute_health_report(df_current: pd.DataFrame, months_range: List[str]) -> Dict[str, Any]:
    report: Dict[str, Any] = {}
    report["missing_columns"] = [col for col in MANDATORY_COLUMNS if col not in df_current.columns]
    available_metrics = set(df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
    report["missing_key_metrics"] = [m for m in KEY_DECISION_METRICS if m not in available_metrics]
    report["tab_dependencies"] = {
        tab: sorted(metric for metric in metrics if metric not in available_metrics)
        for tab, metrics in TAB_METRIC_DEPENDENCIES.items()
    }
    present_months = sorted_months_safe(df_current.get("–ú–µ—Å—è—Ü"))
    report["missing_months"] = [m for m in months_range if m not in present_months]
    regions = sorted(map(str, df_current.get("–†–µ–≥–∏–æ–Ω", pd.Series(dtype=str)).dropna().unique()))
    missing_coords = [reg for reg in regions if _resolve_region_coordinates_static(reg) is None]
    report["missing_coordinates"] = missing_coords
    report["total_rows"] = int(len(df_current))
    return report


def render_health_check(ctx: PageContext) -> None:
    report = compute_health_report(ctx.df_current, ctx.months_range)
    issues_present = bool(
        report["missing_columns"] or report["missing_key_metrics"] or
        any(report["tab_dependencies"].values()) or report["missing_months"] or report["missing_coordinates"]
    )
    with st.expander("ü©∫ Health-check –¥–∞–Ω–Ω—ã—Ö", expanded=issues_present):
        missing_cols = report["missing_columns"]
        if missing_cols:
            st.warning("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: " + ", ".join(missing_cols))
        else:
            st.markdown("- **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:** ‚úÖ –≤—Å—ë –Ω–∞ –º–µ—Å—Ç–µ")

        if report["missing_key_metrics"]:
            st.warning("–ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏: " + ", ".join(report["missing_key_metrics"]))
        else:
            st.markdown("- **–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:** ‚úÖ –≤ –Ω–∞–ª–∏—á–∏–∏")

        tab_messages = []
        for tab, missing in report["tab_dependencies"].items():
            if missing:
                tab_messages.append(f"{tab}: {', '.join(missing)}")
        if tab_messages:
            st.markdown("- **–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–ª—è –≤–∫–ª–∞–¥–æ–∫:**\n  - " + "\n  - ".join(tab_messages))
        else:
            st.markdown("- **–í–∫–ª–∞–¥–∫–∏:** ‚úÖ –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å")

        if report["missing_months"]:
            st.markdown("- **–ú–µ—Å—è—Ü—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö:** " + ", ".join(report["missing_months"]))
        else:
            st.markdown("- **–ú–µ—Å—è—Ü—ã:** ‚úÖ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")

        if report["missing_coordinates"]:
            st.markdown("- **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ä–µ–≥–∏–æ–Ω–æ–≤:** —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –¥–ª—è: " + ", ".join(report["missing_coordinates"]))
        else:
            st.markdown("- **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ä–µ–≥–∏–æ–Ω–æ–≤:** ‚úÖ –≤—Å–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã")

        st.caption(f"–°—Ç—Ä–æ–∫ –≤ —Ç–µ–∫—É—â–µ–º –Ω–∞–±–æ—Ä–µ: {report['total_rows']:,}".replace(",", " "))


def render_faq_block() -> None:
    with st.expander("üìö FAQ / –§–æ—Ä–º—É–ª—ã", expanded=False):
        st.markdown(
            """
            - **–í—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—Ä—É–±)** ‚Äî –ø—Ä—è–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Å—É–º–º–∞ –¥–ª—è –≤—Å–µ—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤.
            - **–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏ –ù–Æ–ó** ‚Äî `–ü–æ–ª—É—á–µ–Ω–æ –Ω–∞—Ü–µ–Ω–∫–∏ / –í—ã—Ä—É—á–∫–∞ √ó 100`; –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ü–µ–Ω–∏—Ç—å –º–∞—Ä–∂—É —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏.
            - **–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %** ‚Äî `–¢–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ / –í—ã—Ä—É—á–∫–∞ √ó 100`; —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ –¥–æ–ª–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂.
            - **–ù–æ–≤—ã–µ / –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã** ‚Äî —Å—É–º–º–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ñ–∏–ª–∏–∞–ª–∞–º; –Ω—É–∂–Ω—ã –¥–ª—è –≤–∫–ª–∞–¥–∫–∏ ¬´–ö–æ–≥–æ—Ä—Ç—ã¬ª –∏ AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏.
            - **–õ–∏–¥–µ—Ä—ã –∏ —Å–∏–≥–Ω–∞–ª—ã** –æ–ø–∏—Ä–∞—é—Ç—Å—è –Ω–∞ –ø–æ—Ä–æ–≥–∏ –∏–∑ —Å–∞–π–¥–±–∞—Ä–∞: –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –Ω–∞—Ü–µ–Ω–∫—É, –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫ –∏ –ª–∏–º–∏—Ç —É–±—ã—Ç–∫–∞.
            - –ï—Å–ª–∏ –≤–∫–ª–∞–¥–∫–∞ –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–¥–µ–ª Health-check: –æ–Ω –ø–æ–¥—Å–∫–∞–∂–µ—Ç, –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã –∏–ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ–±–∞–≤–∏—Ç—å.
            """
        )


def _top_regions_by_metric(df_source: pd.DataFrame, regions_all: List[str], months_range: List[str], metric: str, *, top_n: int = 5, ascending: bool = False) -> List[str]:
    values = period_values_by_region_from_itogo(df_source, regions_all, metric, months_range)
    if not values:
        return []
    filtered = [(reg, val) for reg, val in values.items() if val is not None and not pd.isna(val)]
    if not filtered:
        return []
    sorted_items = sorted(filtered, key=lambda kv: kv[1], reverse=not ascending)
    return [reg for reg, _ in sorted_items[:top_n]]

METRICS_BIGGER_IS_BETTER = {
    Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value, Metrics.MARKUP_PCT.value,
    Metrics.YIELD.value, Metrics.PENALTIES_RECEIVED.value, Metrics.MARKUP_AMOUNT.value,
    Metrics.PENALTIES_PLUS_MARKUP.value, Metrics.AVG_LOAN_TERM.value
}
METRICS_SMALLER_IS_BETTER = {
    Metrics.BELOW_LOAN.value, Metrics.RISK_SHARE.value,
    Metrics.ILLIQUID_BY_COUNT_PCT.value, Metrics.ILLIQUID_BY_VALUE_PCT.value
}

METRIC_HELP: Dict[str, str] = {
    Metrics.MARKUP_PCT.value: "–ù–∞—Ü–µ–Ω–∫–∞ –Ω–∞ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂—É: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—É–º–º—ã –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –Ω–∞—Ü–µ–Ω–∫–∏ –∫ –≤—ã—Ä—É—á–∫–µ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ (–ü–æ–ª—É—á–µ–Ω–æ –Ω–∞—Ü–µ–Ω–∫–∏ / –í—ã—Ä—É—á–∫–∞ √ó 100). –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∏—Ç–æ–≥–æ–≤–∞—è —Ü–µ–Ω–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –æ—Ü–µ–Ω–æ—á–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å; –≤—ã—Å–æ–∫–∏–π % –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –∑–∞—â–∏—â–∞–µ—Ç –º–∞—Ä–∂—É.",
    Metrics.RISK_SHARE.value: "–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞: –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ '–¢–æ–≤–∞—Ä –ø—Ä–æ–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –ù–Æ–ó (—Ä—É–±)' / '–í—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó (—Ä—É–±)' √ó 100. –†–æ—Å—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–æ—Å—Ç —É–±—ã—Ç–æ—á–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π –∏ –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω —Å —Ä–∏—Å–∫–æ–º.",
    Metrics.YIELD.value: "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã–¥–∞—á: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –∏ –ø–µ–Ω–µ–π –∫ —Å—É–º–º–µ –≤—ã–¥–∞–Ω–Ω—ã—Ö –∑–∞–π–º–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥. –ü—Ä–æ—â–µ –≥–æ–≤–æ—Ä—è, —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π –¥–æ—Ö–æ–¥ —Å –∫–∞–∂–¥–æ–≥–æ –≤—ã–¥–∞–Ω–Ω–æ–≥–æ —Ä—É–±–ª—è. –ù–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –≤–ª–∏—è–µ—Ç —Å—Ä–æ–∫ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞ –∑–∞–π–º–æ–≤.",
    Metrics.AVG_LOAN_TERM.value: "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –∫–ª–∏–µ–Ω—Ç—ã –±—Ä–∞–ª–∏ –∑–∞–π–º—ã. –î–ª–∏–Ω–Ω—ã–π —Å—Ä–æ–∫ –º–æ–∂–µ—Ç —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –¥–æ—Ö–æ–¥—ã, –Ω–æ –∏ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –¥–µ–Ω–µ–≥. –ö–æ—Ä–æ—Ç–∫–∏–π —Å—Ä–æ–∫ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É–µ—Ç –ª–∏–±–æ –æ –±—ã—Å—Ç—Ä–æ–º –≤–æ–∑–≤—Ä–∞—Ç–µ, –ª–∏–±–æ –æ –ø–µ—Ä–µ—Ö–æ–¥–µ –∑–∞–π–º–∞ –≤ —Å—Ç–∞–¥–∏—é –ø—Ä–æ–¥–∞–∂–∏.",
    Metrics.ILLIQUID_BY_COUNT_PCT.value: "–ß–∞—Å—Ç—å —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–∞–ø–∞—Å–æ–≤ (–∑–∞–ª–æ–≥–æ–≤), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–∑–Ω–∞–µ—Ç—Å—è –Ω–µ–ª–∏–∫–≤–∏–¥–Ω–æ–π (—Ç—Ä—É–¥–Ω–æ—Ä–µ–∞–ª–∏–∑—É–µ–º–æ–π) –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É. –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∑–∞–ª–æ–≥–æ–≤—ã—Ö –∏–∑–¥–µ–ª–∏–π –¥–æ–ª–≥–æ –Ω–µ –ø—Ä–æ–¥–∞–µ—Ç—Å—è, –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª –∫–æ–º–ø–∞–Ω–∏–∏.",
    Metrics.ILLIQUID_BY_VALUE_PCT.value: "–ß–∞—Å—Ç—å —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–∞–ø–∞—Å–æ–≤ (–∑–∞–ª–æ–≥–æ–≤), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–∑–Ω–∞–µ—Ç—Å—è –Ω–µ–ª–∏–∫–≤–∏–¥–Ω–æ–π (—Ç—Ä—É–¥–Ω–æ—Ä–µ–∞–ª–∏–∑—É–µ–º–æ–π) –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–æ–ª–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç –¥–µ–Ω–µ–∂–Ω—ã–π –æ–±—ä–µ–º.",
    Metrics.REVENUE.value: "–î–µ–Ω—å–≥–∏, —Å—É–º–º–∏—Ä—É–µ–º –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º –∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.",
    Metrics.LOAN_ISSUE.value: "–î–µ–Ω—å–≥–∏, —Å—É–º–º–∏—Ä—É–µ–º.",
    Metrics.BELOW_LOAN.value: "–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ —Ç–æ–≤–∞—Ä–æ–≤, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∏–∂–µ —Å—É–º–º—ã –≤—ã–¥–∞–Ω–Ω–æ–≥–æ –ø–æ –Ω–∏–º –∑–∞–π–º–∞.",
    Metrics.DEBT.value: "–°–Ω–∏–º–æ–∫ –Ω–∞ –∫–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞. –í KPI/—Å–≤–æ–¥–∫–µ –∑–∞ –ø–µ—Ä–∏–æ–¥ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –º–µ—Å—è—á–Ω—ã—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –æ–∫–Ω—É.",
    Metrics.AVG_LOAN.value: "**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç '–ò—Ç–æ–≥–æ':** –µ—Å–ª–∏ –≤ —Ñ–∞–π–ª–µ –µ—Å—Ç—å –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –±–µ—Ä—É—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–µ—ë. –ò–Ω–∞—á–µ ‚Äî –≤–∑–≤–µ—à–µ–Ω–Ω–æ: Œ£(–í—ã–¥–∞–Ω–æ, —Ä—É–±)/Œ£(–í—ã–¥–∞–Ω–æ, —à—Ç).",
    Metrics.MARKUP_AMOUNT.value: "–°—É–º–º–∞. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî —Å—Ç—Ä–æ–∫–æ–≤–æ–µ ¬´–ò—Ç–æ–≥–æ –ø–æ —Ä–µ–≥–∏–æ–Ω—É¬ª, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å.",
    Metrics.DEBT_NO_SALE.value: "–ó–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ù–Æ–ó –Ω–∞ –∫–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞ (—Å–Ω–∏–º–æ–∫). –í –ø–µ—Ä–∏–æ–¥–µ —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ/–ø–æ—Å–ª–µ–¥–Ω–∏–π, –∞ –Ω–µ —Å—É–º–º—É.",
}
METRIC_HELP.update({
    Metrics.PLAN_ISSUE_PCT.value: "–ù–∞—Å–∫–æ–ª—å–∫–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–ª–∞–Ω –ø–æ —Å—É–º–º–µ –≤—ã–¥–∞—á. –ë–µ—Ä—ë–º –≥–æ—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞; –∞–≥—Ä–µ–≥–∞—Ü–∏—è ‚Äî —Å—Ä–µ–¥–Ω–µ–µ.",
    Metrics.PLAN_PENALTIES_PCT.value: "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º –∏ –ø–µ–Ω—è–º. –ë–µ—Ä—ë–º –∏–∑ —Ñ–∞–π–ª–∞; –∞–≥—Ä–µ–≥–∞—Ü–∏—è ‚Äî —Å—Ä–µ–¥–Ω–µ–µ.",
    Metrics.PLAN_REVENUE_PCT.value: "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏. –ë–µ—Ä—ë–º –∏–∑ —Ñ–∞–π–ª–∞; –∞–≥—Ä–µ–≥–∞—Ü–∏—è ‚Äî —Å—Ä–µ–¥–Ω–µ–µ.",
    Metrics.UNIQUE_CLIENTS.value: "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –º–µ—Å—è—Ü–µ. –í –ø–µ—Ä–∏–æ–¥–µ —Å—É–º–º–∏—Ä—É–µ—Ç—Å—è (–±–µ–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –º–µ–∂–¥—É –º–µ—Å—è—Ü–∞–º–∏).",
    Metrics.NEW_UNIQUE_CLIENTS.value: "–ù–æ–≤—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã –∑–∞ –º–µ—Å—è—Ü. –í –ø–µ—Ä–∏–æ–¥–µ —Å—É–º–º–∏—Ä—É–µ—Ç—Å—è.",
    Metrics.BRANCH_COUNT.value: "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤ –Ω–∞ –∫–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞ (—Å–Ω–∏–º–æ–∫). –í –ø–µ—Ä–∏–æ–¥–µ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ/–ø–æ—Å–ª–µ–¥–Ω–∏–π.",
    Metrics.BRANCH_NEW_COUNT.value: "–û—Ç–∫—Ä—ã—Ç–æ –Ω–æ–≤—ã—Ö –ª–æ–º–±–∞—Ä–¥–æ–≤ –∑–∞ –º–µ—Å—è—Ü (—Å–Ω–∏–º–æ–∫/—Å—É–º–º–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞).",
    Metrics.BRANCH_CLOSED_COUNT.value: "–ó–∞–∫—Ä—ã—Ç–æ –ª–æ–º–±–∞—Ä–¥–æ–≤ –∑–∞ –º–µ—Å—è—Ü.",
    Metrics.REDEEMED_ITEMS_COUNT.value: "–í—ã–∫—É–ø–ª–µ–Ω–Ω—ã–µ –∑–∞–ª–æ–≥–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ (—à—Ç). –°—É–º–º–∏—Ä—É–µ—Ç—Å—è.",
    Metrics.LOAN_REPAYMENT_SUM.value: "–°—É–º–º–∞ –ø–æ–≥–∞—à–µ–Ω–∏–π –æ—Å–Ω–æ–≤–Ω–æ–π —Å—É–º–º—ã –∑–∞–π–º–∞ (—Ä—É–±). –°—É–º–º–∏—Ä—É–µ—Ç—Å—è.",
    Metrics.LOSS_BELOW_LOAN.value: "–£–±—ã—Ç–æ–∫ –æ—Ç –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ (—Ä—É–±). –°—É–º–º–∏—Ä—É–µ—Ç—Å—è.",
    Metrics.INTEREST_SHARE.value: "–î–æ–ª—è –ù–Æ–ó –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º % –∏ –ø–µ–Ω–∏. –ë–µ—Ä—ë–º –∏–∑ —Ñ–∞–π–ª–∞; –∞–≥—Ä–µ–≥–∞—Ü–∏—è ‚Äî —Å—Ä–µ–¥–Ω–µ–µ.",
})

PERCENT_METRICS = {
    Metrics.MARKUP_PCT.value,
    Metrics.ILLIQUID_BY_COUNT_PCT.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
    Metrics.YIELD.value,
    Metrics.RISK_SHARE.value,
    Metrics.ISSUE_SHARE.value,
    Metrics.DEBT_SHARE.value,
    Metrics.REDEEMED_SHARE_PCT.value,
}
PERCENT_METRICS |= {
    Metrics.PLAN_ISSUE_PCT.value,
    Metrics.PLAN_PENALTIES_PCT.value,
    Metrics.PLAN_REVENUE_PCT.value,
    Metrics.INTEREST_SHARE.value,
}

def is_percent_metric(name: str) -> bool:
    if not name:
        return False
    s = str(name)
    low = s.lower()
    return (
        s in PERCENT_METRICS
        or "–¥–æ–ª—è" in low
        or ("–Ω–∞—Ü–µ–Ω–∫" in low and s in {Metrics.MARKUP_PCT.value, Metrics.CALC_MARKUP_PCT.value})
    )


def _maybe_scale_percent(metric: str, value: float | None) -> float | None:
    if value is None or pd.isna(value):
        return value
    if not is_percent_metric(metric):
        return value
    if abs(float(value)) <= 1.5:
        return float(value) * 100.0
    return float(value)

def agg_of_metric(metric: str) -> str:
    return "sum" if metric in METRICS_SUM else ("last" if metric in METRICS_LAST else "mean")

def format_rub(x: float | None) -> str:
    if x is None or pd.isna(x):
        return "‚Äî"
    return f"{x:,.0f} ‚ÇΩ".replace(",", " ")

def fmt_pct(v: float | None, digits: int = 2) -> str:
    if v is None or pd.isna(v):
        return "‚Äî"
    return f"{v:.{digits}f}%"

def fmt_days(v: float | None, digits: int = 2) -> str:
    if v is None or pd.isna(v):
        return "‚Äî"
    return f"{v:.{digits}f} –¥–Ω."


# --- AI –∞–Ω–∞–ª–∏–∑ ---
AI_METRICS_FOCUS = [
    Metrics.REVENUE.value,
    Metrics.LOAN_ISSUE.value,
    Metrics.MARKUP_PCT.value,
    Metrics.YIELD.value,
    Metrics.RISK_SHARE.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
    Metrics.REDEEMED_SHARE_PCT.value,
    Metrics.BRANCH_COUNT.value,
]

AI_REGION_METRICS = [
    Metrics.REVENUE.value,
    Metrics.MARKUP_PCT.value,
    Metrics.RISK_SHARE.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
]


def _forecast_target_label(last_month: str) -> str:
    if last_month in ORDER:
        idx = ORDER.index(last_month)
        if idx + 1 < len(ORDER):
            return ORDER[idx + 1]
        return f"{ORDER[0]} (—Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥)"
    return "–°–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥"


def _format_value_for_metric(metric: str, value: float | None) -> str:
    if value is None or pd.isna(value):
        return "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    if is_percent_metric(metric):
        return f"{value:.2f}%"
    if "—Ä—É–±" in metric:
        return f"{value:,.0f} —Ä—É–±".replace(",", " ")
    if "–¥–Ω–µ–π" in metric:
        return f"{value:.2f} –¥–Ω–µ–π"
    return f"{value:,.0f}".replace(",", " ")


def _format_metric_for_prompt(metric: str, value: float | None) -> str:
    val = _format_value_for_metric(metric, value)
    if val == "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö":
        return f"{metric}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    return f"{metric}: {val}"


def _format_pct_change_text(value: float | None) -> str:
    if value is None:
        return "‚Äî"
    arrow = "‚Üë" if value > 0 else ("‚Üì" if value < 0 else "‚Üî")
    return f"{arrow} {value * 100:+.1f}%"


def _collect_period_metrics(df_source: pd.DataFrame, regions: List[str], months_range: List[str]) -> Dict[str, float | None]:
    data: Dict[str, float | None] = {}
    for metric in AI_METRICS_FOCUS:
        data[metric] = period_value_from_itogo(df_source, regions, metric, months_range)
    return data


def _collect_comparison_metrics(df_a: pd.DataFrame, df_b: pd.DataFrame, regions: List[str], months_range: List[str]) -> Tuple[Dict[str, float | None], Dict[str, float | None]]:
    return _collect_period_metrics(df_a, regions, months_range), _collect_period_metrics(df_b, regions, months_range)


@st.cache_data(show_spinner=False, max_entries=512)
def _monthly_series_for_metric(df_source: pd.DataFrame, regions: List[str], metric: str, months_range: List[str]) -> pd.Series:
    months_tuple = tuple(months_range)
    ser = month_series_from_file(df_source, tuple(regions), metric, months_tuple)
    if ser.empty:
        return ser
    ser = ser.reindex(months_tuple).fillna(0.0)
    ser = pd.to_numeric(ser, errors="coerce").fillna(0.0)
    return ser.astype(float)


def _format_monthly_series(metric: str, series: pd.Series) -> str:
    if series is None or series.empty:
        return ""
    parts = []
    for month, val in series.items():
        if val is None or pd.isna(val):
            continue
        parts.append(f"{month}={_format_value_for_metric(metric, val)}")
    return "; ".join(parts)


def _regional_snapshot_for_metric(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metric: str, top_n: int = 3) -> str:
    values = period_values_by_region_from_itogo(df_source, regions, metric, months_range)
    if not values:
        return ""
    items: List[Tuple[str, float | None]] = []
    for reg, val in values.items():
        items.append((reg, None if val is None else float(val)))
    need_desc = metric in METRICS_SMALLER_IS_BETTER
    items.sort(key=lambda kv: (float('inf') if kv[1] is None else kv[1]), reverse=not need_desc)
    top = items[:top_n]
    bottom = []
    if len(items) > top_n:
        bottom_raw = items[-top_n:]
        bottom = bottom_raw if need_desc else list(reversed(bottom_raw))

    def fmt_entry(entry):
        reg, val = entry
        return f"{reg}: {_format_value_for_metric(metric, val)}"

    parts = []
    if top:
        parts.append("–¢–û–ü: " + ", ".join(fmt_entry(row) for row in top))
    if bottom:
        parts.append("–ù–∏–∑: " + ", ".join(fmt_entry(row) for row in bottom))
    return " | ".join(parts)


def _regional_context_block(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metrics_subset: List[str]) -> str:
    lines = []
    for metric in metrics_subset:
        snap = _regional_snapshot_for_metric(df_source, regions, months_range, metric)
        if snap:
            lines.append(f"{metric}: {snap}")
    return "\n".join(lines)


def _build_metric_matrix(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metrics: List[str]) -> pd.DataFrame:
    scoped: Dict[str, pd.Series] = {}
    for metric in metrics:
        series = _monthly_series_for_metric(df_source, tuple(regions), metric, months_range)
        if series is None or series.empty:
            continue
        scoped[metric] = pd.to_numeric(series, errors="coerce")
    if not scoped:
        return pd.DataFrame()
    matrix = pd.DataFrame(scoped)
    matrix = matrix.dropna(how="all")
    matrix = matrix.dropna(axis=1, how="all")
    return matrix


def _future_month_labels(last_month: str, horizon: int) -> List[str]:
    if last_month in ORDER:
        base_index = ORDER.index(last_month)
    else:
        base_index = len(ORDER) - 1
    labels: List[str] = []
    for step in range(1, horizon + 1):
        idx = (base_index + step) % len(ORDER)
        label = ORDER[idx]
        if base_index + step >= len(ORDER):
            label += " (—Å–ª–µ–¥.)"
        labels.append(label)
    return labels


def _linear_trend_forecast(series: pd.Series, horizon: int = 3) -> Dict[str, Any]:
    clean = pd.to_numeric(series, errors="coerce").dropna()
    if clean.empty or len(clean) < 2:
        return {}
    y = clean.values.astype(float)
    x = np.arange(len(y))
    slope, intercept = np.polyfit(x, y, 1)
    fitted = intercept + slope * x
    residuals = y - fitted
    sigma = float(residuals.std(ddof=1)) if len(residuals) > 1 else 0.0
    forecast_vals: List[float] = []
    lower_vals: List[float] = []
    upper_vals: List[float] = []
    for step in range(1, horizon + 1):
        t = len(y) + step - 1
        value = intercept + slope * t
        if sigma == 0.0:
            band = 0.0
        else:
            band = 1.96 * sigma * np.sqrt(1 + step / max(len(y), 1))
        forecast_vals.append(float(value))
        lower_vals.append(float(value - band))
        upper_vals.append(float(value + band))
    return {
        "slope": float(slope),
        "intercept": float(intercept),
        "sigma": sigma,
        "forecast": forecast_vals,
        "lower": lower_vals,
        "upper": upper_vals,
        "fitted": fitted,
        "residuals": residuals,
        "method": "linear",
        "seasonal": None,
        "description": "–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –º–µ—Å—è—Ü–∞–º",
    }


def _seasonal_linear_forecast(series: pd.Series, horizon: int = 3) -> Dict[str, Any]:
    clean = pd.to_numeric(series, errors="coerce").dropna()
    if clean.empty or len(clean) < 4:
        return {}
    y = clean.values.astype(float)
    labels = [str(idx) for idx in series.dropna().index]
    x = np.arange(len(y))
    slope, intercept = np.polyfit(x, y, 1)
    fitted = intercept + slope * x
    residuals = y - fitted
    if len(residuals) < 2:
        return {}
    seasonal_groups: Dict[int, List[float]] = defaultdict(list)
    for idx, label in enumerate(labels):
        month_idx = ORDER.index(label) if label in ORDER else idx % len(ORDER)
        seasonal_groups[month_idx].append(residuals[idx])
    if not seasonal_groups:
        return {}
    seasonal_adjustment = {k: float(np.mean(v)) for k, v in seasonal_groups.items() if v}
    sigma = float(residuals.std(ddof=1))
    future_labels = _future_month_labels(labels[-1], horizon)
    forecast_vals: List[float] = []
    lower_vals: List[float] = []
    upper_vals: List[float] = []
    for step, future_label in enumerate(future_labels, start=1):
        t = len(y) + step - 1
        base_value = intercept + slope * t
        month_key = future_label.split()[0]
        month_idx = ORDER.index(month_key) if month_key in ORDER else t % len(ORDER)
        seasonal = seasonal_adjustment.get(month_idx, 0.0)
        value = base_value + seasonal
        band = 0.0 if sigma == 0.0 else 1.96 * sigma * np.sqrt(1 + step / max(len(y), 1))
        forecast_vals.append(float(value))
        lower_vals.append(float(value - band))
        upper_vals.append(float(value + band))
    return {
        "slope": float(slope),
        "intercept": float(intercept),
        "sigma": sigma,
        "forecast": forecast_vals,
        "lower": lower_vals,
        "upper": upper_vals,
        "fitted": fitted,
        "residuals": residuals,
        "seasonal": seasonal_adjustment,
        "method": "seasonal_linear",
        "description": "–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ —Å –ø–æ–ø—Ä–∞–≤–∫–æ–π –Ω–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü–∞–º",
    }


def _choose_forecast_model(series: pd.Series, horizon: int = 3) -> Dict[str, Any]:
    linear = _linear_trend_forecast(series, horizon)
    seasonal = _seasonal_linear_forecast(series, horizon)
    if not linear and not seasonal:
        return {}
    if not seasonal:
        return linear
    if not linear:
        return seasonal
    def _sse(bundle):
        residuals = bundle.get("residuals")
        if residuals is None:
            return float("inf")
        return float(np.sum(np.square(residuals)))
    linear_sse = _sse(linear)
    seasonal_sse = _sse(seasonal)
    # –µ—Å–ª–∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –æ—â—É—Ç–∏–º–æ –ª—É—á—à–µ (–Ω–∞ 5% –∏ –±–æ–ª–µ–µ), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
    if seasonal_sse < linear_sse * 0.95:
        return seasonal | {"selected_model": "seasonal", "sse": seasonal_sse, "baseline_sse": linear_sse}
    return linear | {"selected_model": "linear", "sse": linear_sse, "baseline_sse": seasonal_sse}


def _prepare_forecast(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metric: str, horizon: int = 3) -> Dict[str, Any]:
    history = _monthly_series_for_metric(df_source, tuple(regions), metric, months_range)
    if history is None or history.empty:
        return {}
    history = pd.to_numeric(history, errors="coerce").dropna()
    if history.empty:
        return {}
    trend = _choose_forecast_model(history, horizon=horizon)
    if not trend:
        return {}
    future_labels = _future_month_labels(str(history.index[-1]), horizon)
    cleaned = {k: v for k, v in trend.items() if k not in {"residuals", "fitted"}}
    return {
        "history": history,
        "future_labels": future_labels,
        **cleaned,
    }


def _monthly_context_block(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metrics_subset: List[str]) -> str:
    lines = []
    for metric in metrics_subset:
        series = _monthly_series_for_metric(df_source, regions, metric, months_range)
        text = _format_monthly_series(metric, series)
        if text:
            lines.append(f"{metric}: {text}")
    return "\n".join(lines)


def _render_insights(title: str, lines: List[str]) -> None:
    clean = [line for line in lines if line]
    if not clean:
        return
    bullets = "\n".join(f"- {line}" for line in clean)
    st.markdown(f"**{title}**\n{bullets}")


def _render_plan(title: str, lines: List[str]) -> None:
    clean = [line for line in lines if line]
    if not clean:
        return
    numbered = "\n".join(f"{idx}. {line}" for idx, line in enumerate(clean, start=1))
    st.markdown(f"**{title}**\n{numbered}")


def _sanitize_metric_label(label: str) -> str:
    return re.sub(r"\(.*?\)", "", str(label)).strip().lower()


def _unique_lines(lines: List[str]) -> List[str]:
    seen = set()
    result: List[str] = []
    for line in lines:
        if line and line not in seen:
            result.append(line)
            seen.add(line)
    return result


def _monthly_diagnostics(series: pd.Series, metric: str) -> List[str]:
    lines: List[str] = []
    s = series.dropna()
    if s.empty:
        return lines

    first_month = str(s.index[0])
    last_month = str(s.index[-1])
    start_val = _format_value_for_metric(metric, s.iloc[0])
    end_val = _format_value_for_metric(metric, s.iloc[-1])
    if first_month != last_month:
        direction = "–≤—ã—Ä–æ—Å" if s.iloc[-1] > s.iloc[0] else ("—Å–Ω–∏–∑–∏–ª—Å—è" if s.iloc[-1] < s.iloc[0] else "–æ—Å—Ç–∞–ª—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ")
        lines.append(f"{metric}: {direction} —Å {start_val} –≤ {first_month} –¥–æ {end_val} –≤ {last_month}.")
    else:
        lines.append(f"{metric}: {first_month} = {start_val}.")

    if len(s) >= 2:
        diff = s.diff().dropna()
        if not diff.empty:
            inc_month = diff.idxmax()
            inc_val = diff.loc[inc_month]
            if inc_val > 0:
                prev_idx = list(s.index).index(inc_month) - 1
                if prev_idx >= 0:
                    prev_month = s.index[prev_idx]
                    prev_val = _format_value_for_metric(metric, s.loc[prev_month])
                    lines.append(f"–ù–∞–∏–±–æ–ª—å—à–∏–π –ø—Ä–∏—Ä–æ—Å—Ç –≤ {inc_month}: +{_format_delta(metric, inc_val)} (—Å {prev_val}).")
            dec_month = diff.idxmin()
            dec_val = diff.loc[dec_month]
            if dec_val < 0:
                prev_idx = list(s.index).index(dec_month) - 1
                if prev_idx >= 0:
                    prev_month = s.index[prev_idx]
                    prev_val = _format_value_for_metric(metric, s.loc[prev_month])
                    lines.append(f"–ù–∞–∏–±–æ–ª—å—à–µ–µ –ø–∞–¥–µ–Ω–∏–µ –≤ {dec_month}: {_format_delta(metric, dec_val)} (—Å {prev_val}).")

    extrema = {
        "max": s.idxmax() if not s.empty else None,
        "min": s.idxmin() if not s.empty else None,
    }
    if extrema["max"] is not None:
        lines.append(f"–ü–∏–∫: {extrema['max']} ‚Äî {_format_value_for_metric(metric, s.loc[extrema['max']])}.")
    if extrema["min"] is not None and extrema["min"] != extrema["max"]:
        lines.append(f"–ú–∏–Ω–∏–º—É–º: {extrema['min']} ‚Äî {_format_value_for_metric(metric, s.loc[extrema['min']])}.")
    return lines


def _plot_metric_trend(metric: str, series: pd.Series, title: str) -> go.Figure:
    s = series.dropna()
    fig = go.Figure()
    if not s.empty:
        fig.add_trace(go.Scatter(
            x=list(map(str, s.index)),
            y=s.values,
            mode="lines+markers",
            fill="tozeroy",
            line=dict(color="#2563eb", width=3),
            marker=dict(size=6)
        ))
    tickfmt, suf = y_fmt_for_metric(metric)
    fig.update_layout(
        title=title,
        height=320,
        margin=dict(t=60, l=20, r=20, b=40),
        hovermode="x unified",
        plot_bgcolor="rgba(255,255,255,0.85)",
        paper_bgcolor="rgba(0,0,0,0)",
    )
    fig.update_yaxes(tickformat=tickfmt, ticksuffix=suf.strip(), title=None)
    fig.update_xaxes(title=None, showgrid=False)
    return fig


def _render_metric_trend_section(
    title: str,
    metrics: List[str],
    df_source: pd.DataFrame,
    regions: List[str],
    months_range: List[str],
    *,
    widget_key: str
) -> None:
    available = []
    for metric in metrics:
        series = _monthly_series_for_metric(df_source, tuple(regions), metric, months_range)
        if not series.empty:
            available.append(metric)
    if not available:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∏–Ω–∞–º–∏–∫–∏.")
        return

    default_metric = available[0]
    chosen_metric = st.selectbox(
        title,
        options=available,
        index=0,
        key=f"trend_{widget_key}"
    )
    series = _monthly_series_for_metric(df_source, tuple(regions), chosen_metric, months_range)
    fig = _plot_metric_trend(chosen_metric, series, chosen_metric)
    st.plotly_chart(fig, use_container_width=True)
    monthly_lines = _monthly_diagnostics(series, chosen_metric)
    _render_insights("–ú–µ—Å—è—á–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞", monthly_lines)


def _describe_metric_series(series: pd.Series, metric: str) -> str | None:
    if series is None:
        return None
    ser = pd.Series(series).dropna()
    if ser.empty:
        return None
    try:
        ser = ser.astype(float)
    except Exception:
        ser = pd.to_numeric(ser, errors="coerce").dropna()
    if ser.empty:
        return None
    is_small_better = metric in METRICS_SMALLER_IS_BETTER
    best_idx = ser.idxmin() if is_small_better else ser.idxmax()
    worst_idx = ser.idxmax() if is_small_better else ser.idxmin()
    best_val = _format_value_for_metric(metric, ser.loc[best_idx])
    best_name = " ¬∑ ".join(map(str, best_idx)) if isinstance(best_idx, tuple) else str(best_idx)
    if best_idx == worst_idx:
        return f"{metric}: –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –ø–æ {best_name} ({best_val})."
    worst_val = _format_value_for_metric(metric, ser.loc[worst_idx])
    worst_name = " ¬∑ ".join(map(str, worst_idx)) if isinstance(worst_idx, tuple) else str(worst_idx)
    if is_small_better:
        return f"{metric}: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É {best_name} ({best_val}); –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π ‚Äî —É {worst_name} ({worst_val})."
    return f"{metric}: –ª–∏–¥–∏—Ä—É–µ—Ç {best_name} ({best_val}); –æ—Ç—Å—Ç–∞—ë—Ç {worst_name} ({worst_val})."


def _format_delta(metric: str, delta: float) -> str:
    if delta is None or pd.isna(delta):
        return "0"
    if is_percent_metric(metric):
        return f"{delta:+.2f} –ø.–ø."
    if "—Ä—É–±" in metric:
        return f"{delta:+,.0f} —Ä—É–±".replace(",", " ")
    if "–¥–Ω–µ–π" in metric:
        return f"{delta:+.1f} –¥–Ω."
    return f"{delta:+,.1f}".replace(",", " ")


def _describe_deltas(deltas: List[tuple[str, float]], metric: str) -> str | None:
    meaningful = [(name, float(delta)) for name, delta in deltas if delta is not None and not pd.isna(delta)]
    if not meaningful:
        return None
    pos = [item for item in meaningful if item[1] > 0]
    neg = [item for item in meaningful if item[1] < 0]
    fragments = []
    if pos:
        leader = max(pos, key=lambda x: x[1])
        fragments.append(f"—Ä–æ—Å—Ç —É {leader[0]} ({_format_delta(metric, leader[1])})")
    if neg:
        lagger = min(neg, key=lambda x: x[1])
        fragments.append(f"—Å–Ω–∏–∂–µ–Ω–∏–µ —É {lagger[0]} ({_format_delta(metric, lagger[1])})")
    if not fragments:
        # –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–π –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç–∏
        top = max(meaningful, key=lambda x: abs(x[1]))
        fragments.append(f"–∏–∑–º–µ–Ω–µ–Ω–∏–µ —É {top[0]} ({_format_delta(metric, top[1])})")
    return f"{metric}: {', '.join(fragments)}"


DEFAULT_ACTION_TEMPLATES = {
    "high": "–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –º–µ—Ç–æ–¥–∏–∫—É {name}: {metric} –¥–µ—Ä–∂–∏—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ {value}. –û–ø–∏—à–∏—Ç–µ —à–∞–≥–∏ –∏ –æ–±—É—á–∏—Ç–µ —Å–æ—Å–µ–¥–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã.",
    "low": "–†–∞–∑–±–µ—Ä–∏—Ç–µ –ø—Ä–∏—á–∏–Ω—É —Å–Ω–∏–∂–µ–Ω–∏—è –≤ {name}: {metric} —É–ø–∞–ª –¥–æ {value}. –ù–∞–∑–Ω–∞—á—å—Ç–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏ –ø–ª–∞–Ω –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.",
    "delta_pos": "–†–æ—Å—Ç —É {name}: {metric} –∏–∑–º–µ–Ω–∏–ª—Å—è –Ω–∞ {delta}. –°–Ω–∏–º–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã –∏ –≤–Ω–µ–¥—Ä–∏—Ç–µ –∫–æ–Ω—Ç—Ä–æ–ª—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏.",
    "delta_neg": "–ü—Ä–æ—Å–∞–¥–∫–∞ –≤ {name}: {metric} –∏–∑–º–µ–Ω–∏–ª—Å—è –Ω–∞ {delta}. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∏ –∑–∞–¥–∞–π—Ç–µ —Å—Ä–æ–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.",
}


ACTION_TEMPLATES = {
    Metrics.REVENUE.value: {
        "high": "–†–∞–∑–≤–∏–≤–∞–π—Ç–µ —Ñ–ª–∞–≥–º–∞–Ω {name}: –≤—ã—Ä—É—á–∫–∞ {value}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ñ–∏—Ü–∏—Ç–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –ø–ª–∞–Ω –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∞–∫—Ç–∏–∫.",
        "low": "–ü–æ–¥–Ω–∏–º–∏—Ç–µ –ø—Ä–æ–¥–∞–∂–∏ –≤ {name}: –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–æ—Å–µ–ª –¥–æ {value}. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø—Ä–µ—Å—Å-–∞—É–¥–∏—Ç –≤–∏—Ç—Ä–∏–Ω—ã, –∑–∞–ø–ª–∞–Ω–∏—Ä—É–π—Ç–µ –∞–∫—Ü–∏—é –∏ —É—Å–∏–ª–∏–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞.",
        "delta_pos": "–ü—Ä–æ–¥–∞–∂–∏ –≤ {name} –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ {delta}. –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –∞–∫—Ü–∏–∏, —Ç—Ä–∞—Ñ–∏–∫ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—é ‚Äî —Å–¥–µ–ª–∞–π—Ç–µ —á–µ–∫-–ª–∏—Å—Ç —Ç–∏—Ä–∞–∂–∏—Ä–æ–≤–∞–Ω–∏—è.",
        "delta_neg": "–ü—Ä–æ–¥–∞–∂–∏ –≤ {name} —É–ø–∞–ª–∏ –Ω–∞ {delta}. –°–æ–±–µ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.",
    },
    Metrics.MARKUP_PCT.value: {
        "high": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–¥—Ö–æ–¥ {name}: –Ω–∞—Ü–µ–Ω–∫–∞ {value}. –ó–∞–ø–∏—à–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º –æ—Ü–µ–Ω–∫–∏ –∏ –æ–±—É—á–∏—Ç–µ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤.",
        "low": "–ü–æ–≤—ã—à–∞–π—Ç–µ –Ω–∞—Ü–µ–Ω–∫—É {name}: –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å {value}. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Ü–µ–Ω–∫—É –∑–∞–ª–æ–≥–æ–≤ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –ø—Ä–æ–¥–∞–∂, –≤—ã—è–≤–∏—Ç–µ —Å–∫–∏–¥–∫–∏.",
        "delta_pos": "–ù–∞—Ü–µ–Ω–∫–∞ {name} –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ {delta}. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫—Ä–µ–ø–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç —Å –≤—ã—Å–æ–∫–æ–π –º–∞—Ä–∂–æ–π.",
        "delta_neg": "–ù–∞—Ü–µ–Ω–∫–∞ {name} —É–ø–∞–ª–∞ –Ω–∞ {delta}. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ä–µ–≤–∏–∑–∏—é —Å–∫–∏–¥–æ–∫, –æ–±–Ω–æ–≤–∏—Ç–µ –ø—Ä–∞–≤–∏–ª–∞ —É—Ü–µ–Ω–∫–∏ –∏ –ø—Ä–æ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ.",
    },
    Metrics.RISK_SHARE.value: {
        "high": "–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ —Ä–∏—Å–∫ {name}: –¥–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞ {value}. –û—Ü–∏—Ñ—Ä—É–π—Ç–µ –æ—Ü–µ–Ω–∫—É –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∏–ª–∏–∞–ª–∞—Ö.",
        "low": "–°–æ–∫—Ä–∞—Ç–∏—Ç–µ —Ä–∏—Å–∫ {name}: –¥–æ–ª—è {value}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ü–µ–Ω–∫—É, —Ä–∞–±–æ—Ç—É —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏ –∏ –∑–∞–ø—Ä–µ—Ç–∏—Ç–µ —Å–¥–µ–ª–∫–∏ —Å —É—è–∑–≤–∏–º—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏.",
        "delta_pos": "–†–∏—Å–∫ –≤ {name} —Å–Ω–∏–∂–∞–µ—Ç—Å—è –Ω–∞ {delta}. –ó–∞–∫—Ä–µ–ø–∏—Ç–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É –æ—Ü–µ–Ω–∫–∏, –ø—Ä–æ–≤–µ–¥–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥.",
        "delta_neg": "–†–∏—Å–∫ –≤ {name} –≤—ã—Ä–æ—Å –Ω–∞ {delta}. –°—Ä–æ—á–Ω–æ –ø—Ä–æ–≤–µ–¥–∏—Ç–µ —Ä–∞–∑–±–æ—Ä —Å–¥–µ–ª–æ–∫ –∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–∏–º–∏—Ç—ã –∏ –¥–∏—Å–∫–æ–Ω—Ç.",
    },
    Metrics.ILLIQUID_BY_VALUE_PCT.value: {
        "high": "–°–∫–ª–∞–¥ –≤ –Ω–æ—Ä–º–µ —É {name}: –Ω–µ–ª–∏–∫–≤–∏–¥ {value}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Ö –ø–æ–¥—Ö–æ–¥ –∫ –æ–±–æ—Ä–æ—Ç—É –∏ –∫–æ–Ω—Ç—Ä–æ–ª—é –æ—Å—Ç–∞—Ç–∫–æ–≤.",
        "low": "–°–Ω–∏–∂–∞–π –Ω–µ–ª–∏–∫–≤–∏–¥ —É {name}: –¥–æ–ª—è {value}. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂—É, —Ä–∞–∑–±–µ—Ä–∏—Ç–µ –ø—Ä–∏—á–∏–Ω—ã –∑–∞–≤–∏—Å–∞–Ω–∏—è –∏ –ø–µ—Ä–µ—Å—Ç—Ä–æ–π—Ç–µ –∑–∞–∫—É–ø–∫–∏.",
        "delta_pos": "–ù–µ–ª–∏–∫–≤–∏–¥ {name} —Å–æ–∫—Ä–∞—Ç–∏–ª—Å—è –Ω–∞ {delta}. –†–∞—Å–ø–∏—à–∏—Ç–µ —É—Å–ø–µ—à–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç.",
        "delta_neg": "–ù–µ–ª–∏–∫–≤–∏–¥ {name} –≤—ã—Ä–æ—Å –Ω–∞ {delta}. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ä–µ–≤–∏–∑–∏—é —Å–∫–ª–∞–¥–∞ –∏ —Å–æ—Å—Ç–∞–≤—å—Ç–µ –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏.",
    },
    Metrics.YIELD.value: {
        "high": "–£–¥–µ—Ä–∂–∏—Ç–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å {name}: {value}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –≤–∑—ã—Å–∫–∞–Ω–∏—è —É—Å—Ç–æ–π—á–∏–≤ –∏ –Ω–µ —É—Ö—É–¥—à–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –æ–ø—ã—Ç.",
        "low": "–ü–æ–¥–Ω–∏–º–∞–π—Ç–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å {name}: {value}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞–≤–∫–∏, —Ä–∞–±–æ—Ç—É —Å –ø—Ä–æ—Å—Ä–æ—á–∫–æ–π –∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞–º.",
        "delta_pos": "–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å {name} –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ {delta}. –ó–∞–∫—Ä–µ–ø–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å –¥–æ–ª–≥–∞–º–∏ –∏ —Å—Ç–∏–º—É–ª–∏—Ä—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ.",
        "delta_neg": "–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å {name} —Å–Ω–∏–∑–∏–ª–∞—Å—å –Ω–∞ {delta}. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞—É–¥–∏—Ç –ø—Ä–æ—Å—Ä–æ—á–∫–∏ –∏ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤–∑—ã—Å–∫–∞–Ω–∏—è.",
    },
}


def _action_templates_for_metric(metric: str) -> Dict[str, str]:
    base = DEFAULT_ACTION_TEMPLATES.copy()
    custom = ACTION_TEMPLATES.get(metric, {})
    base.update(custom)
    return base


def _label_from_index(idx) -> str:
    if isinstance(idx, tuple):
        return " ¬∑ ".join(str(x) for x in idx)
    return str(idx)


def _generate_actions_for_series(series: pd.Series | Dict, metric: str) -> List[str]:
    ser = pd.Series(series).dropna()
    if ser.empty:
        return []
    try:
        ser = ser.astype(float)
    except Exception:
        ser = pd.to_numeric(ser, errors="coerce").dropna()
    if ser.empty:
        return []
    ser.index = [_label_from_index(idx) for idx in ser.index]
    higher_better = metric not in METRICS_SMALLER_IS_BETTER
    best_idx = ser.idxmax() if higher_better else ser.idxmin()
    worst_idx = ser.idxmin() if higher_better else ser.idxmax()
    templates = _action_templates_for_metric(metric)
    lines = []
    best_value = _format_value_for_metric(metric, ser.loc[best_idx])
    lines.append(templates["high"].format(name=best_idx, value=best_value, metric=metric))
    if worst_idx != best_idx and worst_idx in ser.index:
        worst_value = _format_value_for_metric(metric, ser.loc[worst_idx])
        lines.append(templates["low"].format(name=worst_idx, value=worst_value, metric=metric))
    return lines


def _generate_actions_for_deltas(deltas: List[tuple[str, float]], metric: str) -> List[str]:
    meaningful = [(name, float(delta)) for name, delta in deltas if delta is not None and not pd.isna(delta) and abs(delta) > 1e-9]
    if not meaningful:
        return []
    templates = _action_templates_for_metric(metric)
    lines = []
    pos = [item for item in meaningful if item[1] > 0]
    neg = [item for item in meaningful if item[1] < 0]
    if pos:
        leader = max(pos, key=lambda x: x[1])
        lines.append(templates["delta_pos"].format(name=leader[0], delta=_format_delta(metric, leader[1]), metric=metric))
    if neg:
        lagger = min(neg, key=lambda x: x[1])
        lines.append(templates["delta_neg"].format(name=lagger[0], delta=_format_delta(metric, lagger[1]), metric=metric))
    return lines


KEY_DECISION_METRICS = [
    Metrics.LOAN_ISSUE.value,
    Metrics.PENALTIES_RECEIVED.value,
    Metrics.REVENUE.value,
]

SUPPORT_DECISION_METRICS = [
    Metrics.MARKUP_PCT.value,
    Metrics.RISK_SHARE.value,
    Metrics.ILLIQUID_BY_VALUE_PCT.value,
]


METRIC_GUIDE: Dict[str, Dict[str, Dict[str, List[str] | str]]] = {
    Metrics.LOAN_ISSUE.value: {
        "up": {
            "summary": "–í—ã–¥–∞—á–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–∞—Å—Å—ã —É—Å–ø–µ–≤–∞—é—Ç –∑–∞ —Ä–æ—Å—Ç–æ–º.",
                "–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –ª–∏–¥–µ—Ä–æ–≤ –≤—ã–¥–∞—á –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏—Ç–µ –∏—Ö –Ω–∞ –æ—Ç—Å—Ç–∞—é—â–∏—Ö."
            ],
        },
        "down": {
            "summary": "–í—ã–¥–∞—á–∏ —É–ø–∞–ª–∏ –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–†–∞–∑–±–µ—Ä–∏—Ç–µ –ø—Ä–∏—á–∏–Ω—É –ø–∞–¥–µ–Ω–∏—è –ø–æ —Ñ–∏–ª–∏–∞–ª–∞–º, –≥–¥–µ –ø—Ä–æ—Å–∞–¥–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è.",
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ç–∏–º—É–ª–∏—Ä—É—é—â–∏–µ –∞–∫—Ü–∏–∏ –∏–ª–∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Ü–µ–Ω–∫—É –∑–∞–ª–æ–≥–∞, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –ø–æ—Ç–æ–∫."
            ],
        },
        "flat": {
            "summary": "–í—ã–¥–∞—á–∏ –¥–µ—Ä–∂–∞—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ {current} –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ {start}.",
            "actions": [
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏ –∑–∞–¥–∞–π—Ç–µ —Ü–µ–ª–∏ —Ä–æ—Å—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ–∏–ª–∏–∞–ª–∞–º.",
                "–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –ø–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—é –≤—ã–¥–∞—á (–º–∞—Ä–∫–µ—Ç–∏–Ω–≥, –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞)."
            ],
        },
    },
    Metrics.PENALTIES_RECEIVED.value: {
        "up": {
            "summary": "–î–æ—Ö–æ–¥ –æ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –∏ –ø–µ–Ω–µ–π –≤—ã—Ä–æ—Å –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É –≤–∑—ã—Å–∫–∞–Ω–∏—è: —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ.",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ —Ä–∞—Å—Ç—ë—Ç –ª–∏ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —Å—Ç–∞–≤–æ–∫ –∏ —Å—Ä–æ–∫–æ–≤."
            ],
        },
        "down": {
            "summary": "–ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –¥–æ—Ö–æ–¥—ã —Å–Ω–∏–∑–∏–ª–∏—Å—å –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ —É—Ö—É–¥—à–∏–ª–∞—Å—å –ª–∏ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ –ø–æ–≥–∞—à–µ–Ω–∏–π –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏.",
                "–ó–∞–ø–ª–∞–Ω–∏—Ä—É–π—Ç–µ –º–µ—Ä—ã –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Å—Ç–∞–≤–æ–∫, —Ä–∞–±–æ—Ç–∞ —Å –¥–µ–±–∏—Ç–æ—Ä–∫–æ–π."
            ],
        },
        "flat": {
            "summary": "–ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –æ—Å—Ç–∞—é—Ç—Å—è –æ–∫–æ–ª–æ {current}.",
            "actions": [
                "–°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã: –≥–¥–µ –º–æ–∂–Ω–æ —É—Å–∫–æ—Ä–∏—Ç—å –≤–∑—ã—Å–∫–∞–Ω–∏–µ –±–µ–∑ —Ä–æ—Å—Ç–∞ –ø—Ä–æ—Å—Ä–æ—á–∫–∏?",
                "–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –º–µ—Ä—ã –ø–æ –ø–æ–≤—ã—à–µ–Ω–∏—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è (up-sell, –ø—Ä–æ–ª–æ–Ω–≥–∞—Ü–∏—è)."
            ],
        },
    },
    Metrics.REVENUE.value: {
        "up": {
            "summary": "–í—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–∞—Ä–∂–∞ –Ω–µ –ø—Ä–æ—Å–µ–¥–∞–µ—Ç ‚Äî –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –Ω–∞—Ü–µ–Ω–∫—É.",
                "–ü–æ–¥–¥–µ—Ä–∂–∏—Ç–µ —Ñ–∏–ª–∏–∞–ª—ã-–ª–∏–¥–µ—Ä—ã —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–π—Ç–µ –∏—Ö –ø–æ–¥—Ö–æ–¥—ã."
            ],
        },
        "down": {
            "summary": "–í—ã—Ä—É—á–∫–∞ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ —Å–Ω–∏–∑–∏–ª–∞—Å—å –Ω–∞ {delta_pct_pct:.1f}% (—Å {start} –¥–æ {current}).",
            "actions": [
                "–†–∞–∑–±–µ—Ä–∏—Ç–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç –∏ –ø—Ä–∏—á–∏–Ω—ã –ø–∞–¥–µ–Ω–∏—è —Å–ø—Ä–æ—Å–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º.",
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–∞–º–ø–∞–Ω–∏—é –ø–æ –∞–∫—Ç–∏–≤–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–¥–∞–∂ –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ—Ç–∏–≤–∞—Ü–∏—é –ø–µ—Ä—Å–æ–Ω–∞–ª–∞."
            ],
        },
        "flat": {
            "summary": "–í—ã—Ä—É—á–∫–∞ –¥–µ—Ä–∂–∏—Ç—Å—è –æ–∫–æ–ª–æ {current}; –∑–Ω–∞—á–∏–º—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç.",
            "actions": [
                "–ò—â–∏—Ç–µ —Ç–æ—á–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞: —Å–ø–µ—Ü–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, cross-sell.",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ—Ç –ª–∏ —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ—Å–∞–¥–æ–∫ –ø–æ –º–∞—Ä–∂–µ –∏–ª–∏ —Ä–∏—Å–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∏–ª–∏–∞–ª–∞—Ö."
            ],
        },
    },
}


SCENARIO_CONFIGS: Dict[str, Dict[str, Any]] = {
    "–ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å": {
        "delta_threshold": 0.03,
        "delta_strong": 0.08,
        "yoy_threshold": 0.05,
        "risk_high": 12.0,
        "illiquid_high": 30.0,
        "markup_drop": -0.03,
        "action_suffix": {
            "up": "–ó–∞–∫—Ä–µ–ø–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏ –Ω–∞ –ø–ª–∞–Ω—ë—Ä–∫–µ.",
            "down": "–ù–∞–∑–Ω–∞—á—å—Ç–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å —Å—Ä–æ–∫–æ–≤.",
            "flat": "–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è."
        },
        "intensity": {
            "strong_up": " (–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–æ—Å—Ç)",
            "strong_down": " (—Ä–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ)"
        }
    },
    "–ê–Ω—Ç–∏–∫—Ä–∏–∑–∏—Å": {
        "delta_threshold": 0.02,
        "delta_strong": 0.05,
        "yoy_threshold": 0.03,
        "risk_high": 10.0,
        "illiquid_high": 25.0,
        "markup_drop": -0.02,
        "action_suffix": {
            "up": "–£–¥–µ—Ä–∂–∏—Ç–µ —Ç—Ä–µ–Ω–¥: –∑–∞–∫—Ä–µ–ø–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ –¥–æ–±–∞–≤—å—Ç–µ –∫–æ–Ω—Ç—Ä–æ–ª—å.",
            "down": "–°—Ä–æ—á–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Å–æ–≥–ª–∞—Å—É–π—Ç–µ –µ—ë —Å —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º.",
            "flat": "–ò—â–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è quick wins –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–≤–∞–ª–æ–≤."
        },
        "intensity": {
            "strong_up": " (—Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —à–∞–Ω—Å)",
            "strong_down": " (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ ‚Äî –Ω—É–∂–µ–Ω –∫—Ä–∏–∑–∏—Å–Ω—ã–π –ø–ª–∞–Ω)"
        }
    },
    "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ": {
        "delta_threshold": 0.04,
        "delta_strong": 0.10,
        "yoy_threshold": 0.07,
        "risk_high": 12.0,
        "illiquid_high": 28.0,
        "markup_drop": -0.04,
        "action_suffix": {
            "up": "–í–∫–ª—é—á–∏—Ç–µ —ç—Ç–æ—Ç —Ä–æ—Å—Ç –≤ –ø–ª–∞–Ω—ã –∏ –æ–±–µ—Å–ø–µ—á—å—Ç–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ.",
            "down": "–ó–∞–∫–ª–∞–¥—ã–≤–∞–π—Ç–µ –≤ –ø–ª–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏.",
            "flat": "–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Ç–æ—á–∫–∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏ –∑–∞–ø–ª–∞–Ω–∏—Ä—É–π—Ç–µ –ø–∏–ª–æ—Ç—ã –¥–ª—è —Ä–æ—Å—Ç–∞."
        },
        "intensity": {
            "strong_up": " (–∑–Ω–∞—á–∏–º—ã–π —Ä–æ—Å—Ç ‚Äî –∑–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é)",
            "strong_down": " (—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ ‚Äî –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –ø–ª–∞–Ω)"
        }
    }
}


SCENARIO_DESCRIPTIONS = {
    "–ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å": "–°–ª–µ–¥–∏–º –∑–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏ –∏ –±—ã—Å—Ç—Ä–æ —É—Å—Ç—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.",
    "–ê–Ω—Ç–∏–∫—Ä–∏–∑–∏—Å": "–§–æ–∫—É—Å –Ω–∞ —Ä–∏—Å–∫–∞—Ö –∏ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π.",
    "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ": "–û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞ –∏ –∑–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –≤ –ø–ª–∞–Ω—ã." 
}


@dataclass
class PageContext:
    mode: str  # "single" –∏–ª–∏ "compare"
    df_current: pd.DataFrame
    df_previous: pd.DataFrame | None
    agg_current: pd.DataFrame
    regions: List[str]
    months_range: List[str]
    months_available: List[str]
    scenario_name: str
    year_current: int
    year_previous: int | None
    color_map: Dict[str, str]
    strict_mode: bool
    thresholds: Dict[str, float] | None = None


def _calc_pct_change(new: float | None, old: float | None) -> float | None:
    if new is None or old is None or abs(old) < 1e-9:
        return None
    return (new - old) / old


@st.cache_data(show_spinner=False, max_entries=256)
def compute_metric_stats(df_source: pd.DataFrame, regions: List[str], months_range: List[str], metric: str) -> Dict[str, Any]:
    series = _monthly_series_for_metric(df_source, regions, metric, months_range)
    if series is None:
        series = pd.Series(dtype=float)
    else:
        series = pd.to_numeric(series, errors="coerce")
    series = series.dropna()
    total = period_value_from_itogo(df_source, regions, metric, months_range)
    start = float(series.iloc[0]) if not series.empty else None
    current = float(series.iloc[-1]) if not series.empty else None
    delta_abs = None
    delta_pct = None
    if start is not None and current is not None:
        delta_abs = current - start
        if abs(start) > 1e-9:
            delta_pct = delta_abs / start

    current_month = str(series.index[-1]) if not series.empty else None
    previous_month = str(series.index[-2]) if len(series) >= 2 else None
    mom_pct = None
    if len(series) >= 2 and series.iloc[-2] != 0:
        mom_pct = _calc_pct_change(series.iloc[-1], series.iloc[-2])
    qoq_pct = None
    if len(series) >= 4 and series.iloc[-4] != 0:
        qoq_pct = _calc_pct_change(series.iloc[-1], series.iloc[-4])

    extrema = {}
    if not series.empty:
        if metric in METRICS_SMALLER_IS_BETTER:
            best_idx = series.idxmin(); worst_idx = series.idxmax()
        else:
            best_idx = series.idxmax(); worst_idx = series.idxmin()
        extrema = {
            "best": {"month": best_idx, "value": float(series.loc[best_idx])},
            "worst": {"month": worst_idx, "value": float(series.loc[worst_idx])}
        }

    # –≥–æ–¥-–∫-–≥–æ–¥—É –Ω–∞ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü
    if len(months_range) >= 1:
        try:
            prev_year = df_source["–ì–æ–¥"].dropna().astype(int).unique()
        except Exception:
            prev_year = np.array([])
        prev_total = None
        for yr in prev_year:
            mask = df_source["–ì–æ–¥"] == yr
            if mask.any():
                prev_total = period_value_from_itogo(df_source[mask], regions, metric, months_range)
                break
    else:
        prev_total = None
    yoy_pct = _calc_pct_change(total, prev_total) if prev_total is not None else None

    if metric in METRICS_LAST and total is not None:
        try:
            current = float(total)
        except (TypeError, ValueError):
            pass

    return {
        "series": series,
        "total": total,
        "start": start,
        "current": current,
        "delta_abs": delta_abs,
        "delta_pct": delta_pct,
        "prev_total": prev_total,
        "yoy_pct": yoy_pct,
        "extrema": extrema,
        "current_month": current_month,
        "previous_month": previous_month,
        "mom_pct": mom_pct,
        "qoq_pct": qoq_pct,
    }


def _interpret_metric(metric: str, stats: Dict[str, Any], scenario_conf: Dict[str, Any], period_start: str,
                      stats_map: Dict[str, Dict[str, Any]], months_range: List[str],
                      baseline_stats: Dict[str, Any] | None = None) -> tuple[str | None, List[str], List[str], str]:
    current = stats.get("current")
    start = stats.get("start")
    delta_abs = stats.get("delta_abs")
    delta_pct = stats.get("delta_pct")
    total = stats.get("total")
    baseline_total = baseline_stats.get("total") if baseline_stats else None
    yoy_pct = _calc_pct_change(total, baseline_total)

    current_str = _format_value_for_metric(metric, current) if current is not None else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    start_str = _format_value_for_metric(metric, start) if start is not None else current_str
    delta_abs_str = _format_delta(metric, delta_abs) if delta_abs is not None else "0"
    delta_pct_pct = (delta_pct * 100) if delta_pct is not None else 0.0
    yoy_pct_pct = (yoy_pct * 100) if yoy_pct is not None else None

    format_params = {
        "start": start_str,
        "current": current_str,
        "delta_abs": delta_abs_str,
        "delta_pct_pct": abs(delta_pct_pct),
        "period_start": period_start,
        "metric": metric,
    }

    status = evaluate_metric_status(
        metric,
        current,
        scenario_conf,
        delta_pct=delta_pct,
        yoy_pct=yoy_pct,
    )

    guide = METRIC_GUIDE.get(metric, {})
    base_status = status
    if status in {"risk_high", "margin_drop"}:
        base_status = "down"
    if status == "no_data":
        base_status = "flat"
    if status not in {"strong_up", "up", "strong_down", "down"}:
        # fall back to delta-based buckets for guide selection
        if delta_pct is not None:
            if delta_pct >= scenario_conf["delta_threshold"]:
                base_status = "up"
            elif delta_pct <= -scenario_conf["delta_threshold"]:
                base_status = "down"
            else:
                base_status = "flat"

    entry = guide.get(status) or guide.get(base_status) or guide.get("flat")
    summary: str | None = None
    actions: List[str] = []
    highlights: List[str] = []
    if entry:
        summary_template = entry.get("summary")
        if summary_template:
            summary = summary_template.format(**format_params)
            intensity = scenario_conf["intensity"].get(status)
            if intensity:
                summary += intensity
        action_templates = entry.get("actions", [])
        for template in action_templates:
            actions.append(template.format(**format_params))

    if delta_pct is None and summary is None:
        summary = f"{metric}: —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å {current_str}."

    if delta_pct is not None and abs(delta_pct) < scenario_conf["delta_threshold"] and summary:
        summary += " (–±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)"

    if yoy_pct is not None and summary:
        if abs(yoy_pct) >= scenario_conf["yoy_threshold"]:
            summary += f" –ì–æ–¥ –∫ –≥–æ–¥—É: {yoy_pct_pct:+.1f}%."

    scenario_suffix = scenario_conf["action_suffix"].get(base_status)
    if scenario_suffix:
        actions.append(scenario_suffix)

    extrema = stats.get("extrema") or {}
    best = extrema.get("best")
    worst = extrema.get("worst")
    if best and best.get("value") is not None:
        highlights.append(f"–ú–∞–∫—Å–∏–º—É–º: {best['month']} ‚Äî {_format_value_for_metric(metric, best['value'])}.")
    if worst and worst.get("value") is not None and (not best or worst['month'] != best['month']):
        highlights.append(f"–ú–∏–Ω–∏–º—É–º: {worst['month']} ‚Äî {_format_value_for_metric(metric, worst['value'])}.")

    if delta_pct is not None and months_range and start is not None and current is not None:
        first_month = months_range[0]
        last_month = months_range[-1]
        direction = "–≤—ã—Ä–æ—Å" if delta_pct > 0 else ("—Å–Ω–∏–∑–∏–ª—Å—è" if delta_pct < 0 else "–±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        highlights.append(
            f"{metric}: {direction} —Å {_format_value_for_metric(metric, start)} –≤ {first_month} –¥–æ {_format_value_for_metric(metric, current)} –≤ {last_month}."
        )

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–Ω—Ç—Ä–º–µ—Ä—ã –ø–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º –º–µ—Ç—Ä–∏–∫–∞–º
    markup_stats = stats_map.get(Metrics.MARKUP_PCT.value)
    if metric == Metrics.REVENUE.value and markup_stats:
        markup_delta = markup_stats.get("delta_pct")
        if markup_delta is not None and markup_delta < scenario_conf["markup_drop"]:
            summary = (summary or "") + " –ù–∞—Ü–µ–Ω–∫–∞ —Å–Ω–∏–∂–∞–µ—Ç—Å—è ‚Äî —Ä–æ—Å—Ç –≤—ã—Ä—É—á–∫–∏ —Å—ä–µ–¥–∞–µ—Ç –º–∞—Ä–∂—É."

    return summary, actions, highlights, status


def build_metric_recommendations(stats_map: Dict[str, Dict[str, Any]], scenario_name: str, months_range: List[str], baseline_map: Dict[str, Dict[str, Any]] | None = None) -> tuple[List[str], List[str]]:
    config = SCENARIO_CONFIGS[scenario_name]
    period_start = months_range[0] if months_range else "–Ω–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞"
    summary_lines: List[str] = []
    action_lines: List[str] = []
    for metric in KEY_DECISION_METRICS:
        stats = stats_map.get(metric)
        if not stats:
            continue
        baseline_stats = baseline_map.get(metric) if baseline_map else None
        summary, actions, highlights, _ = _interpret_metric(metric, stats, config, period_start, stats_map, months_range, baseline_stats)
        if summary:
            summary_lines.append(summary)
        action_lines.extend(actions)
        summary_lines.extend(highlights)

    risk_stats = stats_map.get(Metrics.RISK_SHARE.value)
    if risk_stats and risk_stats.get("current") is not None:
        risk_val = float(risk_stats["current"])
        if risk_val > config["risk_high"]:
            summary_lines.append(f"–†–∏—Å–∫: –¥–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞ {risk_val:.1f}% ‚Äî –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ {config['risk_high']}%.")
            action_lines.append("–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø—Ä–µ—Å—Å-–∞—É–¥–∏—Ç –æ—Ü–µ–Ω–∫–∏ –∑–∞–ª–æ–≥–æ–≤ –∏ –æ–≥—Ä–∞–Ω–∏—á—å—Ç–µ –≤—ã–¥–∞—á–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.")
        else:
            baseline_risk = baseline_map.get(Metrics.RISK_SHARE.value)["current"] if baseline_map and baseline_map.get(Metrics.RISK_SHARE.value) else None
            if baseline_risk and risk_val < float(baseline_risk) - 1:
                summary_lines.append(f"–†–∏—Å–∫ —Å–Ω–∏–∂–∞–µ—Ç—Å—è: –¥–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞ {risk_val:.1f}% (–±—ã–ª–æ {float(baseline_risk):.1f}%).")

    illiquid_stats = stats_map.get(Metrics.ILLIQUID_BY_VALUE_PCT.value)
    if illiquid_stats and illiquid_stats.get("current") is not None:
        illiquid_val = float(illiquid_stats["current"])
        if illiquid_val > config["illiquid_high"]:
            summary_lines.append(f"–ù–µ–ª–∏–∫–≤–∏–¥: {illiquid_val:.1f}% ‚Äî –≤—ã—à–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ {config['illiquid_high']}%.")
            action_lines.append("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –Ω–µ–ª–∏–∫–≤–∏–¥–∞ –∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ –∑–∞–∫—É–ø–æ—á–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É.")

    markup_stats = stats_map.get(Metrics.MARKUP_PCT.value)
    if markup_stats and markup_stats.get("current") is not None and markup_stats.get("delta_pct") is not None:
        if markup_stats["delta_pct"] < config["markup_drop"]:
            markup_summary = f"–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–∞–¥–∞–µ—Ç –¥–æ {_format_value_for_metric(Metrics.MARKUP_PCT.value, markup_stats['current'])}."
            if all("–º–∞—Ä–∂" not in line.lower() for line in summary_lines):
                summary_lines.append(markup_summary)
            action_lines.append("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–∏–¥–∫–∏, –∫–æ–Ω—Ç—Ä–æ–ª—å –æ—Ü–µ–Ω–æ–∫ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—é –ø—Ä–æ–¥–∞–≤—Ü–æ–≤.")

    return summary_lines, action_lines


STATUS_SEVERITY = {
    "risk_high": 0,
    "strong_down": 1,
    "margin_drop": 2,
    "down": 3,
    "flat": 4,
    "up": 5,
    "strong_up": 6,
    "no_data": 7,
}

STATUS_LABELS = {
    "risk_high": "üö® –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫",
    "strong_down": "üî¥ –†–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ",
    "margin_drop": "üü† –ü–∞–¥–µ–Ω–∏–µ –º–∞—Ä–∂–∏",
    "down": "üü† –°–Ω–∏–∂–µ–Ω–∏–µ",
    "flat": "‚ö™Ô∏è –°—Ç–∞–±–∏–ª—å–Ω–æ",
    "up": "üü¢ –†–æ—Å—Ç",
    "strong_up": "üü¢ –†–æ—Å—Ç+",
    "no_data": "‚öôÔ∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö",
}

STATUS_ICONS = {
    "risk_high": "üö®",
    "strong_down": "üî¥",
    "margin_drop": "üü†",
    "down": "üü†",
    "flat": "‚ö™Ô∏è",
    "up": "üü¢",
    "strong_up": "üü¢",
    "no_data": "‚öôÔ∏è",
}

STATUS_COLORS = {
    "risk_high": "#b91c1c",
    "strong_down": "#dc2626",
    "margin_drop": "#f97316",
    "down": "#f59e0b",
    "flat": "#6b7280",
    "up": "#10b981",
    "strong_up": "#047857",
    "no_data": "#94a3b8",
}


def evaluate_metric_status(
    metric: str,
    value: float | None,
    config: Dict[str, Any],
    *,
    delta_pct: float | None = None,
    yoy_pct: float | None = None,
) -> str:
    if value is None or pd.isna(value):
        return "no_data"

    if metric == Metrics.RISK_SHARE.value and value > config["risk_high"]:
        return "risk_high"

    if metric == Metrics.ILLIQUID_BY_VALUE_PCT.value and value > config["illiquid_high"]:
        return "risk_high"

    if metric == Metrics.MARKUP_PCT.value:
        if delta_pct is not None and delta_pct < config["markup_drop"]:
            return "margin_drop"
        if yoy_pct is not None and yoy_pct < config["markup_drop"]:
            return "margin_drop"

    candidate = "flat"

    def classify(delta: float) -> str:
        if delta >= config["delta_strong"]:
            return "strong_up"
        if delta >= config["delta_threshold"]:
            return "up"
        if delta <= -config["delta_strong"]:
            return "strong_down"
        if delta <= -config["delta_threshold"]:
            return "down"
        return "flat"

    if delta_pct is not None:
        candidate = classify(delta_pct)

    if candidate in {"flat", "up", "strong_up"} and yoy_pct is not None:
        yoy_candidate = classify(yoy_pct)
        if STATUS_SEVERITY.get(yoy_candidate, 4) < STATUS_SEVERITY.get(candidate, 4):
            candidate = yoy_candidate

    return candidate


def compute_alert_streak(metric: str, stats: Dict[str, Any], config: Dict[str, Any]) -> int:
    series = stats.get("series")
    if series is None or series.empty:
        return 0
    values = pd.to_numeric(series, errors="coerce").dropna()
    if values.empty:
        return 0
    streak = 0
    for idx in range(len(values) - 1, -1, -1):
        current = values.iloc[idx]
        prev = values.iloc[idx - 1] if idx > 0 else None
        delta_pct = None
        if prev is not None and prev != 0:
            delta_pct = (current - prev) / prev
        status = evaluate_metric_status(
            metric,
            current,
            config,
            delta_pct=delta_pct,
            yoy_pct=None,
        )
        if STATUS_SEVERITY.get(status, 4) > STATUS_SEVERITY["down"]:
            break
        streak += 1
    return streak


def forecast_next_value(stats: Dict[str, Any]) -> float | None:
    series = stats.get("series")
    if series is None or series.empty:
        return None
    values = pd.to_numeric(series, errors="coerce").dropna()
    if values.empty:
        return None
    if len(values) == 1:
        return float(values.iloc[-1])
    recent = values.iloc[-3:] if len(values) >= 3 else values
    deltas = recent.diff().dropna()
    if deltas.empty:
        delta = 0.0
    else:
        delta = float(deltas.mean())
    return float(values.iloc[-1] + delta)


def _format_forecast(metric: str, value: float | None) -> str:
    if value is None or pd.isna(value):
        return "‚Äî"
    if is_percent_metric(metric):
        return f"{value:.2f}%"
    if "—Ä—É–±" in metric:
        return f"{value:,.0f} ‚ÇΩ".replace(",", " ")
    if "–¥–Ω–µ–π" in metric:
        return f"{value:.1f} –¥–Ω."
    return f"{value:,.0f}".replace(",", " ")


def build_metric_dashboard(
    stats_current: Dict[str, Dict[str, Any]],
    stats_previous: Dict[str, Dict[str, Any]] | None,
    scenario_name: str,
    months_range: List[str],
) -> tuple[pd.DataFrame, List[str], List[Dict[str, Any]]]:
    scenario_conf = SCENARIO_CONFIGS[scenario_name]
    metrics_sequence = list(stats_current.keys())
    period_start = months_range[0] if months_range else "–Ω–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞"
    rows: List[Dict[str, Any]] = []
    priority_actions: List[str] = []
    alerts: List[Dict[str, Any]] = []

    for metric in metrics_sequence:
        stats = stats_current.get(metric)
        if not stats:
            continue
        baseline_stats = stats_previous.get(metric) if stats_previous else None
        summary, actions, highlights, status = _interpret_metric(
            metric,
            stats,
            scenario_conf,
            period_start,
            stats_current,
            months_range,
            baseline_stats,
        )

        label = STATUS_LABELS.get(status, STATUS_LABELS["flat"])
        severity = STATUS_SEVERITY.get(status, STATUS_SEVERITY["flat"])

        delta_abs = stats.get("delta_abs")
        delta_pct = stats.get("delta_pct")
        if delta_abs is not None:
            delta_text = _format_delta(metric, float(delta_abs))
            if delta_pct is not None:
                delta_text += f" ({delta_pct * 100:+.1f}%)"
        else:
            delta_text = "‚Äî"

        yoy_pct = stats.get("yoy_pct")
        yoy_text = f"{yoy_pct * 100:+.1f}%" if yoy_pct is not None else "‚Äî"

        current_val = stats.get("current")
        current_text = _format_value_for_metric(metric, current_val)
        comment = summary or (highlights[0] if highlights else "‚Äî")
        recommendation = actions[0] if actions else "‚Äî"

        streak = compute_alert_streak(metric, stats, scenario_conf)
        streak_text = str(streak) if streak > 0 else "‚Äî"

        forecast_val = forecast_next_value(stats)
        forecast_text = _format_forecast(metric, forecast_val)

        rows.append(
            {
                "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": metric,
                "–°—Ç–∞—Ç—É—Å": label,
                "–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å": current_text,
                "Œî —Å –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞": delta_text,
                "Œî –∫ –ø—Ä–æ—à–ª–æ–º—É –≥–æ–¥—É": yoy_text,
                "–°—Ç—Ä–∏–∫ —Ç—Ä–µ–≤–æ–≥–∏ (–º–µ—Å.)": streak_text,
                "–ü—Ä–æ–≥–Ω–æ–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞": forecast_text,
                "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": comment,
                "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": recommendation,
                "__severity": severity,
                "__status_code": status,
            }
        )

        if recommendation != "‚Äî" and severity <= STATUS_SEVERITY.get("down", 3):
            icon = STATUS_ICONS.get(status, "‚Ä¢")
            if streak > 1:
                priority_actions.append(f"{icon} {metric}: {recommendation} (—Å—Ç—Ä–∏–∫ {streak})")
            else:
                priority_actions.append(f"{icon} {metric}: {recommendation}")

        series = stats.get("series")
        series_numeric = None
        if series is not None:
            try:
                series_numeric = pd.to_numeric(series, errors="coerce").dropna()
            except Exception:
                series_numeric = None

        alerts.append(
            {
                "metric": metric,
                "status": status,
                "severity": severity,
                "label": label,
                "icon": STATUS_ICONS.get(status, "‚Ä¢"),
                "current_text": current_text,
                "delta_text": delta_text,
                "yoy_text": yoy_text,
                "streak": streak,
                "forecast_text": forecast_text,
                "comment": comment,
                "recommendation": recommendation,
                "series": series_numeric,
            }
        )

    if not rows:
        return pd.DataFrame(), [], alerts

    df_board = pd.DataFrame(rows)
    df_board = df_board.sort_values(["__severity", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"]).reset_index(drop=True)
    df_board = df_board.drop(columns=["__severity", "__status_code"])
    column_order = [
        "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å",
        "–°—Ç–∞—Ç—É—Å",
        "–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å",
        "Œî —Å –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞",
        "Œî –∫ –ø—Ä–æ—à–ª–æ–º—É –≥–æ–¥—É",
        "–°—Ç—Ä–∏–∫ —Ç—Ä–µ–≤–æ–≥–∏ (–º–µ—Å.)",
        "–ü—Ä–æ–≥–Ω–æ–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞",
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è",
    ]
    df_board = df_board[column_order]
    df_board = df_board.fillna("‚Äî")
    alerts.sort(key=lambda item: (item["severity"], item["metric"]))
    return df_board, priority_actions, alerts


def render_executive_summary(
    ctx: PageContext,
    stats_current: Dict[str, Dict[str, Any]],
    stats_previous: Dict[str, Dict[str, Any]] | None,
) -> None:
    st.markdown("### üß≠ Executive summary")
    board, priority_actions, alerts = build_metric_dashboard(stats_current, stats_previous, ctx.scenario_name, ctx.months_range)
    if alerts:
        render_severity_ribbon(alerts)
        render_alert_cards(alerts, max_cards=3)
    if board.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–≤–æ–¥–∫–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º.")
    else:
        st.markdown("#### üìä –¢–∞–±–ª–∏—Ü–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")
        st.dataframe(board, use_container_width=True, hide_index=True)
    if priority_actions:
        _render_plan("–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —à–∞–≥–∏", priority_actions[:5])
    else:
        st.caption("–°–∏–≥–Ω–∞–ª—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –≤ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö.")

def render_tab_summary(
    ctx: PageContext,
    metrics: List[str],
    *,
    title: str,
) -> None:
    stats_current = {
        metric: compute_metric_stats(ctx.df_current, ctx.regions, ctx.months_range, metric)
        for metric in metrics
    }
    stats_previous = None
    if ctx.mode == "compare" and ctx.df_previous is not None:
        stats_previous = {
            metric: compute_metric_stats(ctx.df_previous, ctx.regions, ctx.months_range, metric)
            for metric in metrics
        }
    st.markdown(title)
    board, priority_actions, alerts = build_metric_dashboard(
        stats_current,
        stats_previous,
        ctx.scenario_name,
        ctx.months_range,
    )
    if alerts:
        render_severity_ribbon(alerts, max_items=3)
        render_alert_cards(alerts, max_cards=2)
    if board.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–≤–æ–¥–∫–∏.")
    else:
        st.dataframe(board, use_container_width=True, hide_index=True)
    if priority_actions:
        _render_plan("–í –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å", priority_actions[:5])
    else:
        st.caption("–¢—Ä–µ–≤–æ–∂–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ —ç—Ç–∏–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º –Ω–µ—Ç.")


def _render_alert_sparkline(alert: Dict[str, Any], *, chart_key: str | None = None) -> None:
    series = alert.get("series")
    if series is None or len(series) < 2:
        return
    data = series.tail(6)
    try:
        x_values = [str(x) for x in data.index]
        y_values = data.values.astype(float)
    except Exception:
        return
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=x_values,
        y=y_values,
        mode="lines+markers",
        line=dict(color="#2563eb", width=2),
        marker=dict(size=4),
        fill="tozeroy",
        fillcolor="rgba(37,99,235,0.15)",
        hovertemplate="%{x}: %{y:.2f}<extra></extra>",
    ))
    fig.update_layout(
        height=110,
        margin=dict(l=0, r=0, t=20, b=10),
        showlegend=False,
        template="plotly_white",
    )
    fig.update_xaxes(visible=False)
    fig.update_yaxes(visible=False)
    if chart_key is None:
        metric_slug = _normalize_metric_label(alert.get("metric", "metric"))
        chart_key = f"spark_{metric_slug}_{hash(tuple(x_values)) & 0xFFFF}"
    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False}, key=chart_key)


def render_severity_ribbon(alerts: List[Dict[str, Any]], *, max_items: int = 4) -> None:
    if not alerts:
        return
    critical = [a for a in alerts if a["severity"] <= STATUS_SEVERITY["down"]]
    shortlisted = critical or alerts
    shortlisted = sorted(shortlisted, key=lambda a: (a["severity"], a["metric"]))[:max_items]
    cols = st.columns(len(shortlisted))
    for col, alert in zip(cols, shortlisted):
        color = STATUS_COLORS.get(alert["status"], "#6b7280")
        chip = (
            f"<div style='background:{color};color:white;padding:6px 12px;"
            "border-radius:999px;font-weight:600;text-align:center;'>"
            f"{alert['icon']} {alert['metric']}</div>"
        )
        col.markdown(chip, unsafe_allow_html=True)
        subtitle = alert["comment"]
        if (not subtitle) or subtitle == "‚Äî":
            subtitle = alert["recommendation"]
        if subtitle and subtitle != "‚Äî":
            if len(subtitle) > 140:
                subtitle = subtitle[:137] + "‚Ä¶"
            col.caption(subtitle)


def render_alert_cards(alerts: List[Dict[str, Any]], *, max_cards: int = 3) -> None:
    if not alerts:
        st.caption("–¢—Ä–µ–≤–æ–∂–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç.")
        return
    critical = [a for a in alerts if a["severity"] <= STATUS_SEVERITY["down"]]
    cards = critical[:max_cards] if critical else alerts[:max_cards]
    for idx, alert in enumerate(cards):
        color = STATUS_COLORS.get(alert["status"], "#6b7280")
        with st.container():
            st.markdown(
                f"<div style='padding:14px 18px;border:1px solid rgba(148,163,184,0.35);"
                f"border-radius:16px;margin-bottom:8px;background:rgba(148,163,184,0.05);'>"
                f"<h4 style='margin:0;color:{color};'>{alert['icon']} {alert['metric']}</h4>",
                unsafe_allow_html=True,
            )

            metrics_cols = st.columns(4)
            metrics_cols[0].markdown(
                f"**–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å**<br>{alert['current_text']}",
                unsafe_allow_html=True,
            )
            metrics_cols[1].markdown(
                f"**Œî –ø–µ—Ä–∏–æ–¥–∞**<br>{alert['delta_text']}",
                unsafe_allow_html=True,
            )
            metrics_cols[2].markdown(
                f"**Œî –∫ –ø—Ä–æ—à–ª–æ–º—É –≥–æ–¥—É**<br>{alert['yoy_text']}",
                unsafe_allow_html=True,
            )
            metrics_cols[3].markdown(
                f"**–ü—Ä–æ–≥–Ω–æ–∑**<br>{alert['forecast_text']}",
                unsafe_allow_html=True,
            )

            if alert.get("streak", 0) > 1:
                st.markdown(
                    f"<span style='color:{color}; font-weight:600;'>‚ö†Ô∏è –£–∂–µ {alert['streak']} –º–µ—Å. –ø–æ–¥—Ä—è–¥ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞.</span>",
                    unsafe_allow_html=True,
                )

            if alert["comment"] and alert["comment"] != "‚Äî":
                st.markdown(f"**–ß—Ç–æ –≤–∏–¥–Ω–æ:** {alert['comment']}")
            if alert["recommendation"] and alert["recommendation"] != "‚Äî":
                st.markdown(f"**–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å:** {alert['recommendation']}")
            if alert["forecast_text"] and alert["forecast_text"] != "‚Äî":
                st.caption(f"–ï—Å–ª–∏ —Ç—Ä–µ–Ω–¥ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è, –≤ —Å–ª–µ–¥—É—é—â–µ–º –ø–µ—Ä–∏–æ–¥–µ –æ–∂–∏–¥–∞–µ–º {alert['forecast_text']}.")

            spark_key = f"spark_card_{uuid4()}"
            _render_alert_sparkline(alert, chart_key=spark_key)

            st.markdown("</div>", unsafe_allow_html=True)


def render_correlation_block(df_source: pd.DataFrame, regions: List[str], months_range: List[str], *, default_metrics: List[str]) -> None:
    st.subheader("üìà –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    available = sorted({m for m in df_source["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique() if m in ACCEPTED_METRICS_CANONICAL and m not in HIDDEN_METRICS})
    if not available:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.")
        return
    defaults = [m for m in default_metrics if m in available] or available[: min(len(available), 4)]
    selected = st.multiselect(
        "–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π",
        options=available,
        default=defaults,
        help="–û—Ç–º–µ—Ç—å—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π."
    )
    if not selected:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–µ—Ç—Ä–∏–∫—É.")
        return
    matrix = _build_metric_matrix(df_source, regions, months_range, selected)
    if matrix.empty or matrix.shape[1] < 2:
        st.info("–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
        return
    corr = matrix.corr()
    fig = go.Figure(data=go.Heatmap(
        z=corr.values,
        x=corr.columns,
        y=corr.index,
        colorscale="RdBu",
        zmid=0,
        colorbar=dict(title="r"),
    ))
    fig.update_layout(margin=dict(l=40, r=40, t=40, b=40), height=420)
    st.plotly_chart(fig, use_container_width=True, key="corr_heatmap")

    pairs: List[Tuple[str, str, float]] = []
    cols = corr.columns
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):
            val = corr.iloc[i, j]
            if pd.isna(val):
                continue
            pairs.append((cols[i], cols[j], float(val)))
    if not pairs:
        return
    pairs.sort(key=lambda item: abs(item[2]), reverse=True)
    top_pairs = pairs[:5]
    bullets = []
    for left, right, value in top_pairs:
        relation = "–ø—Ä—è–º–∞—è" if value > 0 else "–æ–±—Ä–∞—Ç–Ω–∞—è"
        bullets.append(f"- **{left} ‚Üî {right}**: {value:+.2f} ({relation} —Å–≤—è–∑—å)")
    st.markdown("**–°–∏–ª—å–Ω–µ–π—à–∏–µ —Å–≤—è–∑–∏:**\n" + "\n".join(bullets))


def render_revenue_waterfall(ctx: PageContext) -> None:
    st.subheader("üíß –í–∫–ª–∞–¥ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏")
    if len(ctx.months_range) < 2:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º –¥–≤–∞ –º–µ—Å—è—Ü–∞, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –¥–∏–Ω–∞–º–∏–∫—É.")
        return
    start_month, end_month = ctx.months_range[0], ctx.months_range[-1]
    subset = ctx.df_current[
        (ctx.df_current["–†–µ–≥–∏–æ–Ω"].isin(ctx.regions)) &
        (ctx.df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == Metrics.REVENUE.value) &
        (ctx.df_current["–ú–µ—Å—è—Ü"].astype(str).isin([start_month, end_month]))
    ]
    if subset.empty:
        subset = ctx.df_current[
            (ctx.df_current["–†–µ–≥–∏–æ–Ω"].isin(ctx.regions)) &
            (ctx.df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == Metrics.REVENUE.value) &
            (ctx.df_current["–ú–µ—Å—è—Ü"].astype(str).isin(ctx.months_range))
        ]
        if subset.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã—Ä—É—á–∫–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã.")
            return
    grouped = (subset.groupby(["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                     .sum()
                     .unstack(fill_value=0))
    available_months = [m for m in ctx.months_range if m in grouped.columns]
    if len(available_months) < 2:
        fallback_months = sorted_months_safe(grouped.columns)
        if len(fallback_months) < 2:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Å—è—Ü–∞–º.")
            return
        available_months = [fallback_months[0], fallback_months[-1]]
    start_month, end_month = available_months[0], available_months[-1]
    start_series = grouped.get(start_month, pd.Series(dtype=float)).fillna(0.0)
    end_series = grouped.get(end_month, pd.Series(dtype=float)).fillna(0.0)
    if start_series.empty or end_series.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Å—è—Ü–∞–º.")
        return
    start_total = float(start_series.sum())
    end_total = float(end_series.sum())
    delta = (end_series - start_series).sort_values(key=lambda x: -x.abs())
    if np.isclose(start_total, end_total) and delta.abs().sum() < 1e-6:
        st.caption("–°—É–º–º–∞—Ä–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å ‚Äî –≤–æ–¥–æ–ø–∞–¥ –æ–∫–∞–∂–µ—Ç—Å—è –ø–ª–æ—Å–∫–∏–º.")
        return
    measures = ["absolute"] + ["relative"] * len(delta) + ["total"]
    x_axis = ["–ù–∞—á–∞–ª–æ"] + delta.index.tolist() + ["–ö–æ–Ω–µ—Ü"]
    y_axis = [start_total] + delta.values.tolist() + [end_total]
    fig = go.Figure(go.Waterfall(
        orientation="v",
        measure=measures,
        x=x_axis,
        y=y_axis,
        connector={"line": {"color": "rgba(148,163,184,0.35)"}},
        decreasing={"marker": {"color": "#ef4444"}},
        increasing={"marker": {"color": "#10b981"}},
        totals={"marker": {"color": "#2563eb"}}
    ))
    fig.update_layout(height=420, margin=dict(l=40, r=40, t=40, b=40), showlegend=False)
    st.plotly_chart(fig, use_container_width=True, key="revenue_waterfall")
    st.caption(f"–°—Ç–∞—Ä—Ç: {format_rub(start_total)} ‚Üí –ö–æ–Ω–µ—Ü: {format_rub(end_total)}.")


def sales_intelligence_block(ctx: PageContext, thresholds: Dict[str, float] | None = None) -> None:
    st.subheader("üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç –ø—Ä–æ–¥–∞–∂ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
    st.caption("–°–≤–æ–¥–Ω—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –≤—ã—Ä—É—á–∫—É, –º–∞—Ä–∂—É –∏ —Ä–∏—Å–∫ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º: —Å–≤–µ—Ä—Ö—É —Ç–∞–±–ª–∏—Ü–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –Ω–∏–∂–µ ‚Äî –∫–∞—Ä—Ç–∞ –Ω–∞—Ü–µ–Ω–∫–∞ ‚Üî —Ä–∏—Å–∫.")
    revenue_map = period_values_by_region_from_itogo(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    if not revenue_map:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã—Ä—É—á–∫–µ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞.")
        return
    markup_map = period_values_by_region_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    risk_map = period_values_by_region_from_itogo(ctx.df_current, ctx.regions, Metrics.RISK_SHARE.value, ctx.months_range)

    rows: list[dict[str, float | str]] = []
    for region, value in revenue_map.items():
        if value is None or pd.isna(value):
            continue
        rows.append({
            "–†–µ–≥–∏–æ–Ω": region,
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": float(value),
            "–ù–∞—Ü–µ–Ω–∫–∞, %": float(markup_map.get(region)) if markup_map and markup_map.get(region) not in (None, np.nan) else np.nan,
            "–†–∏—Å–∫, %": float(risk_map.get(region)) if risk_map and risk_map.get(region) not in (None, np.nan) else np.nan,
        })
    if not rows:
        st.info("–ù–µ—Ç —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –≤—ã—Ä—É—á–∫–µ.")
        return

    df = pd.DataFrame(rows).sort_values("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", ascending=False)
    total_revenue = float(df["–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"].sum())
    if total_revenue > 0:
        df["–î–æ–ª—è, %"] = (df["–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"] / total_revenue) * 100
    if df["–ù–∞—Ü–µ–Ω–∫–∞, %"].notna().any():
        mean_markup = float(df["–ù–∞—Ü–µ–Ω–∫–∞, %"].dropna().mean())
        df["Œî –Ω–∞—Ü–µ–Ω–∫–∏ –∫ —Å—Ä–µ–¥–Ω."] = df["–ù–∞—Ü–µ–Ω–∫–∞, %"] - mean_markup
    if thresholds:
        df["–°–∏–≥–Ω–∞–ª"] = ""
        min_markup = thresholds.get("min_markup")
        max_risk = thresholds.get("max_risk")
        for idx, row in df.iterrows():
            notes: List[str] = []
            if min_markup is not None and not pd.isna(row.get("–ù–∞—Ü–µ–Ω–∫–∞, %")) and row["–ù–∞—Ü–µ–Ω–∫–∞, %"] < min_markup:
                notes.append("‚¨áÔ∏é –Ω–∞—Ü–µ–Ω–∫–∞")
            if max_risk is not None and not pd.isna(row.get("–†–∏—Å–∫, %")) and row["–†–∏—Å–∫, %"] > max_risk:
                notes.append("‚ö†Ô∏è —Ä–∏—Å–∫")
            if notes:
                df.at[idx, "–°–∏–≥–Ω–∞–ª"] = ", ".join(notes)
    else:
        df["–°–∏–≥–Ω–∞–ª"] = ""
    column_config = {
        "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": st.column_config.NumberColumn("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", format="%.0f"),
        "–ù–∞—Ü–µ–Ω–∫–∞, %": st.column_config.NumberColumn("–ù–∞—Ü–µ–Ω–∫–∞, %", format="%.2f"),
        "–†–∏—Å–∫, %": st.column_config.NumberColumn("–†–∏—Å–∫, %", format="%.2f"),
    }
    if "–î–æ–ª—è, %" in df.columns:
        column_config["–î–æ–ª—è, %"] = st.column_config.NumberColumn("–î–æ–ª—è –æ—Ç –∏—Ç–æ–≥–∞, %", format="%.1f%%")
    if "Œî –Ω–∞—Ü–µ–Ω–∫–∏ –∫ —Å—Ä–µ–¥–Ω." in df.columns:
        column_config["Œî –Ω–∞—Ü–µ–Ω–∫–∏ –∫ —Å—Ä–µ–¥–Ω."] = st.column_config.NumberColumn("Œî –Ω–∞—Ü–µ–Ω–∫–∏ –∫ —Å—Ä–µ–¥–Ω., –ø.–ø.", format="%.2f")
    if "–°–∏–≥–Ω–∞–ª" in df.columns:
        column_config["–°–∏–≥–Ω–∞–ª"] = st.column_config.TextColumn("–°–∏–≥–Ω–∞–ª")
    st.dataframe(df, use_container_width=True, hide_index=True, column_config=column_config)

    insights: list[str] = []
    top_row = df.iloc[0]
    if "–î–æ–ª—è, %" in df.columns:
        insights.append(f"–õ–∏–¥–µ—Ä –ø–æ –≤—ã—Ä—É—á–∫–µ ‚Äî {top_row['–†–µ–≥–∏–æ–Ω']}: {format_rub(top_row['–í—ã—Ä—É—á–∫–∞, ‚ÇΩ'])} ({top_row['–î–æ–ª—è, %']:.1f}% –æ—Ç —Å—É–º–º–∞—Ä–Ω–æ–π –≤—ã—Ä—É—á–∫–∏).")
    else:
        insights.append(f"–õ–∏–¥–µ—Ä –ø–æ –≤—ã—Ä—É—á–∫–µ ‚Äî {top_row['–†–µ–≥–∏–æ–Ω']}: {format_rub(top_row['–í—ã—Ä—É—á–∫–∞, ‚ÇΩ'])}.")
    if df["–ù–∞—Ü–µ–Ω–∫–∞, %"].notna().any():
        best_markup = df.sort_values("–ù–∞—Ü–µ–Ω–∫–∞, %", ascending=False).iloc[0]
        delta_markup = best_markup.get("Œî –Ω–∞—Ü–µ–Ω–∫–∏ –∫ —Å—Ä–µ–¥–Ω.")
        extra = "" if pd.isna(delta_markup) else f" (Œî –∫ —Å—Ä–µ–¥–Ω–µ–º—É {delta_markup:+.2f} –ø.–ø.)"
        insights.append(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ ‚Äî {best_markup['–†–µ–≥–∏–æ–Ω']}: {fmt_pct(best_markup['–ù–∞—Ü–µ–Ω–∫–∞, %'])}{extra}.")
    if df["–†–∏—Å–∫, %"].notna().any():
        highest_risk = df.sort_values("–†–∏—Å–∫, %", ascending=False).iloc[0]
        insights.append(f"–°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ —É {highest_risk['–†–µ–≥–∏–æ–Ω']}: {fmt_pct(highest_risk['–†–∏—Å–∫, %'])}.")
    _render_insights("–ì–ª–∞–≤–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è", insights)

    flagged = df[df["–°–∏–≥–Ω–∞–ª"].astype(str).str.len() > 0]
    if not flagged.empty:
        st.markdown("**–°–∏–≥–Ω–∞–ª—ã –ø–æ—Ä–æ–≥–æ–≤:**\n" + "\n".join(f"- {row['–†–µ–≥–∏–æ–Ω']}: {row['–°–∏–≥–Ω–∞–ª']}" for _, row in flagged.iterrows()))

    revenue_series = df.set_index("–†–µ–≥–∏–æ–Ω")["–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"]
    action_lines = _generate_actions_for_series(revenue_series, Metrics.REVENUE.value)
    _render_plan("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã—Ä—É—á–∫–µ", action_lines[:4])

    scatter_df = df.dropna(subset=["–ù–∞—Ü–µ–Ω–∫–∞, %", "–†–∏—Å–∫, %"]).copy()
    if not scatter_df.empty:
        scatter = px.scatter(
            scatter_df,
            x="–ù–∞—Ü–µ–Ω–∫–∞, %",
            y="–†–∏—Å–∫, %",
            size=scatter_df["–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"].clip(lower=0.0),
            color="–†–µ–≥–∏–æ–Ω",
            hover_data={
                "–†–µ–≥–∏–æ–Ω": True,
                "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": ':,.0f',
                "–ù–∞—Ü–µ–Ω–∫–∞, %": ':.2f',
                "–†–∏—Å–∫, %": ':.2f',
                "–î–æ–ª—è, %": ':.1f' if "–î–æ–ª—è, %" in scatter_df else False,
            },
            labels={"–ù–∞—Ü–µ–Ω–∫–∞, %": "–ù–∞—Ü–µ–Ω–∫–∞, %", "–†–∏—Å–∫, %": "–†–∏—Å–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞, %"},
            title="–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∞: –Ω–∞—Ü–µ–Ω–∫–∞ vs —Ä–∏—Å–∫",
        )
        scatter.update_layout(height=360, margin=dict(l=40, r=40, t=60, b=40))
        st.plotly_chart(scatter, use_container_width=True, key="sales_risk_markup")


def render_scenario_simulator(ctx: PageContext) -> None:
    st.subheader("üß™ –°–∏–º—É–ª—è—Ç–æ—Ä ¬´—á—Ç–æ –µ—Å–ª–∏¬ª")
    st.caption("–ü—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å: –≤—ã—Å—Ç–∞–≤–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫ –º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –∫–ª—é—á–µ–≤—ã–µ KPI.")
    col_issue, col_markup, col_risk = st.columns(3)
    delta_issue = col_issue.slider("–í—ã–¥–∞—á–∏ –∑–∞–π–º–æ–≤", -40, 40, 0, step=2, format="%d%%")
    delta_markup = col_markup.slider("–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏", -30, 30, 0, step=1, format="%d%%")
    delta_risk = col_risk.slider("–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞", -30, 30, 0, step=1, format="%d%%")

    def _safe(value: float | None) -> float:
        try:
            return float(value)
        except (TypeError, ValueError):
            return 0.0

    base_issue = _safe(period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.LOAN_ISSUE.value, ctx.months_range))
    base_revenue = _safe(period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range))
    base_markup = _safe(period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range))
    base_risk_share = _safe(period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.RISK_SHARE.value, ctx.months_range))
    base_below = _safe(period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.BELOW_LOAN.value, ctx.months_range))

    factor_issue = 1 + delta_issue / 100
    factor_markup = 1 + delta_markup / 100
    factor_risk = 1 + delta_risk / 100

    new_issue = base_issue * factor_issue
    new_revenue = base_revenue * factor_issue * factor_markup
    new_markup = base_markup * factor_markup
    new_risk_share = max(0.0, base_risk_share * factor_risk)
    new_below = base_below * factor_issue * factor_risk

    m1, m2, m3 = st.columns(3)
    m1.metric("–í—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ (—Ä—É–±)", format_rub(new_issue), delta=format_rub(new_issue - base_issue))
    m2.metric("–í—ã—Ä—É—á–∫–∞ (—Ä—É–±)", format_rub(new_revenue), delta=format_rub(new_revenue - base_revenue))
    m3.metric("–ù–∞—Ü–µ–Ω–∫–∞ / –†–∏—Å–∫", f"{fmt_pct(new_markup)} / {fmt_pct(new_risk_share)}")

    st.caption("–û—Ü–µ–Ω–∫–∞ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–∞—è. –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∫–ª–∞–¥–∫—É ¬´–ü—Ä–æ–≥–Ω–æ–∑¬ª –∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏.")

    values_base = {
        "–í—ã–¥–∞—á–∏": base_issue,
        "–í—ã—Ä—É—á–∫–∞": base_revenue,
        "–ù–∞—Ü–µ–Ω–∫–∞ (%)": base_markup,
        "–†–∏—Å–∫ (%)": base_risk_share,
        "–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞": base_below,
    }
    values_new = {
        "–í—ã–¥–∞—á–∏": new_issue,
        "–í—ã—Ä—É—á–∫–∞": new_revenue,
        "–ù–∞—Ü–µ–Ω–∫–∞ (%)": new_markup,
        "–†–∏—Å–∫ (%)": new_risk_share,
        "–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞": new_below,
    }

    comparison = make_subplots(specs=[[{"secondary_y": True}]])
    money_labels = ["–í—ã–¥–∞—á–∏", "–í—ã—Ä—É—á–∫–∞", "–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞"]
    money_base = [values_base[label] for label in money_labels]
    money_new = [values_new[label] for label in money_labels]
    comparison.add_trace(
        go.Bar(
            x=money_labels,
            y=money_base,
            name="–ë–∞–∑–∞ (—Ä—É–±)",
            marker_color="rgba(148, 163, 184, 0.6)",
        ),
        secondary_y=False,
    )
    comparison.add_trace(
        go.Bar(
            x=money_labels,
            y=money_new,
            name="–°—Ü–µ–Ω–∞—Ä–∏–π (—Ä—É–±)",
            marker_color="#2563eb",
        ),
        secondary_y=False,
    )

    perc_labels = ["–ù–∞—Ü–µ–Ω–∫–∞ (%)", "–†–∏—Å–∫ (%)"]
    perc_base = [values_base[label] for label in perc_labels]
    perc_new = [values_new[label] for label in perc_labels]
    comparison.add_trace(
        go.Scatter(
            x=perc_labels,
            y=perc_base,
            name="–ù–∞—Ü–µ–Ω–∫–∞/–†–∏—Å–∫ (–±–∞–∑–∞)",
            mode="lines+markers",
            line=dict(color="#22c55e", width=3),
        ),
        secondary_y=True,
    )
    comparison.add_trace(
        go.Scatter(
            x=perc_labels,
            y=perc_new,
            name="–ù–∞—Ü–µ–Ω–∫–∞/–†–∏—Å–∫ (—Å—Ü–µ–Ω–∞—Ä–∏–π)",
            mode="lines+markers",
            line=dict(color="#f97316", width=3, dash="dot"),
        ),
        secondary_y=True,
    )

    comparison.update_layout(
        height=360,
        margin=dict(l=30, r=40, t=30, b=40),
        barmode="group",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
        title_text="–î–µ–Ω–µ–∂–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏"
    )
    comparison.update_yaxes(title_text="—Ä—É–±", secondary_y=False)
    comparison.update_yaxes(title_text="%", secondary_y=True)
    st.plotly_chart(comparison, use_container_width=True, key="what_if_combined")

    monthly_revenue = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.REVENUE.value, ctx.months_range)
    monthly_issue = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.LOAN_ISSUE.value, ctx.months_range)
    monthly_markup = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.MARKUP_PCT.value, ctx.months_range)
    monthly_risk = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.RISK_SHARE.value, ctx.months_range)

    scenario_timeline = pd.DataFrame(index=monthly_revenue.index.astype(str))
    scenario_timeline["–í—ã—Ä—É—á–∫–∞ (–±–∞–∑–∞)"] = pd.to_numeric(monthly_revenue, errors="coerce")
    scenario_timeline["–í—ã—Ä—É—á–∫–∞ (—Å—Ü–µ–Ω–∞—Ä–∏–π)"] = scenario_timeline["–í—ã—Ä—É—á–∫–∞ (–±–∞–∑–∞)"] * factor_issue * factor_markup
    scenario_timeline["–†–∏—Å–∫ (–±–∞–∑–∞)"] = pd.to_numeric(monthly_risk, errors="coerce")
    scenario_timeline["–†–∏—Å–∫ (—Å—Ü–µ–Ω–∞—Ä–∏–π)"] = scenario_timeline["–†–∏—Å–∫ (–±–∞–∑–∞)"] * factor_risk
    scenario_timeline = scenario_timeline.dropna(how="all")

    if not scenario_timeline.empty:
        trend_fig = make_subplots(specs=[[{"secondary_y": True}]])
        trend_fig.add_trace(
            go.Scatter(
                x=scenario_timeline.index,
                y=scenario_timeline["–í—ã—Ä—É—á–∫–∞ (–±–∞–∑–∞)"],
                name="–í—ã—Ä—É—á–∫–∞ (–±–∞–∑–∞)",
                line=dict(color="#0ea5e9", width=3),
                mode="lines+markers"
            ),
            secondary_y=False,
        )
        trend_fig.add_trace(
            go.Scatter(
                x=scenario_timeline.index,
                y=scenario_timeline["–í—ã—Ä—É—á–∫–∞ (—Å—Ü–µ–Ω–∞—Ä–∏–π)"],
                name="–í—ã—Ä—É—á–∫–∞ (—Å—Ü–µ–Ω–∞—Ä–∏–π)",
                line=dict(color="#2563eb", width=3, dash="dot"),
                mode="lines+markers"
            ),
            secondary_y=False,
        )
        if scenario_timeline["–†–∏—Å–∫ (–±–∞–∑–∞)"].notna().any():
            trend_fig.add_trace(
                go.Scatter(
                    x=scenario_timeline.index,
                    y=scenario_timeline["–†–∏—Å–∫ (–±–∞–∑–∞)"],
                    name="–†–∏—Å–∫ (–±–∞–∑–∞)",
                    line=dict(color="#f97316", width=2),
                    mode="lines+markers"
                ),
                secondary_y=True,
            )
        if scenario_timeline["–†–∏—Å–∫ (—Å—Ü–µ–Ω–∞—Ä–∏–π)"].notna().any():
            trend_fig.add_trace(
                go.Scatter(
                    x=scenario_timeline.index,
                    y=scenario_timeline["–†–∏—Å–∫ (—Å—Ü–µ–Ω–∞—Ä–∏–π)"],
                    name="–†–∏—Å–∫ (—Å—Ü–µ–Ω–∞—Ä–∏–π)",
                    line=dict(color="#fb923c", width=2, dash="dot"),
                    mode="lines+markers"
                ),
                secondary_y=True,
            )
        trend_fig.update_layout(
            height=360,
            margin=dict(l=30, r=20, t=30, b=30),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0)
        )
        trend_fig.update_yaxes(title_text="–í—ã—Ä—É—á–∫–∞ (—Ä—É–±)", secondary_y=False)
        trend_fig.update_yaxes(title_text="–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %", secondary_y=True)
        st.plotly_chart(trend_fig, use_container_width=True, key="what_if_trend")

    delta_text = []
    if base_issue:
        delta_text.append(f"–í—ã–¥–∞—á–∏ {delta_issue:+d}% ‚Üí {format_rub(new_issue)}")
    if base_revenue:
        delta_text.append(f"–í—ã—Ä—É—á–∫–∞ {format_rub(new_revenue - base_revenue)}")
    delta_text.append(f"–ù–∞—Ü–µ–Ω–∫–∞ {fmt_pct(new_markup)} | –†–∏—Å–∫ {fmt_pct(new_risk_share)}")
    if base_below:
        delta_text.append(f"–£–±—ã—Ç–æ–∫ –æ—Ç –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ {format_rub(new_below - base_below)}")
    st.markdown("**–ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è:** " + "; ".join(delta_text))


def render_margin_capacity_planner(ctx: PageContext, widget_prefix: str = "margin_planner") -> None:
    st.subheader("üéØ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –º–∞—Ä–∂–∏ –∏ —Å–∫–∏–¥–æ–∫")
    base_markup = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    base_revenue = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    base_loss = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.BELOW_LOAN.value, ctx.months_range)
    base_loss_units = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.BELOW_LOAN_UNITS.value, ctx.months_range)
    base_markup_amount = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_AMOUNT.value, ctx.months_range)

    default_markup = 45.0
    if base_markup is not None and not pd.isna(base_markup):
        default_markup = float(np.clip(base_markup, 0.0, 150.0))

    if base_loss is not None and not pd.isna(base_loss) and base_loss > 0:
        default_loss_budget = float(max(0.5, round((base_loss / 1_000_000) * 1.1, 1)))
    else:
        default_loss_budget = 5.0

    col_target, col_budget = st.columns(2)
    target_markup = col_target.slider(
        "–¶–µ–ª–µ–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏",
        min_value=0.0,
        max_value=150.0,
        value=default_markup,
        step=0.5,
        help="–ö–∞–∫–æ–π —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ —É–¥–µ—Ä–∂–∞—Ç—å –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É.",
        key=f"{widget_prefix}_target_markup",
    )
    loss_budget_mln = col_budget.number_input(
        "–î–æ–ø—É—Å—Ç–∏–º—ã–π –±—é–¥–∂–µ—Ç —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂, –º–ª–Ω ‚ÇΩ",
        min_value=0.0,
        max_value=500.0,
        value=default_loss_budget,
        step=0.5,
        help="–õ–∏–º–∏—Ç –ø–æ—Ç–µ—Ä—å –Ω–∞ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞—Ö –Ω–∏–∂–µ –∑–∞–π–º–∞, –≤–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.",
        key=f"{widget_prefix}_loss_budget",
    )
    loss_budget = loss_budget_mln * 1_000_000

    markup_gap_pct = None
    if base_markup is not None and not pd.isna(base_markup):
        markup_gap_pct = target_markup - base_markup

    target_markup_amount = None
    markup_amount_gap = None
    if base_markup_amount is not None and base_markup is not None and base_markup not in (0, 0.0) and not pd.isna(base_markup_amount):
        target_markup_amount = base_markup_amount * (target_markup / base_markup if base_markup else 1.0)
    elif base_revenue is not None and not pd.isna(base_revenue):
        target_markup_amount = base_revenue * (target_markup / 100)
    if target_markup_amount is not None and base_markup_amount is not None and not pd.isna(base_markup_amount):
        markup_amount_gap = target_markup_amount - base_markup_amount

    loss_gap = None
    if base_loss is not None and not pd.isna(base_loss):
        loss_gap = loss_budget - base_loss

    avg_loss_per_unit = None
    if base_loss_units and base_loss_units > 0 and base_loss is not None and not pd.isna(base_loss) and base_loss > 0:
        avg_loss_per_unit = base_loss / base_loss_units

    allowed_extra_units = None
    if loss_gap is not None and loss_gap > 0 and avg_loss_per_unit:
        allowed_extra_units = loss_gap / avg_loss_per_unit

    col_status_1, col_status_2, col_status_3 = st.columns(3)
    delta_markup_label = "‚Äî"
    if markup_gap_pct is not None:
        delta_markup_label = f"{markup_gap_pct:+.1f} –ø.–ø."
    col_status_1.metric("–¶–µ–ª–µ–≤–∞—è –Ω–∞—Ü–µ–Ω–∫–∞", fmt_pct(target_markup), delta=delta_markup_label)

    col_status_2.metric(
        "–ú–∞—Ä–∂–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ (–Ω–æ–≤–∞—è)",
        format_rub(target_markup_amount),
        delta="‚Äî" if markup_amount_gap is None else format_rub(markup_amount_gap)
    )

    loss_delta_label = "‚Äî"
    if loss_gap is not None and base_loss is not None and not pd.isna(base_loss):
        loss_delta_label = f"{(loss_budget - base_loss) / 1_000_000:+.2f} –º–ª–Ω ‚ÇΩ"
    col_status_3.metric(
        "–õ–∏–º–∏—Ç —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂",
        f"{loss_budget_mln:.2f} –º–ª–Ω ‚ÇΩ",
        delta=loss_delta_label
    )

    insights: list[str] = []
    if markup_gap_pct is not None:
        if markup_gap_pct > 0:
            if markup_amount_gap is not None:
                insights.append(f"–ù—É–∂–Ω–æ –¥–æ–±—Ä–∞—Ç—å {format_rub(markup_amount_gap)} –º–∞—Ä–∂–∏, —á—Ç–æ–±—ã –≤—ã–π—Ç–∏ –Ω–∞ {fmt_pct(target_markup)}.")
            else:
                insights.append(f"–ü–æ–¥–Ω—è—Ç—å –Ω–∞—Ü–µ–Ω–∫—É –¥–æ {fmt_pct(target_markup)} (+{markup_gap_pct:.1f} –ø.–ø.).")
        elif markup_gap_pct < 0:
            insights.append(f"–ï—Å—Ç—å –∑–∞–ø–∞—Å –≤ {abs(markup_gap_pct):.1f} –ø.–ø. –ø–æ –Ω–∞—Ü–µ–Ω–∫–µ ‚Äî –º–æ–∂–Ω–æ —É–ø—Ä–æ—Å—Ç–∏—Ç—å —É—Å–ª–æ–≤–∏—è —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏.")
        else:
            insights.append("–¢–µ–∫—É—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ —É–∂–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª–∏.")
    if loss_gap is not None:
        if loss_gap > 0:
            msg = f"–ú–æ–∂–Ω–æ –µ—â—ë –¥–æ–ø—É—Å—Ç–∏—Ç—å {format_rub(loss_gap)} –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞"
            if allowed_extra_units is not None and allowed_extra_units > 0:
                msg += f" (~{int(max(1, np.floor(allowed_extra_units)))} –ø–æ–∑.)."
            else:
                msg += "."
            insights.append(msg)
        elif loss_gap < 0:
            insights.append(f"–ë—é–¥–∂–µ—Ç —É–±—ã—Ç–∫–æ–≤ –ø—Ä–µ–≤—ã—à–µ–Ω –Ω–∞ {format_rub(abs(loss_gap))} ‚Äî —É–≤–µ–ª–∏—á—å—Ç–µ –Ω–∞—Ü–µ–Ω–∫—É –∏–ª–∏ —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ —Å–∫–∏–¥–∫–∏.")
        else:
            insights.append("–õ–∏–º–∏—Ç —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂ –≤—ã–±—Ä–∞–Ω –≤—Ä–æ–≤–µ–Ω—å —Å —Ç–µ–∫—É—â–∏–º —É—Ä–æ–≤–Ω–µ–º.")
    if avg_loss_per_unit:
        insights.append(f"–°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫ –Ω–∞ –ø–æ–∑–∏—Ü–∏—é —Å–µ–π—á–∞—Å {format_rub(avg_loss_per_unit)}.")

    if insights:
        bullets = "\n".join(f"- {line}" for line in insights)
        st.markdown(f"**–í—ã–≤–æ–¥—ã:**\n{bullets}")
    else:
        st.caption("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π ‚Äî –∑–∞–≥—Ä—É–∑–∏—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –Ω–∞—Ü–µ–Ω–∫–∏ –∏ —É–±—ã—Ç–∫–æ–≤.")


def risk_alerts_block(ctx: PageContext) -> dict[str, float | None]:
    st.subheader("üîî –°–∏–≥–Ω–∞–ª—ã —Ä–∏—Å–∫–∞")
    thresholds = ctx.thresholds or {}
    default_risk = float(thresholds.get("max_risk", 25.0))
    default_markup = float(thresholds.get("min_markup", 45.0))
    default_loss = float(thresholds.get("loss_cap", 5.0))
    col_risk, col_markup, col_loss = st.columns(3)
    risk_threshold = col_risk.number_input(
        "–ü–æ—Ä–æ–≥ –¥–æ–ª–∏ –Ω–∏–∂–µ –∑–∞–π–º–∞, %",
        min_value=0.0,
        max_value=100.0,
        value=default_risk,
        step=1.0,
        help="–°–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ –¥–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç —ç—Ç–æ—Ç —É—Ä–æ–≤–µ–Ω—å."
    )
    markup_floor = col_markup.number_input(
        "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞—Ü–µ–Ω–∫–∞, %",
        min_value=0.0,
        max_value=200.0,
        value=default_markup,
        step=1.0,
        help="–°–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è –Ω–∞—Ü–µ–Ω–∫–∞ –æ–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∏–∂–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞."
    )
    loss_cap_mln = col_loss.number_input(
        "–õ–∏–º–∏—Ç —É–±—ã—Ç–∫–∞ –Ω–∏–∂–µ –∑–∞–π–º–∞, –º–ª–Ω ‚ÇΩ",
        min_value=0.0,
        max_value=500.0,
        value=default_loss,
        step=0.5,
        help="–°–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ —Å—É–º–º–∞—Ä–Ω—ã–π —É–±—ã—Ç–æ–∫ –æ—Ç –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –±—é–¥–∂–µ—Ç."
    )
    loss_cap = loss_cap_mln * 1_000_000

    current_risk = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.RISK_SHARE.value, ctx.months_range)
    current_markup = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    current_loss = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.BELOW_LOAN.value, ctx.months_range)

    def _delta_text(delta: float | None, unit: str) -> str | None:
        if delta is None or pd.isna(delta):
            return None
        sign = "+" if delta >= 0 else ""
        return f"{sign}{delta:.1f} {unit}"

    with st.container():
        col_r, col_m, col_l = st.columns(3)
        risk_delta = None
        if current_risk is not None and pd.notna(current_risk):
            risk_delta = risk_threshold - current_risk
        markup_delta = None
        if current_markup is not None and pd.notna(current_markup):
            markup_delta = current_markup - markup_floor
        loss_delta = None
        if current_loss is not None and pd.notna(current_loss):
            loss_delta = loss_cap - current_loss

        col_r.metric(
            "–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞",
            fmt_pct(current_risk),
            delta=_delta_text(risk_delta, "–ø.–ø.") or "‚Äî"
        )
        col_r.caption(f"–ü–æ—Ä–æ–≥: {fmt_pct(risk_threshold)}")
        if risk_delta is not None and risk_delta < 0:
            col_r.error("–ü–æ—Ä–æ–≥ –ø—Ä–µ–≤—ã—à–µ–Ω ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–∫—Ü–∏—è.")

        col_m.metric(
            "–°—Ä–µ–¥–Ω—è—è –Ω–∞—Ü–µ–Ω–∫–∞",
            fmt_pct(current_markup),
            delta=_delta_text(markup_delta, "–ø.–ø.") or "‚Äî"
        )
        col_m.caption(f"–ú–∏–Ω–∏–º—É–º: {fmt_pct(markup_floor)}")
        if markup_delta is not None and markup_delta < 0:
            col_m.warning("–ù–∞—Ü–µ–Ω–∫–∞ –Ω–∏–∂–µ —Ü–µ–ª–µ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è.")

        loss_value_display = None if current_loss is None else current_loss / 1_000_000
        loss_delta_display = None if loss_delta is None else loss_delta / 1_000_000
        loss_delta_text = _delta_text(loss_delta_display, "–º–ª–Ω") or "‚Äî"
        col_l.metric(
            "–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞ (–º–ª–Ω ‚ÇΩ)",
            "‚Äî" if loss_value_display is None else f"{loss_value_display:.2f}",
            delta=loss_delta_text
        )
        col_l.caption(f"–õ–∏–º–∏—Ç: {loss_cap_mln:.1f} –º–ª–Ω ‚ÇΩ")
        if loss_delta is not None and loss_delta < 0:
            col_l.error("–ë—é–¥–∂–µ—Ç —É–±—ã—Ç–∫–æ–≤ –ø—Ä–µ–≤—ã—à–µ–Ω.")

    bullet_points: list[str] = []
    if current_risk is not None and not pd.isna(current_risk):
        flag = "‚úÖ" if risk_delta is None or risk_delta >= 0 else "‚ö†Ô∏è"
        bullet_points.append(f"{flag} –†–∏—Å–∫: {fmt_pct(current_risk)} –ø—Ä–∏ –ø–æ—Ä–æ–≥–µ {fmt_pct(risk_threshold)}.")
    if current_markup is not None and not pd.isna(current_markup):
        flag = "‚úÖ" if markup_delta is None or markup_delta >= 0 else "‚ö†Ô∏è"
        bullet_points.append(f"{flag} –ù–∞—Ü–µ–Ω–∫–∞: {fmt_pct(current_markup)} vs –º–∏–Ω–∏–º—É–º {fmt_pct(markup_floor)}.")
    if current_loss is not None and not pd.isna(current_loss):
        flag = "‚úÖ" if loss_delta is None or loss_delta >= 0 else "‚ö†Ô∏è"
        bullet_points.append(
            f"{flag} –£–±—ã—Ç–æ–∫: {format_rub(current_loss)} –ø—Ä–∏ –ª–∏–º–∏—Ç–µ {format_rub(loss_cap)}."
        )
    if bullet_points:
        st.markdown("**–°—Ç–∞—Ç—É—Å:**<br>" + "<br>".join(bullet_points), unsafe_allow_html=True)

    st.session_state["thresholds_config"] = {
        "min_markup": float(markup_floor),
        "max_risk": float(risk_threshold),
        "loss_cap": float(loss_cap_mln),
    }

    return {
        "risk_threshold": risk_threshold,
        "markup_floor": markup_floor,
        "loss_cap": loss_cap,
    }


def risk_markup_heatmap_block(ctx: PageContext) -> None:
    st.subheader("üî• –¢–µ–ø–ª–æ–∫–∞—Ä—Ç–∞ ¬´—Ä–∏—Å–∫ ‚Üî –Ω–∞—Ü–µ–Ω–∫–∞¬ª")
    risk_df = get_monthly_totals_from_file(ctx.df_current, tuple(ctx.regions), Metrics.RISK_SHARE.value)
    markup_df = get_monthly_totals_from_file(ctx.df_current, tuple(ctx.regions), Metrics.MARKUP_PCT.value)
    revenue_df = get_monthly_totals_from_file(ctx.df_current, tuple(ctx.regions), Metrics.REVENUE.value)
    if risk_df.empty or markup_df.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—ã.")
        return

    merged = (
        risk_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Risk"})
        .merge(markup_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Markup"}), on=["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"], how="inner")
    )
    if revenue_df is not None and not revenue_df.empty:
        merged = merged.merge(
            revenue_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Revenue"}),
            on=["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"],
            how="left"
        )
    merged = merged[merged["–ú–µ—Å—è—Ü"].astype(str).isin(ctx.months_range)]
    merged["Risk"] = pd.to_numeric(merged["Risk"], errors="coerce")
    merged["Markup"] = pd.to_numeric(merged["Markup"], errors="coerce")
    merged["Revenue"] = pd.to_numeric(merged.get("Revenue"), errors="coerce")
    merged = merged.dropna(subset=["Risk", "Markup"])
    if merged.empty:
        st.info("–ù–µ—Ç —Ç–æ—á–µ–∫ —Å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —Ä–∏—Å–∫–∞ –∏ –Ω–∞—Ü–µ–Ω–∫–∏.")
        return

    risk_min, risk_max = merged["Risk"].min(), merged["Risk"].max()
    markup_min, markup_max = merged["Markup"].min(), merged["Markup"].max()
    if np.isclose(risk_min, risk_max) or np.isclose(markup_min, markup_max):
        st.info("–†–∞–∑–±—Ä–æ—Å –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω –¥–ª—è —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—ã ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞—é —Ç–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫.")
        scatter = px.scatter(
            merged,
            x="Markup",
            y="Risk",
            size=merged["Revenue"].clip(lower=0.0) if "Revenue" in merged else None,
            color="–†–µ–≥–∏–æ–Ω",
            hover_data=["–ú–µ—Å—è—Ü", "–†–µ–≥–∏–æ–Ω", "Revenue"],
            labels={"Markup": "–ù–∞—Ü–µ–Ω–∫–∞, %", "Risk": "–†–∏—Å–∫, %"}
        )
        scatter.update_layout(height=380, margin=dict(l=40, r=40, t=30, b=40))
        st.plotly_chart(scatter, use_container_width=True, key="risk_markup_scatter_fallback")
        return

    risk_bins = np.linspace(risk_min, risk_max, num=7)
    markup_bins = np.linspace(markup_min, markup_max, num=7)
    merged["risk_bucket"] = pd.cut(merged["Risk"], bins=risk_bins, include_lowest=True)
    merged["markup_bucket"] = pd.cut(merged["Markup"], bins=markup_bins, include_lowest=True)

    weight = merged["Revenue"].fillna(0.0)
    if weight.abs().sum() == 0:
        weight = pd.Series(1.0, index=merged.index)

    heat = (
        merged.assign(weight=weight)
        .groupby(["risk_bucket", "markup_bucket"], observed=True)["weight"]
        .sum()
        .unstack(fill_value=0.0)
    )
    if heat.empty:
        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—É.")
        return

    heat = heat.loc[:, heat.sum(axis=0) > 0.0]
    heat = heat.loc[heat.sum(axis=1) > 0.0]
    if heat.empty:
        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—É.")
        return

    x_display = [f"{interval.left:.1f}‚Äì{interval.right:.1f}%" for interval in heat.columns]
    y_display = [f"{interval.left:.1f}‚Äì{interval.right:.1f}%" for interval in heat.index]

    fig = go.Figure(
        go.Heatmap(
            z=heat.values,
            x=x_display,
            y=y_display,
            colorscale=[
                [0.0, "#f8fafc"],
                [0.2, "#dbeafe"],
                [0.5, "#93c5fd"],
                [0.8, "#3b82f6"],
                [1.0, "#1d4ed8"],
            ],
            hovertemplate="–ù–∞—Ü–µ–Ω–∫–∞: %{x}<br>–†–∏—Å–∫: %{y}<br>–í–µ—Å: %{z:,.0f}<extra></extra>",
        )
    )
    fig.update_layout(
        height=380,
        margin=dict(l=60, r=40, t=40, b=60),
        xaxis_title="–î–∏–∞–ø–∞–∑–æ–Ω –Ω–∞—Ü–µ–Ω–∫–∏, %",
        yaxis_title="–î–∏–∞–ø–∞–∑–æ–Ω —Ä–∏—Å–∫–∞, %",
    )
    st.plotly_chart(fig, use_container_width=True, key="risk_markup_heatmap")
    st.caption("–Ø—Ä–∫–æ—Å—Ç—å –∫–ª–µ—Ç–∫–∏ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å–æ–≤–æ–∫—É–ø–Ω—É—é –≤—ã—Ä—É—á–∫—É (–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫), –ø–æ–ø–∞–≤—à–∏—Ö –≤ –ø–∞—Ä—É –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤.")


def risk_failure_forecast_block(ctx: PageContext, risk_threshold: float | None) -> None:
    st.subheader("üìâ –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–≤–∞–ª–æ–≤ –ø–æ —Ä–∏—Å–∫—É")
    st.caption("–ü—Ä–æ–≥–Ω–æ–∑ –¥–æ–ª–∏ –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ —Å—É–º–º—ã –∑–∞–π–º–∞ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –º–µ—Å—è—Ü—ã. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –ø–æ —Ñ–∞–∫—Ç—É: –ª–∏–Ω–∏—è ‚Äî –æ–∂–∏–¥–∞–µ–º—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç, –æ–±–ª–∞—Å—Ç—å ‚Äî 95% –∏–Ω—Ç–µ—Ä–≤–∞–ª. –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Ä–æ–≥, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –≥–¥–µ –ø—Ä–æ–≥–Ω–æ–∑ –µ–≥–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç.")
    forecast_bundle = _prepare_forecast(
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        Metrics.RISK_SHARE.value,
        horizon=4,
    )
    if not forecast_bundle:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞.")
        return

    history = forecast_bundle["history"]
    future_labels = forecast_bundle["future_labels"]
    forecast_vals = forecast_bundle["forecast"]
    lower_vals = forecast_bundle["lower"]
    upper_vals = forecast_bundle["upper"]

    fig = go.Figure()
    hist_x = [str(x) for x in history.index]
    fig.add_trace(go.Scatter(
        x=hist_x,
        y=history.values,
        mode="lines+markers",
        name="–§–∞–∫—Ç",
        line=dict(color="#2563eb", width=3),
    ))

    forecast_x = [hist_x[-1]] + future_labels
    forecast_y = [history.values[-1]] + forecast_vals
    fig.add_trace(go.Scatter(
        x=forecast_x,
        y=forecast_y,
        mode="lines+markers",
        name="–ü—Ä–æ–≥–Ω–æ–∑",
        line=dict(color="#7c3aed", width=2, dash="dot"),
    ))

    fig.add_trace(go.Scatter(
        x=future_labels + future_labels[::-1],
        y=upper_vals + lower_vals[::-1],
        fill="toself",
        fillcolor="rgba(124,58,237,0.15)",
        line=dict(color="rgba(0,0,0,0)"),
        hoverinfo="skip",
        showlegend=True,
        name="95% –∏–Ω—Ç–µ—Ä–≤–∞–ª",
    ))

    if risk_threshold is not None:
        fig.add_hline(
            y=risk_threshold,
            line=dict(color="#ef4444", width=2, dash="dash"),
            annotation_text=f"–ü–æ—Ä–æ–≥ {risk_threshold:.1f}%",
            annotation_position="top left",
        )

    fig.update_layout(
        height=380,
        margin=dict(l=40, r=40, t=50, b=30),
        yaxis_title="–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞, %",
        xaxis_title="–ú–µ—Å—è—Ü",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
    )
    st.plotly_chart(fig, use_container_width=True, key="risk_failure_forecast")

    forecast_table = pd.DataFrame({
        "–ú–µ—Å—è—Ü": future_labels,
        "–ü—Ä–æ–≥–Ω–æ–∑, %": [float(v) for v in forecast_vals],
        "–ù–∏–∑, %": [float(v) for v in lower_vals],
        "–í–µ—Ä—Ö, %": [float(v) for v in upper_vals],
    })
    if risk_threshold is not None:
        forecast_table["–°–∏–≥–Ω–∞–ª"] = [
            "‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ" if (risk_threshold is not None and val > risk_threshold) else "‚úÖ –í –Ω–æ—Ä–º–µ"
            for val in forecast_table["–ü—Ä–æ–≥–Ω–æ–∑, %"]
        ]
    st.dataframe(
        forecast_table,
        use_container_width=True,
        hide_index=True,
        column_config={
            "–ü—Ä–æ–≥–Ω–æ–∑, %": st.column_config.NumberColumn("–ü—Ä–æ–≥–Ω–æ–∑, %", format="%.2f"),
            "–ù–∏–∑, %": st.column_config.NumberColumn("–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞, %", format="%.2f"),
            "–í–µ—Ä—Ö, %": st.column_config.NumberColumn("–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞, %", format="%.2f"),
        },
    )
    st.caption("–ü—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –ª–∏–Ω–µ–π–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ —Å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é. –°–∏–≥–Ω–∞–ª –ø–æ—è–≤–ª—è–µ—Ç—Å—è, –µ—Å–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥.")


def render_risk_dependency(ctx: PageContext) -> None:
    st.subheader("‚öñÔ∏è –†–∏—Å–∫ –∏ –º–∞—Ä–∂–∞")
    risk_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.RISK_SHARE.value, ctx.months_range)
    markup_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.MARKUP_PCT.value, ctx.months_range)
    below_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.BELOW_LOAN.value, ctx.months_range)
    revenue_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), Metrics.REVENUE.value, ctx.months_range)
    data = pd.DataFrame({
        "Risk": pd.to_numeric(risk_series, errors="coerce"),
        "Markup": pd.to_numeric(markup_series, errors="coerce"),
        "Below": pd.to_numeric(below_series, errors="coerce"),
        "Revenue": pd.to_numeric(revenue_series, errors="coerce")
    })
    data = data.dropna(how="all")
    if data.empty or data["Risk"].dropna().empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏.")
        return

    line_df = data.dropna(subset=["Risk", "Markup"])
    if not line_df.empty:
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        fig.add_trace(
            go.Scatter(
                x=[str(x) for x in line_df.index],
                y=line_df["Risk"],
                mode="lines+markers",
                name="–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %",
                line=dict(color="#f97316", width=3),
            ),
            secondary_y=False,
        )
        fig.add_trace(
            go.Scatter(
                x=[str(x) for x in line_df.index],
                y=line_df["Markup"],
                mode="lines+markers",
                name="–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏",
                line=dict(color="#22c55e", width=2, dash="dot"),
            ),
            secondary_y=True,
        )
        if not data["Below"].dropna().empty:
            fig.add_trace(
                go.Bar(
                    x=[str(x) for x in data.index],
                    y=data["Below"].fillna(0.0),
                    name="–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞ (—Ä—É–±)",
                    marker_color="rgba(239,68,68,0.35)",
                    opacity=0.6,
                ),
                secondary_y=False,
            )
        fig.update_yaxes(title_text="–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %", secondary_y=False)
        fig.update_yaxes(title_text="–ù–∞—Ü–µ–Ω–∫–∞, %", secondary_y=True)
        fig.update_layout(
            height=360,
            margin=dict(l=40, r=40, t=30, b=30),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
        )
        st.plotly_chart(fig, use_container_width=True, key="risk_dual_axis")

    scatter_df = data.dropna(subset=["Risk", "Markup"])
    if not scatter_df.empty:
        revenue_max = float(scatter_df["Revenue"].fillna(0).abs().max() or 1.0)
        sizes = scatter_df["Revenue"].fillna(0).apply(lambda v: 12 + 30 * (abs(v) / revenue_max))
        colors = scatter_df["Below"].fillna(0.0)
        scatter = go.Figure(go.Scatter(
            x=scatter_df["Risk"],
            y=scatter_df["Markup"],
            mode="markers+text",
            text=[str(x) for x in scatter_df.index],
            textposition="top center",
            marker=dict(
                size=sizes,
                color=colors,
                colorscale="Reds",
                showscale=True,
                colorbar=dict(title="–£–±—ã—Ç–æ–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞, —Ä—É–±"),
            ),
            name="–ú–µ—Å—è—Ü—ã",
        ))
        scatter.update_layout(
            height=360,
            margin=dict(l=40, r=40, t=20, b=40),
            xaxis_title="–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞, %",
            yaxis_title="–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏, %",
        )
        st.plotly_chart(scatter, use_container_width=True, key="risk_scatter")
        corr = float(scatter_df["Risk"].corr(scatter_df["Markup"])) if scatter_df.shape[0] > 1 else float("nan")
        if not np.isnan(corr):
            st.caption(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–æ–ª–µ–π –Ω–∏–∂–µ –∑–∞–π–º–∞ –∏ –Ω–∞—Ü–µ–Ω–∫–æ–π: {corr:+.2f}.")
    st.caption("–†–∞–∑–º–µ—Ä —Ç–æ—á–∫–∏ –æ—Ç—Ä–∞–∂–∞–µ—Ç –≤—ã—Ä—É—á–∫—É –º–µ—Å—è—Ü–∞, —Ü–≤–µ—Ç ‚Äî —É—Ä–æ–≤–µ–Ω—å —É–±—ã—Ç–∫–∞ –æ—Ç –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞.")


@st.cache_data(show_spinner=False, max_entries=256)
def _extract_region_month_metric(df_source: pd.DataFrame, regions: list[str], metric: str, months: list[str]) -> pd.DataFrame:
    frame = get_monthly_totals_from_file(df_source, tuple(regions), metric)
    if frame.empty:
        return frame
    frame = frame.copy()
    frame["–ú–µ—Å—è—Ü"] = frame["–ú–µ—Å—è—Ü"].astype(str)
    frame = frame[frame["–ú–µ—Å—è—Ü"].isin(months)]
    if frame.empty:
        return frame
    frame["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(frame["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
    frame = frame.dropna(subset=["–ó–Ω–∞—á–µ–Ω–∏–µ"])
    if not frame.empty and is_percent_metric(metric):
        sample = frame["–ó–Ω–∞—á–µ–Ω–∏–µ"].abs()
        if sample.median(skipna=True) <= 1.5:
            frame["–ó–Ω–∞—á–µ–Ω–∏–µ"] = frame["–ó–Ω–∞—á–µ–Ω–∏–µ"] * 100.0
    frame["–†–µ–≥–∏–æ–Ω"] = frame["–†–µ–≥–∏–æ–Ω"].astype(str)
    frame["–ú–µ—Å—è—Ü"] = pd.Categorical(frame["–ú–µ—Å—è—Ü"], categories=ORDER, ordered=True)
    frame = frame.sort_values("–ú–µ—Å—è—Ü")
    frame["–ú–µ—Å—è—Ü"] = frame["–ú–µ—Å—è—Ü"].astype(str)
    return frame


def render_region_band_chart(ctx: PageContext) -> None:
    st.subheader("üéÄ –õ–µ–Ω—Ç–æ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –≤—ã—Ä—É—á–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
    st.caption("–õ–µ–Ω—Ç–∞ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω 10‚Äì90 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π –ø–æ –≤—ã—Ä—É—á–∫–µ, —Ç—ë–º–Ω–∞—è –ª–∏–Ω–∏—è ‚Äî –º–µ–¥–∏–∞–Ω–∞. –¢–∞–∫ –≤–∏–¥–Ω–æ —Ç–∏–ø–∏—á–Ω—ã–π –∫–æ—Ä–∏–¥–æ—Ä –∏ –≤—ã–±—Ä–æ—Å—ã –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")
    df_metric = _extract_region_month_metric(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    if df_metric.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã—Ä—É—á–∫–µ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤.")
        return
    stats: Dict[str, Dict[str, float]] = {}
    for month, group in df_metric.groupby("–ú–µ—Å—è—Ü"):
        values = group["–ó–Ω–∞—á–µ–Ω–∏–µ"].astype(float)
        if values.empty:
            continue
        stats[str(month)] = {
            "p10": float(np.percentile(values, 10)),
            "median": float(np.percentile(values, 50)),
            "p90": float(np.percentile(values, 90)),
        }
    months = [m for m in ctx.months_range if m in stats]
    if not months:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞.")
        return
    p10 = [stats[m]["p10"] for m in months]
    p90 = [stats[m]["p90"] for m in months]
    median = [stats[m]["median"] for m in months]
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=months,
        y=p90,
        mode="lines",
        name="90-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å",
        line=dict(color="#38bdf8", width=1.5),
    ))
    fig.add_trace(go.Scatter(
        x=months,
        y=p10,
        mode="lines",
        name="10-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å",
        line=dict(color="#38bdf8", width=1.5),
        fill="tonexty",
        fillcolor="rgba(59,130,246,0.18)",
    ))
    fig.add_trace(go.Scatter(
        x=months,
        y=median,
        mode="lines+markers",
        name="–ú–µ–¥–∏–∞–Ω–∞",
        line=dict(color="#0f172a", width=3),
        marker=dict(size=6, color="#0ea5e9")
    ))
    fig.update_layout(
        height=360,
        margin=dict(l=40, r=40, t=40, b=40),
        hovermode="x unified",
        yaxis_title="–í—ã—Ä—É—á–∫–∞, ‚ÇΩ",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
    )
    st.plotly_chart(fig, use_container_width=True, key="region_band_chart")
    st.caption("–¢—ë–º–Ω–∞—è –ª–∏–Ω–∏—è ‚Äî –º–µ–¥–∏–∞–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞; –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è –ª–µ–Ω—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω 10‚Äì90 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")


def render_markup_candlestick(ctx: PageContext) -> None:
    st.subheader("üïØÔ∏è –°–≤–µ—á–Ω–æ–π –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞—Ü–µ–Ω–∫–∏")
    df_metric = _extract_region_month_metric(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    if df_metric.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–∞—Ü–µ–Ω–∫–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–≤–µ—á–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞.")
        return
    stats: Dict[str, Dict[str, float]] = {}
    for month, group in df_metric.groupby("–ú–µ—Å—è—Ü"):
        values = group["–ó–Ω–∞—á–µ–Ω–∏–µ"].astype(float)
        if values.empty:
            continue
        stats[str(month)] = {
            "low": float(values.min()),
            "q1": float(np.percentile(values, 25)),
            "q3": float(np.percentile(values, 75)),
            "high": float(values.max()),
        }
    months = [m for m in ctx.months_range if m in stats]
    if not months:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–∞—Ü–µ–Ω–∫–µ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞.")
        return
    fig = go.Figure(go.Candlestick(
        x=months,
        open=[stats[m]["q1"] for m in months],
        close=[stats[m]["q3"] for m in months],
        low=[stats[m]["low"] for m in months],
        high=[stats[m]["high"] for m in months],
        increasing_line_color="#22c55e",
        increasing_fillcolor="rgba(34,197,94,0.4)",
        decreasing_line_color="#ef4444",
        decreasing_fillcolor="rgba(239,68,68,0.35)",
        name="–î–∏–∞–ø–∞–∑–æ–Ω –Ω–∞—Ü–µ–Ω–∫–∏"
    ))
    fig.update_layout(
        height=360,
        margin=dict(l=40, r=40, t=40, b=40),
        showlegend=False,
        yaxis_title="–ù–∞—Ü–µ–Ω–∫–∞, %",
        xaxis_title=None,
    )
    st.plotly_chart(fig, use_container_width=True, key="markup_candlestick")
    st.caption("–°–≤–µ—á–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–∞–∑–±—Ä–æ—Å –Ω–∞—Ü–µ–Ω–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º: –æ—Å–Ω–æ–≤–∞–Ω–∏—è ‚Äî –∫–≤–∞—Ä—Ç–∏–ª—å 25/75, —Ç–µ–Ω–∏ ‚Äî –º–∏–Ω–∏–º—É–º –∏ –º–∞–∫—Å–∏–º—É–º.")


def render_region_map_block(ctx: PageContext) -> None:
    st.subheader("üó∫Ô∏è –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º")
    map_metrics = [
        (Metrics.REVENUE.value, "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"),
        (Metrics.RISK_SHARE.value, "–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞, %"),
        (Metrics.MARKUP_PCT.value, "–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏, %"),
    ]
    view_mode = st.radio(
        "–§–æ—Ä–º–∞—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        options=["–õ–µ–Ω—Ç–∞ –ª–∏–¥–µ—Ä–æ–≤", "–ö–∞—Ä—Ç–∞"],
        horizontal=True,
        key="region_map_mode"
    )
    metric_choice = st.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞",
        options=map_metrics,
        format_func=lambda item: item[1],
        key="region_map_metric"
    )
    metric_key = metric_choice[0]
    st.caption(METRIC_HELP.get(metric_key, ""))

    sub = strip_totals_rows(ctx.df_current)
    sub = sub[
        (sub["–†–µ–≥–∏–æ–Ω"].isin(ctx.regions)) &
        (sub["–ú–µ—Å—è—Ü"].astype(str).isin(ctx.months_range)) &
        (sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric_key)
    ].copy()
    if sub.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.")
        return

    agg = (
        sub.groupby(["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        .sum()
        .reset_index()
    )
    agg["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(agg["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
    agg = agg.dropna(subset=["–ó–Ω–∞—á–µ–Ω–∏–µ"])
    if agg.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º.")
        return

    percent_metric = is_percent_metric(metric_key)
    if percent_metric and agg["–ó–Ω–∞—á–µ–Ω–∏–µ"].abs().median() <= 1.5:
        agg["–ó–Ω–∞—á–µ–Ω–∏–µ"] *= 100.0

    rows: List[Dict[str, Any]] = []
    missing_regions: List[str] = []
    for _, row in agg.iterrows():
        coords = resolve_region_coordinates(str(row["–†–µ–≥–∏–æ–Ω"]))
        if not coords:
            missing_regions.append(str(row["–†–µ–≥–∏–æ–Ω"]))
            continue
        rows.append({
            "–†–µ–≥–∏–æ–Ω": row["–†–µ–≥–∏–æ–Ω"],
            "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ": row["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"],
            "lat": coords[0],
            "lon": coords[1],
            "–ó–Ω–∞—á–µ–Ω–∏–µ": float(row["–ó–Ω–∞—á–µ–Ω–∏–µ"]),
        })
    if not rows:
        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–≥–∏–æ–Ω—ã —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏. –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ —Å–ª–æ–≤–∞—Ä—å REGION_COORDS.")
        return
    df_map = pd.DataFrame(rows)
    if missing_regions:
        st.caption("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è: " + ", ".join(sorted(set(missing_regions))))

    df_ranked = df_map.sort_values("–ó–Ω–∞—á–µ–Ω–∏–µ", ascending=percent_metric and metric_key in METRICS_SMALLER_IS_BETTER)
    if view_mode == "–õ–µ–Ω—Ç–∞ –ª–∏–¥–µ—Ä–æ–≤" or df_map["lat"].isna().all():
        df_ranked = df_ranked.copy()
        df_ranked["–ö–ª—é—á"] = df_ranked["–†–µ–≥–∏–æ–Ω"] + " ¬∑ " + df_ranked["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].fillna("‚Äî")
        df_ranked["–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ"] = df_ranked["–ó–Ω–∞—á–µ–Ω–∏–µ"].apply(
            lambda v: fmt_pct(v) if percent_metric else format_rub(v)
        )
        bar_fig = px.bar(
            df_ranked,
            x="–ó–Ω–∞—á–µ–Ω–∏–µ",
            y="–ö–ª—é—á",
            color="–ó–Ω–∞—á–µ–Ω–∏–µ",
            orientation="h",
            color_continuous_scale="Blues" if not percent_metric else "Oranges",
        )
        bar_fig.update_layout(
            height=420,
            margin=dict(l=40, r=20, t=40, b=40),
            coloraxis_showscale=False,
        )
        bar_fig.update_traces(
            hovertemplate="<b>%{y}</b><br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{x:.2f}" + ("%" if percent_metric else " ‚ÇΩ") + "<extra></extra>"
        )
        st.plotly_chart(bar_fig, use_container_width=True, key="region_leaderboard")
        st.dataframe(
            df_ranked[["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ"]],
            use_container_width=True,
            hide_index=True,
            column_config={"–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ": "–ó–Ω–∞—á–µ–Ω–∏–µ"},
        )
        st.caption("–°—Ç–æ–ª–±–∏–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é: —Å–≤–µ—Ä—Ö—É —Ç–æ–ø –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è, –≤ —Ç–∞–±–ª–∏—Ü–µ –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –Ω–∞–π—Ç–∏ –Ω—É–∂–Ω—ã–π —Ä–µ–≥–∏–æ–Ω." )
    else:
        color_values = df_map["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        size_raw = color_values.fillna(0.0).abs()
        if percent_metric:
            normalized = size_raw / (size_raw.max() or 1.0)
            size_values = 6 + normalized * 12
        else:
            size_values = 6 + np.log1p(size_raw)
        fig = go.Figure(go.Scattergeo(
            lon=df_map["lon"],
            lat=df_map["lat"],
            text=df_map["–†–µ–≥–∏–æ–Ω"],
            customdata=np.column_stack([df_map["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], df_map["–ó–Ω–∞—á–µ–Ω–∏–µ"]]),
            marker=dict(
                size=size_values,
                color=color_values,
                colorscale="Blues" if not percent_metric else "Sunset",
                colorbar=dict(
                    title=metric_choice[1],
                    tickformat=".1f" if percent_metric else ".0f",
                ),
                line=dict(width=0.6, color="rgba(15,23,42,0.45)"),
                sizemode="diameter",
                opacity=0.85,
            ),
            hovertemplate="<b>%{text}</b><br>–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: %{customdata[0]}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{customdata[1]:.2f}" + ("%" if percent_metric else " ‚ÇΩ") + "<extra></extra>",
            name="",
        ))
        fig.update_layout(
            height=420,
            margin=dict(l=0, r=0, t=0, b=0),
            geo=dict(
                projection_type="natural earth",
                showcountries=True,
                showcoastlines=True,
                lonaxis=dict(range=[20, 170]),
                lataxis=dict(range=[40, 75]),
                bgcolor="rgba(255,255,255,0)",
            ),
        )
        st.plotly_chart(fig, use_container_width=True, key="region_map")
        st.caption("–†–∞–∑–º–µ—Ä –∫—Ä—É–≥–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç –º–∞—Å—à—Ç–∞–± –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è, —Ü–≤–µ—Ç ‚Äî –µ–≥–æ —É—Ä–æ–≤–µ–Ω—å. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –≤ REGION_COORDS –∏–ª–∏ —á–µ—Ä–µ–∑ –∞–≤—Ç–æ-–≥–µ–æ–∫–æ–¥–µ—Ä (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Å–µ—Å—Å–∏–∏).")


def render_region_map_block(ctx: PageContext) -> None:  # override with matrix-based view
    st.subheader("üìç –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º")
    map_metrics = [
        (Metrics.REVENUE.value, "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"),
        (Metrics.RISK_SHARE.value, "–î–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞, %"),
        (Metrics.MARKUP_PCT.value, "–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏, %"),
    ]
    view_mode = st.radio(
        "–§–æ—Ä–º–∞—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        options=["–õ–µ–Ω—Ç–∞ –ª–∏–¥–µ—Ä–æ–≤", "–¢–µ–ø–ª–æ–∫–∞—Ä—Ç–∞"],
        horizontal=True,
        key="region_map_mode"
    )
    metric_choice = st.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞",
        options=map_metrics,
        format_func=lambda item: item[1],
        key="region_map_metric"
    )
    metric_key = metric_choice[0]
    st.caption(METRIC_HELP.get(metric_key, ""))

    sub = strip_totals_rows(ctx.df_current)
    sub = sub[
        (sub["–†–µ–≥–∏–æ–Ω"].isin(ctx.regions)) &
        (sub["–ú–µ—Å—è—Ü"].astype(str).isin(ctx.months_range)) &
        (sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric_key)
    ].copy()
    if sub.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.")
        return

    agg = (
        sub.groupby(["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        .sum()
        .reset_index()
    )
    agg["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(agg["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
    agg = agg.dropna(subset=["–ó–Ω–∞—á–µ–Ω–∏–µ"])
    if agg.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º.")
        return

    percent_metric = is_percent_metric(metric_key)
    if percent_metric and agg["–ó–Ω–∞—á–µ–Ω–∏–µ"].abs().median() <= 1.5:
        agg["–ó–Ω–∞—á–µ–Ω–∏–µ"] *= 100.0

    df_ranked = agg.sort_values("–ó–Ω–∞—á–µ–Ω–∏–µ", ascending=percent_metric and metric_key in METRICS_SMALLER_IS_BETTER)
    if view_mode == "–õ–µ–Ω—Ç–∞ –ª–∏–¥–µ—Ä–æ–≤":
        df_ranked = df_ranked.copy()
        df_ranked["–ö–ª—é—á"] = df_ranked["–†–µ–≥–∏–æ–Ω"] + " ¬∑ " + df_ranked["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].fillna("‚Äî")
        df_ranked["–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ"] = df_ranked["–ó–Ω–∞—á–µ–Ω–∏–µ"].apply(
            lambda v: fmt_pct(v) if percent_metric else format_rub(v)
        )
        bar_fig = px.bar(
            df_ranked,
            x="–ó–Ω–∞—á–µ–Ω–∏–µ",
            y="–ö–ª—é—á",
            color="–ó–Ω–∞—á–µ–Ω–∏–µ",
            orientation="h",
            color_continuous_scale="Blues" if not percent_metric else "Oranges",
        )
        bar_fig.update_layout(
            height=420,
            margin=dict(l=40, r=20, t=40, b=40),
            coloraxis_showscale=False,
        )
        bar_fig.update_traces(
            hovertemplate="<b>%{y}</b><br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{x:.2f}" + ("%" if percent_metric else " ‚ÇΩ") + "<extra></extra>"
        )
        st.plotly_chart(bar_fig, use_container_width=True, key="region_leaderboard")
        st.dataframe(
            df_ranked[["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ"]],
            use_container_width=True,
            hide_index=True,
            column_config={"–ó–Ω–∞—á–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ": "–ó–Ω–∞—á–µ–Ω–∏–µ"},
        )
        st.caption("–°—Ç–æ–ª–±–∏–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é: —Å–≤–µ—Ä—Ö—É —Ç–æ–ø –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è, –≤ —Ç–∞–±–ª–∏—Ü–µ –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –Ω–∞–π—Ç–∏ –Ω—É–∂–Ω—ã–π —Ä–µ–≥–∏–æ–Ω.")
        return

    pivot = agg.pivot_table(index="–†–µ–≥–∏–æ–Ω", columns="–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="sum", observed=True)
    if pivot.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—ã.")
        return
    totals = pivot.abs().sum(axis=0).sort_values(ascending=percent_metric and metric_key in METRICS_SMALLER_IS_BETTER)
    top_columns = totals.index[: min(15, len(totals))]
    pivot = pivot[top_columns].fillna(0.0)

    heat = go.Figure(go.Heatmap(
        z=pivot.values,
        x=pivot.columns,
        y=pivot.index,
        colorscale="Blues" if not percent_metric else "Sunset",
        colorbar=dict(title=metric_choice[1], tickformat=".1f" if percent_metric else ".0f"),
        hovertemplate="–†–µ–≥–∏–æ–Ω: %{y}<br>–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: %{x}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{z:.2f}" + ("%" if percent_metric else " ‚ÇΩ") + "<extra></extra>",
    ))
    heat.update_layout(height=420, margin=dict(l=40, r=20, t=40, b=40))
    st.plotly_chart(heat, use_container_width=True, key="region_heatmap")
    st.caption("–¢–µ–ø–ª–æ–∫–∞—Ä—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ä–µ–≥–∏–æ–Ω—É/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é. –û—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –≤–∫–ª–∞–¥–æ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ.")


def render_comparison_page(ctx: PageContext) -> None:
    st.markdown("### üß≠ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ —Ñ–∏–ª–∏–∞–ª–æ–≤")
    st.caption("–ë—ã—Å—Ç—Ä–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –æ–∫–Ω–µ –º–µ—Å—è—Ü–µ–≤.")
    render_region_band_chart(ctx)
    st.divider()
    render_markup_candlestick(ctx)
    st.divider()
    render_region_map_block(ctx)
    st.divider()
    revenue_values = period_values_by_region_from_itogo(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    markup_values = period_values_by_region_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    if revenue_values:
        comparison_df = pd.DataFrame(
            {
                "–†–µ–≥–∏–æ–Ω": list(revenue_values.keys()),
                "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": [revenue_values.get(reg) for reg in revenue_values.keys()],
                "–ù–∞—Ü–µ–Ω–∫–∞, %": [markup_values.get(reg) for reg in revenue_values.keys()],
            }
        )
        comparison_df = comparison_df.sort_values(by="–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", ascending=False)
        st.dataframe(
            comparison_df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": st.column_config.NumberColumn("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", format="%.0f"),
                "–ù–∞—Ü–µ–Ω–∫–∞, %": st.column_config.NumberColumn("–ù–∞—Ü–µ–Ω–∫–∞, %", format="%.2f"),
            },
        )


def _month_to_quarter(month: str) -> str:
    if month not in ORDER:
        return month
    idx = ORDER.index(month)
    quarter = (idx // 3) + 1
    return f"Q{quarter}"


def render_cohort_page(ctx: PageContext) -> None:
    st.markdown("### üë• –ö–ª–∏–µ–Ω—Ç—Å–∫–∏–µ –∫–æ–≥–æ—Ä—Ç—ã")
    st.caption("–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–æ–∫–∞ –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –ø–æ –º–µ—Å—è—Ü–∞–º (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫).")
    available_metrics = sorted(
        m for m in ctx.df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().astype(str).unique()
        if m not in HIDDEN_METRICS
    )
    default_new_metric = Metrics.NEW_UNIQUE_CLIENTS.value if Metrics.NEW_UNIQUE_CLIENTS.value in available_metrics else (
        next((m for m in available_metrics if "–Ω–æ–≤" in m.lower() or "new" in m.lower()), None)
    )
    default_total_metric = Metrics.UNIQUE_CLIENTS.value if Metrics.UNIQUE_CLIENTS.value in available_metrics else (
        Metrics.LOAN_ISSUE_UNITS.value if Metrics.LOAN_ISSUE_UNITS.value in available_metrics else (
            next((m for m in available_metrics if "–∫–ª–∏–µ–Ω—Ç" in m.lower()), None)
        )
    )
    if default_new_metric == default_total_metric:
        default_total_metric = next((m for m in available_metrics if m != default_new_metric), default_total_metric)

    if not available_metrics:
        st.info("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –∫–æ–≥–æ—Ä—Ç.")
        return

    col_new, col_total = st.columns(2)
    new_metric = col_new.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞ –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤",
        options=available_metrics,
        index=available_metrics.index(default_new_metric) if default_new_metric in available_metrics else 0,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –ø—Ä–∏—Ç–æ–∫–∞ –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ—Ç, –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –≤—ã–¥–∞—á–∏ (—à—Ç).",
        key="cohort_new_metric",
    )
    total_metric = col_total.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞ —Ç–µ–∫—É—â–µ–π –±–∞–∑—ã",
        options=available_metrics,
        index=available_metrics.index(default_total_metric) if default_total_metric in available_metrics else 0,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å, –æ—Ç—Ä–∞–∂–∞—é—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π –±–∞–∑—ã.",
        key="cohort_total_metric",
    )

    if new_metric == total_metric:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–∏—Ç–æ–∫–∞ –∏ –±–∞–∑—ã ‚Äî –∏–Ω–∞—á–µ —É–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–µ –ø–æ—Å—á–∏—Ç–∞—Ç—å.")
        return

    view_mode = st.radio(
        "–†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
        options=["–°–≤–æ–¥–Ω–æ", "–°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–≥–∏–æ–Ω—ã"],
        horizontal=True,
        key="cohort_view_mode"
    )

    new_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), new_metric, ctx.months_range)
    total_series = _monthly_series_for_metric(ctx.df_current, tuple(ctx.regions), total_metric, ctx.months_range)
    if view_mode == "–°–≤–æ–¥–Ω–æ":
        if (new_series is None or new_series.empty) and (total_series is None or total_series.empty):
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º.")
            return
        months = [m for m in ctx.months_range if (new_series is not None and m in new_series.index) or (total_series is not None and m in total_series.index)]
        if not months:
            st.info("–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º.")
            return
        data = []
        has_retention = False
        for month in months:
            new_val = float(new_series.get(month, np.nan)) if new_series is not None else np.nan
            total_val = float(total_series.get(month, np.nan)) if total_series is not None else np.nan
            retention = np.nan
            share_new = np.nan
            if pd.notna(total_val) and total_val > 0:
                share_new = (new_val / total_val) * 100 if pd.notna(new_val) else np.nan
                if pd.notna(share_new):
                    retention = max(0.0, 100 - share_new)
                    has_retention = True
            data.append({
                "–ú–µ—Å—è—Ü": month,
                "–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã": new_val,
                "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞": total_val,
                "–î–æ–ª—è –Ω–æ–≤—ã—Ö, %": share_new,
                "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %": retention,
            })
        df_clients = pd.DataFrame(data)
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        fig.add_trace(
            go.Bar(
                x=df_clients["–ú–µ—Å—è—Ü"],
                y=df_clients["–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"],
                name="–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã",
                marker_color="rgba(168,85,247,0.55)",
            ),
            secondary_y=False,
        )
        fig.add_trace(
            go.Scatter(
                x=df_clients["–ú–µ—Å—è—Ü"],
                y=df_clients["–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞"],
                mode="lines+markers",
                name="–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞",
                line=dict(color="#2563eb", width=3),
            ),
            secondary_y=False,
        )
        if has_retention and df_clients["–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"].notna().any():
            fig.add_trace(
                go.Scatter(
                    x=df_clients["–ú–µ—Å—è—Ü"],
                    y=df_clients["–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"],
                    mode="lines+markers",
                    name="–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %",
                    line=dict(color="#10b981", width=3, dash="dot"),
                ),
                secondary_y=True,
            )
        fig.update_layout(
            height=380,
            margin=dict(l=40, r=40, t=40, b=40),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
            hovermode="x unified",
        )
        fig.update_yaxes(title_text="–ö–ª–∏–µ–Ω—Ç–æ–≤", secondary_y=False)
        if has_retention and df_clients["–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"].notna().any():
            fig.update_yaxes(title_text="–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %", secondary_y=True, range=[0, 110])
        else:
            fig.update_yaxes(secondary_y=True, showgrid=False, visible=False)
        st.plotly_chart(fig, use_container_width=True, key="cohort_trend")
        st.caption(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∏: –Ω–æ–≤—ã–µ ‚Äî ¬´{new_metric}¬ª, –±–∞–∑–∞ ‚Äî ¬´{total_metric}¬ª.")

        retention_matrix: Dict[str, Dict[str, float]] = {}
        for idx, month in enumerate(months):
            base = float(total_series.get(month, np.nan)) if total_series is not None else np.nan
            if pd.isna(base) or base <= 0:
                continue
            row: Dict[str, float] = {}
            for lag in range(1, 5):
                if idx + lag >= len(months):
                    break
                next_month = months[idx + lag]
                next_total = float(total_series.get(next_month, np.nan)) if total_series is not None else np.nan
                next_new = float(new_series.get(next_month, 0.0)) if new_series is not None else 0.0
                if pd.isna(next_total):
                    continue
                retained = max(0.0, next_total - max(0.0, next_new))
                row[f"+{lag} –º–µ—Å."] = (retained / base) * 100
            if row:
                retention_matrix[month] = row
        if has_retention and retention_matrix:
            cohort_df = pd.DataFrame(retention_matrix).T.fillna(0.0)
            heat = go.Figure(
                go.Heatmap(
                    z=cohort_df.values,
                    x=cohort_df.columns,
                    y=cohort_df.index,
                    colorscale="Blues",
                    zmin=0,
                    zmax=100,
                    hovertemplate="–°—Ç–∞—Ä—Ç %{y}<br>–ì–æ—Ä–∏–∑–æ–Ω—Ç %{x}<br>–£–¥–µ—Ä–∂–∞–Ω–∏–µ: %{z:.1f}%<extra></extra>",
                )
            )
            heat.update_layout(
                height=360,
                margin=dict(l=40, r=40, t=40, b=60),
            )
            st.plotly_chart(heat, use_container_width=True, key="cohort_heatmap")
            st.caption("–ú–∞—Ç—Ä–∏—Ü–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –¥–æ–ª—è –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π –±–∞–∑—ã –æ—Å—Ç–∞—ë—Ç—Å—è —á–µ—Ä–µ–∑ n –º–µ—Å—è—Ü–µ–≤ (–ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º).")
        else:
            st.caption("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ —Å–∫—Ä—ã—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –≤–≤–æ–¥–∏—Ç—å –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ.")

        st.dataframe(
            df_clients,
            use_container_width=True,
            hide_index=True,
            column_config={
                "–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã": st.column_config.NumberColumn("–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã", format="%.0f"),
                "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞": st.column_config.NumberColumn("–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞", format="%.0f"),
                "–î–æ–ª—è –Ω–æ–≤—ã—Ö, %": st.column_config.NumberColumn("–î–æ–ª—è –Ω–æ–≤—ã—Ö, %", format="%.1f"),
                "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %": st.column_config.NumberColumn("–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %", format="%.1f"),
            },
        )
    else:
        df_new_reg = _extract_region_month_metric(ctx.df_current, ctx.regions, new_metric, ctx.months_range)
        df_total_reg = _extract_region_month_metric(ctx.df_current, ctx.regions, total_metric, ctx.months_range)
        if df_new_reg.empty or df_total_reg.empty:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö.")
            return
        merged = (
            df_total_reg.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞"})
            .merge(df_new_reg.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"}), on=["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"], how="outer")
        )
        merged["–ú–µ—Å—è—Ü"] = pd.Categorical(merged["–ú–µ—Å—è—Ü"], categories=ctx.months_range, ordered=True)
        merged = merged.sort_values(["–ú–µ—Å—è—Ü", "–†–µ–≥–∏–æ–Ω"])
        merged["–î–æ–ª—è –Ω–æ–≤—ã—Ö, %"] = np.where(
            merged["–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞"] > 0,
            (merged["–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"] / merged["–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞"]) * 100,
            np.nan,
        )
        merged["–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"] = np.where(
            merged["–î–æ–ª—è –Ω–æ–≤—ã—Ö, %"].notna(),
            np.clip(100 - merged["–î–æ–ª—è –Ω–æ–≤—ã—Ö, %"], 0, 100),
            np.nan,
        )
        region_order = merged.groupby("–†–µ–≥–∏–æ–Ω")["–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã"].sum().sort_values(ascending=False).index.tolist()
        default_regions = region_order[: min(5, len(region_order))]
        selected_regions = st.multiselect(
            "–†–µ–≥–∏–æ–Ω—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
            options=region_order,
            default=default_regions,
            key="cohort_region_select",
        )
        if not selected_regions:
            st.info("–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º –æ–¥–∏–Ω —Ä–µ–≥–∏–æ–Ω.")
            return
        panel = merged[merged["–†–µ–≥–∏–æ–Ω"].isin(selected_regions)].copy()
        if panel.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º.")
            return
        line_share = px.line(
            panel,
            x="–ú–µ—Å—è—Ü",
            y="–î–æ–ª—è –Ω–æ–≤—ã—Ö, %",
            color="–†–µ–≥–∏–æ–Ω",
            markers=True,
            labels={"–î–æ–ª—è –Ω–æ–≤—ã—Ö, %": "–î–æ–ª—è –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤, %"},
        )
        line_share.update_layout(
            height=360,
            margin=dict(l=40, r=20, t=40, b=40),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
        )
        st.plotly_chart(line_share, use_container_width=True, key="cohort_share_compare")

        if panel["–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"].notna().any():
            line_ret = px.line(
                panel,
                x="–ú–µ—Å—è—Ü",
                y="–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %",
                color="–†–µ–≥–∏–æ–Ω",
                markers=True,
                labels={"–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %": "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"},
            )
            line_ret.update_layout(
                height=360,
                margin=dict(l=40, r=20, t=40, b=40),
                legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
            )
            st.plotly_chart(line_ret, use_container_width=True, key="cohort_ret_compare")

        summary = (
            panel.groupby("–†–µ–≥–∏–æ–Ω", as_index=False)[["–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã", "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞", "–î–æ–ª—è –Ω–æ–≤—ã—Ö, %", "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"]]
            .agg({"–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã": "sum", "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞": "mean", "–î–æ–ª—è –Ω–æ–≤—ã—Ö, %": "mean", "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %": "mean"})
            .sort_values("–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã", ascending=False)
        )
        st.dataframe(
            summary,
            use_container_width=True,
            hide_index=True,
            column_config={
                "–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã": st.column_config.NumberColumn("–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã (Œ£)", format="%.0f"),
                "–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞": st.column_config.NumberColumn("–ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞ (—Å—Ä.)", format="%.0f"),
                "–î–æ–ª—è –Ω–æ–≤—ã—Ö, %": st.column_config.NumberColumn("–î–æ–ª—è –Ω–æ–≤—ã—Ö, % (—Å—Ä.)", format="%.1f"),
                "–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %": st.column_config.NumberColumn("–£–¥–µ—Ä–∂–∞–Ω–∏–µ, % (—Å—Ä.)", format="%.1f"),
            },
        )


def render_market_lab_page(ctx: PageContext) -> None:
    st.markdown("### üß™ –°—Ü–µ–Ω–∞—Ä–∏–∏ ¬´—á—Ç–æ –µ—Å–ª–∏¬ª –ø–æ —Ä—ã–Ω–∫—É")
    st.caption("–ú–æ–¥–µ–ª–∏—Ä—É–µ–º –≤–ª–∏—è–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä—ã–Ω–∫–∞, –¥–æ–ª–∏ –∏ —Å–∫–∏–¥–æ–∫ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ –¥–∏–Ω–∞–º–∏–∫—É —Ä–µ–≥–∏–æ–Ω–æ–≤.")
    base_revenue = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    base_issue = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.LOAN_ISSUE.value, ctx.months_range)
    base_markup = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    base_risk = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.RISK_SHARE.value, ctx.months_range)
    base_loss = period_value_from_itogo(ctx.df_current, ctx.regions, Metrics.BELOW_LOAN.value, ctx.months_range)

    col_market, col_share, col_discount = st.columns(3)
    market_growth = col_market.slider("–†—ã–Ω–æ–∫ (–æ–±—ä—ë–º)", -30, 30, 0, step=2, format="%d%%")
    share_change = col_share.slider("–î–æ–ª—è –∫–æ–º–ø–∞–Ω–∏–∏", -20, 20, 0, step=1, format="%d%%")
    discount_change = col_discount.slider(
        "–°–∫–∏–¥–∫–∏ / –ø—Ä–æ–º–æ",
        -20,
        20,
        0,
        step=1,
        format="%d%%",
        help="–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ —Å–∫–∏–¥–∫–∏, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ ‚Äî —É–∂–µ—Å—Ç–æ—á–∞–µ–º —Ü–µ–Ω–æ–≤—É—é –ø–æ–ª–∏—Ç–∏–∫—É.",
    )

    def _safe(val):
        return float(val) if val is not None and not pd.isna(val) else None

    base_revenue = _safe(base_revenue)
    base_issue = _safe(base_issue)
    base_markup = _safe(_maybe_scale_percent(Metrics.MARKUP_PCT.value, base_markup))
    base_risk = _safe(_maybe_scale_percent(Metrics.RISK_SHARE.value, base_risk))
    base_loss = _safe(base_loss)

    factor_market = 1 + market_growth / 100
    factor_share = 1 + share_change / 100
    factor_discount = 1 - discount_change / 110
    new_revenue = base_revenue * factor_market * factor_share if base_revenue is not None else None
    new_issue = base_issue * factor_market if base_issue is not None else None
    new_markup = max(0.0, base_markup * factor_discount) if base_markup is not None else None
    risk_adjust = 1 + (discount_change / 35) - (share_change / 80)
    new_risk = max(0.0, base_risk * risk_adjust) if base_risk is not None else None
    new_loss = base_loss * (1 + discount_change / 30) if base_loss is not None else None

    col_metric_a, col_metric_b, col_metric_c = st.columns(3)
    col_metric_a.metric(
        "–í—ã—Ä—É—á–∫–∞ (—Ä—ã–Ω–æ–∫)",
        format_rub(new_revenue) if new_revenue is not None else "‚Äî",
        delta=format_rub(new_revenue - base_revenue) if new_revenue is not None and base_revenue is not None else "‚Äî",
    )
    col_metric_b.metric(
        "–ù–∞—Ü–µ–Ω–∫–∞ (–Ω–æ–≤–∞—è)",
        fmt_pct(new_markup) if new_markup is not None else "‚Äî",
        delta=f"{(new_markup - base_markup):+.1f} –ø.–ø." if new_markup is not None and base_markup is not None else "‚Äî",
    )
    if new_risk is not None and base_risk is not None:
        risk_delta = f"{(new_risk - base_risk):+.1f} –ø.–ø."
    else:
        risk_delta = "‚Äî"
    col_metric_c.metric(
        "–†–∏—Å–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞",
        fmt_pct(new_risk) if new_risk is not None else "‚Äî",
        delta=risk_delta,
    )
    st.caption("–†–∞—Å—á—ë—Ç –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–π: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –º–µ–∂–¥—É —Å–∫–∏–¥–∫–∞–º–∏, –¥–æ–ª–µ–π –∏ —Ä–∏—Å–∫–æ–º.")

    risk_df = _extract_region_month_metric(ctx.df_current, ctx.regions, Metrics.RISK_SHARE.value, ctx.months_range)
    markup_df = _extract_region_month_metric(ctx.df_current, ctx.regions, Metrics.MARKUP_PCT.value, ctx.months_range)
    revenue_df = _extract_region_month_metric(ctx.df_current, ctx.regions, Metrics.REVENUE.value, ctx.months_range)
    if not risk_df.empty and not markup_df.empty:
        merged = risk_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Risk"}).merge(
            markup_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Markup"}),
            on=["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"],
            how="inner"
        )
        if not revenue_df.empty:
            merged = merged.merge(
                revenue_df.rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Revenue"}),
                on=["–†–µ–≥–∏–æ–Ω", "–ú–µ—Å—è—Ü"],
                how="left"
            )
        merged["Risk"] = pd.to_numeric(merged["Risk"], errors="coerce")
        merged["Markup"] = pd.to_numeric(merged["Markup"], errors="coerce")
        merged["Revenue"] = pd.to_numeric(merged.get("Revenue"), errors="coerce").fillna(0.0)
        merged = merged.dropna(subset=["Risk", "Markup"])
        if not merged.empty:
            merged["–ú–µ—Å—è—Ü"] = pd.Categorical(merged["–ú–µ—Å—è—Ü"], categories=ctx.months_range, ordered=True)
            merged = merged.sort_values("–ú–µ—Å—è—Ü")
            scatter = px.scatter(
                merged,
                x="Markup",
                y="Risk",
                color="–†–µ–≥–∏–æ–Ω",
                size=merged["Revenue"].clip(lower=0.0) + 1,
                animation_frame="–ú–µ—Å—è—Ü",
                size_max=28,
                labels={"Markup": "–ù–∞—Ü–µ–Ω–∫–∞, %", "Risk": "–†–∏—Å–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞, %"},
            )
            scatter.update_layout(
                height=420,
                margin=dict(l=40, r=40, t=60, b=40),
                legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
                xaxis=dict(
                    title="–ù–∞—Ü–µ–Ω–∫–∞, %",
                    range=[0, max(10.0, float(merged["Markup"].max()) * 1.15)],
                ),
                yaxis=dict(
                    title="–†–∏—Å–∫ –Ω–∏–∂–µ –∑–∞–π–º–∞, %",
                    range=[0, max(5.0, float(merged["Risk"].max()) * 1.25)],
                ),
            )
            st.plotly_chart(scatter, use_container_width=True, key="market_animation")
            st.caption("–ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–Ω–¥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Å–≤—è–∑–∫–∞ ¬´–Ω–∞—Ü–µ–Ω–∫–∞ ‚Üî —Ä–∏—Å–∫¬ª —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ –ø–æ —Ä—ã–Ω–∫—É.")

    insights = []
    if new_revenue is not None and base_revenue is not None:
        insights.append(f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä—ã–Ω–∫–∞ –∏ –¥–æ–ª–∏ –¥–≤–∏–≥–∞–µ—Ç –≤—ã—Ä—É—á–∫—É –Ω–∞ {format_rub(new_revenue - base_revenue)}.")
    if new_markup is not None and base_markup is not None:
        direction = "—Å–Ω–∏–∂–∞–µ—Ç—Å—è" if new_markup < base_markup else "—Ä–∞—Å—Ç—ë—Ç"
        insights.append(f"–ù–∞—Ü–µ–Ω–∫–∞ {direction} –¥–æ {fmt_pct(new_markup)} –ø—Ä–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å–∫–∏–¥–æ—á–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ.")
    if new_risk is not None and base_risk is not None:
        if new_risk > base_risk:
            insights.append("–†–∏—Å–∫ –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ —Ä–∞—Å—Ç—ë—Ç ‚Äî –∑–∞–∫–ª–∞–¥—ã–≤–∞–π—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ª–∏–º–∏—Ç –Ω–∞ —É–±—ã—Ç–∫–∏.")
        else:
            insights.append("–†–∏—Å–∫ —Å–Ω–∏–∂–∞–µ—Ç—Å—è ‚Äî –º–æ–∂–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —É—Å–∏–ª–∏–≤–∞—Ç—å –ø—Ä–æ–º–æ.")
    if new_loss is not None and base_loss is not None:
        insights.append(f"–£–±—ã—Ç–æ–∫ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂: {format_rub(new_loss)} (–∏–∑–º–µ–Ω–µ–Ω–∏–µ {format_rub(new_loss - base_loss)}).")
    if insights:
        bullets = "\n".join(f"- {line}" for line in insights)
        st.markdown(f"**–ß—Ç–æ –≤–∞–∂–Ω–æ:**\n{bullets}")


def render_management_tools(ctx: PageContext, stats_current: Dict[str, Dict[str, Any]], stats_previous: Dict[str, Dict[str, Any]] | None) -> None:
    st.markdown("### üßë‚Äçüíº –£–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç")
    st.caption("–°—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –∫—Ä–∞—Ç–∫–∏–π executive-–¥–∞–π–¥–∂–µ—Å—Ç –∏ –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å –∏–º –≤ Markdown, PDF –∏–ª–∏ e-mail.")
    summary_lines, action_lines = build_metric_recommendations(
        stats_current,
        ctx.scenario_name,
        ctx.months_range,
        baseline_map=stats_previous or None,
    )
    period_label = f"{ctx.months_range[0]} ‚Äì {ctx.months_range[-1]}" if ctx.months_range else "–ü–µ—Ä–∏–æ–¥ –Ω–µ –≤—ã–±—Ä–∞–Ω"
    report_lines = [
        f"# Executive Brief ‚Äî –ù–Æ–ó ({period_label})",
        f"**–°—Ü–µ–Ω–∞—Ä–∏–π:** {ctx.scenario_name}",
        f"**–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞:** {'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤' if ctx.mode == 'compare' else '–û–¥–∏–Ω –≥–æ–¥'}",
        f"**–†–µ–≥–∏–æ–Ω–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ:** {len(ctx.regions)}",
        "",
        "## KPI Snapshot",
    ]
    if summary_lines:
        report_lines.extend(f"- {line}" for line in summary_lines)
    else:
        report_lines.append("- –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤.")
    report_lines.append("")
    report_lines.append("## Priority Actions")
    if action_lines:
        report_lines.extend(f"{idx}. {line}" for idx, line in enumerate(action_lines, start=1))
    else:
        report_lines.append("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, —á—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")
    report_lines.append("")
    report_lines.append("## –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–æ–∫—Ä—ã—Ç–∏–µ")
    report_lines.append(f"- –ü–µ—Ä–∏–æ–¥: {period_label}")
    sample_regions = ", ".join(ctx.regions[:10]) + (" ‚Ä¶" if len(ctx.regions) > 10 else "")
    report_lines.append(f"- –†–µ–≥–∏–æ–Ω—ã: {sample_regions if sample_regions else '–Ω–µ –≤—ã–±—Ä–∞–Ω—ã'}")

    report_md = "\n".join(report_lines)
    report_plain = report_md.replace("**", "").replace("#", "")

    with st.expander("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –æ—Ç—á—ë—Ç–∞", expanded=False):
        st.markdown(report_md)

    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (Markdown)",
        data=report_md.encode("utf-8"),
        file_name="NUZ_management_report.md",
        mime="text/markdown",
    )

    pdf_bytes = None
    try:
        from reportlab.lib.pagesizes import A4  # type: ignore
        from reportlab.pdfgen import canvas  # type: ignore

        buffer = BytesIO()
        canv = canvas.Canvas(buffer, pagesize=A4)
        text = canv.beginText(40, 800)
        text.setFont("Helvetica", 11)
        for line in report_plain.splitlines():
            text.textLine(line)
            if text.getY() <= 40:
                canv.drawText(text)
                canv.showPage()
                text = canv.beginText(40, 800)
                text.setFont("Helvetica", 11)
        canv.drawText(text)
        canv.save()
        pdf_bytes = buffer.getvalue()
    except Exception:
        pdf_bytes = None

    if pdf_bytes:
        st.download_button(
            "‚¨áÔ∏è –û—Ç—á—ë—Ç –≤ PDF",
            data=pdf_bytes,
            file_name="NUZ_management_report.pdf",
            mime="application/pdf",
        )
    else:
        st.caption("–î–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –≤ PDF —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç `reportlab` (`pip install reportlab`).")

    with st.expander("E-mail –¥–∞–π–¥–∂–µ—Å—Ç", expanded=False):
        st.caption("–î–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Å–µ—Å—Å–∏–∏ Streamlit.")
        default_subject = f"NUZ –¥–∞–π–¥–∂–µ—Å—Ç ‚Äî {period_label}"
        smtp_defaults = st.session_state.setdefault(
            "email_digest_defaults",
            {"server": "", "port": 465, "use_ssl": True, "user": "", "recipients": ""},
        )
        with st.form("email_digest_form"):
            smtp_server = st.text_input("SMTP —Å–µ—Ä–≤–µ—Ä", value=smtp_defaults["server"])
            smtp_port = st.number_input("–ü–æ—Ä—Ç", value=smtp_defaults["port"], min_value=1, max_value=65535, step=1)
            use_ssl = st.toggle("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SSL (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", value=smtp_defaults["use_ssl"])
            smtp_user = st.text_input("–õ–æ–≥–∏–Ω", value=smtp_defaults["user"])
            smtp_password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
            recipients = st.text_input("–ü–æ–ª—É—á–∞—Ç–µ–ª–∏", value=smtp_defaults["recipients"], help="–ß–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é")
            subject = st.text_input("–¢–µ–º–∞ –ø–∏—Å—å–º–∞", value=default_subject)
            send_btn = st.form_submit_button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç")

        smtp_defaults.update({"server": smtp_server, "port": smtp_port, "use_ssl": use_ssl, "user": smtp_user, "recipients": recipients})

        if send_btn:
            if not smtp_server or not recipients:
                st.error("–£–∫–∞–∂–∏—Ç–µ SMTP —Å–µ—Ä–≤–µ—Ä –∏ –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π.")
            else:
                try:
                    from email.mime.text import MIMEText  # type: ignore
                    import smtplib  # type: ignore

                    recipient_list = [addr.strip() for addr in recipients.split(",") if addr.strip()]
                    if not recipient_list:
                        st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π.")
                    else:
                        msg = MIMEText(report_plain, "plain", "utf-8")
                        sender = smtp_user or "noreply@example.com"
                        msg["Subject"] = subject
                        msg["From"] = sender
                        msg["To"] = ", ".join(recipient_list)

                        if use_ssl:
                            server = smtplib.SMTP_SSL(smtp_server, int(smtp_port))
                        else:
                            server = smtplib.SMTP(smtp_server, int(smtp_port))
                            server.starttls()
                        if smtp_user and smtp_password:
                            server.login(smtp_user, smtp_password)
                        server.sendmail(sender, recipient_list, msg.as_string())
                        server.quit()
                        st.success("–î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
                except Exception as exc:  # pragma: no cover
                    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–∏—Å—å–º–æ: {exc}")


def render_forecast_page(ctx: PageContext) -> None:
    st.markdown("### üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫")
    st.caption("–ü—Ä–æ–≥–Ω–æ–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –ª–∏–Ω–µ–π–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º 95%.")
    available_metrics = [m for m in FORECAST_METRICS if m in ctx.df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].unique()]
    if not available_metrics:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤.")
        return
    horizon = st.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞, –º–µ—Å.", min_value=1, max_value=6, value=3, step=1, key="forecast_horizon")
    for metric in available_metrics:
        forecast_bundle = _prepare_forecast(ctx.df_current, ctx.regions, ctx.months_range, metric, horizon=horizon)
        if not forecast_bundle:
            continue
        history = forecast_bundle["history"]
        future_labels = forecast_bundle["future_labels"]
        forecast_vals = forecast_bundle["forecast"]
        lower_vals = forecast_bundle["lower"]
        upper_vals = forecast_bundle["upper"]
        next_value = forecast_vals[0]
        delta_value = next_value - float(history.iloc[-1])

        st.markdown(f"#### {metric}")
        col_info, col_chart = st.columns([1, 2])
        with col_info:
            st.metric(
                f"–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {future_labels[0]}",
                _format_value_for_metric(metric, next_value),
                delta=_format_value_for_metric(metric, delta_value)
            )
            model_tag = forecast_bundle.get("selected_model") or forecast_bundle.get("method")
            if model_tag == "seasonal":
                model_text = "–ú–æ–¥–µ–ª—å: –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ + —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü–∞–º"
            else:
                model_text = "–ú–æ–¥–µ–ª—å: –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥"
            st.caption(model_text)
            st.caption(f"–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {forecast_bundle['sigma']:.2f}")
            if forecast_bundle.get("selected_model") == "seasonal" and forecast_bundle.get("seasonal"):
                top_seasonal = sorted(forecast_bundle["seasonal"].items(), key=lambda kv: abs(kv[1]), reverse=True)[:2]
                if top_seasonal:
                    seasonal_desc = ", ".join(
                        f"{ORDER[idx % len(ORDER)]}: {value:+.1f}" for idx, value in top_seasonal
                    )
                    st.caption(f"–°–µ–∑–æ–Ω–Ω—ã–µ –ø–æ–ø—Ä–∞–≤–∫–∏: {seasonal_desc}")
            if forecast_bundle.get("selected_model") == "seasonal" and forecast_bundle.get("baseline_sse") and forecast_bundle.get("sse"):
                base_sse = float(forecast_bundle["baseline_sse"]) or 1e-9
                gain = 1 - (float(forecast_bundle["sse"]) / base_sse)
                st.caption(f"–¢–æ—á–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∞ –Ω–∞ {gain:.1%} –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —á–∏—Å—Ç–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞.")
        with col_chart:
            fig = go.Figure()
            hist_x = [str(x) for x in history.index]
            fig.add_trace(go.Scatter(
                x=hist_x,
                y=history.values,
                mode="lines+markers",
                name="–§–∞–∫—Ç",
                line=dict(color="#2563eb", width=3),
            ))
            forecast_x = [hist_x[-1]] + future_labels
            forecast_y = [history.values[-1]] + forecast_vals
            fig.add_trace(go.Scatter(
                x=forecast_x,
                y=forecast_y,
                mode="lines+markers",
                name="–ü—Ä–æ–≥–Ω–æ–∑",
                line=dict(color="#7c3aed", width=2, dash="dot"),
                marker=dict(symbol="circle"),
            ))
            ci_x = future_labels + future_labels[::-1]
            ci_y = upper_vals + lower_vals[::-1]
            fig.add_trace(go.Scatter(
                x=ci_x,
                y=ci_y,
                fill="toself",
                fillcolor="rgba(124,58,237,0.12)",
                line=dict(width=0),
                hoverinfo="skip",
                name="95% –∏–Ω—Ç–µ—Ä–≤–∞–ª"
            ))
            fig.update_layout(
                height=360,
                margin=dict(l=20, r=20, t=30, b=30),
                legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0),
            )
            fig.update_xaxes(title=None)
            fig.update_yaxes(title=None)
            st.plotly_chart(fig, use_container_width=True, key=f"forecast_{_normalize_metric_label(metric)}")

        summary_df = pd.DataFrame({
            "–ü–µ—Ä–∏–æ–¥": future_labels,
            "–ü—Ä–æ–≥–Ω–æ–∑": forecast_vals,
            "–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞": lower_vals,
            "–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞": upper_vals,
        })
        st.dataframe(
            summary_df,
            hide_index=True,
            use_container_width=True,
            column_config={
                "–ü—Ä–æ–≥–Ω–æ–∑": st.column_config.NumberColumn(format="%.2f"),
                "–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞": st.column_config.NumberColumn(format="%.2f"),
                "–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞": st.column_config.NumberColumn(format="%.2f"),
            }
        )








def scenario_overview_block_single(
    df_scope: pd.DataFrame,
    regions: List[str],
    months_range: List[str],
    scenario_name: str,
    year_selected: int,
    *,
    stats_map: Dict[str, Dict[str, Any]] | None = None,
) -> None:
    if stats_map is None:
        stats_map = {
            metric: compute_metric_stats(df_scope, regions, months_range, metric)
            for metric in KEY_DECISION_METRICS + SUPPORT_DECISION_METRICS
        }
    summary_lines, action_lines = build_metric_recommendations(stats_map, scenario_name, months_range)
    st.markdown(f"### üéØ {scenario_name}: —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç ({year_selected})")
    desc = SCENARIO_DESCRIPTIONS.get(scenario_name)
    if desc:
        st.caption(desc)
    _render_insights("–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã", summary_lines)
    _render_plan("–ü–µ—Ä–≤–∏—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è", action_lines[:6])


def scenario_overview_block_compare(
    df_a: pd.DataFrame,
    df_b: pd.DataFrame,
    regions: List[str],
    months_range: List[str],
    scenario_name: str,
    year_a: int,
    year_b: int,
    *,
    stats_current: Dict[str, Dict[str, Any]] | None = None,
    stats_previous: Dict[str, Dict[str, Any]] | None = None,
) -> None:
    if stats_current is None:
        stats_current = {
            metric: compute_metric_stats(df_b, regions, months_range, metric)
            for metric in KEY_DECISION_METRICS + SUPPORT_DECISION_METRICS
        }
    if stats_previous is None:
        stats_previous = {
            metric: compute_metric_stats(df_a, regions, months_range, metric)
            for metric in KEY_DECISION_METRICS + SUPPORT_DECISION_METRICS
        }
    summary_lines, action_lines = build_metric_recommendations(
        stats_current, scenario_name, months_range, baseline_map=stats_previous
    )
    st.markdown(f"### üéØ {scenario_name}: —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç ({year_b} vs {year_a})")
    desc = SCENARIO_DESCRIPTIONS.get(scenario_name)
    if desc:
        st.caption(desc)
    _render_insights("–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã", summary_lines)
    _render_plan("–ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π", action_lines[:6])


def _build_single_year_prompt(year: int, period_label: str, region_list: List[str], metrics: Dict[str, float | None], *, df_source: pd.DataFrame, months_range: List[str], monthly_context: str, forecast_target: str) -> str:
    metrics_lines = "\n".join(_format_metric_for_prompt(k, metrics.get(k)) for k in AI_METRICS_FOCUS)
    raw_values = {k: (None if metrics.get(k) is None else float(metrics[k])) for k in AI_METRICS_FOCUS}
    regional_lines = _regional_context_block(df_source, region_list, months_range, AI_REGION_METRICS)
    instructions = (
        f"–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ —Å–µ—Ç–∏ –ª–æ–º–±–∞—Ä–¥–æ–≤. –ü–æ–¥–≥–æ—Ç–æ–≤—å –æ—Ç—á—ë—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏—è:\n"
        "1. **–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã** ‚Äî 3 —Ç–µ–∑–∏—Å–∞ —Å –≥–ª–∞–≤–Ω—ã–º–∏ —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è–º–∏; –ø—Ä–∏–≤–æ–¥–∏—Ç–µ —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ —á–∏—Å–ª–∞.\n"
        "2. **–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞** ‚Äî –æ–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ç–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å (–ø–æ –º–µ—Å—è—Ü–∞–º –∏ —Ä–µ–≥–∏–æ–Ω–∞–º), —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –ø—Ä–∏—á–∏–Ω–∞—Ö.\n"
        "3. **–†–∏—Å–∫–∏ –∏ —Å–∏–≥–Ω–∞–ª—ã** ‚Äî 3‚Äì4 –ø—É–Ω–∫—Ç–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º–∏ –∏ –∑–æ–Ω–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è.\n"
        f"4. **–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –ø—Ä–æ–≥–Ω–æ–∑** ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –æ–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç) –∏ –¥–∞–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –ø–µ—Ä–∏–æ–¥ {forecast_target}.\n"
        "–ò–≥–Ω–æ—Ä–∏—Ä—É–π –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–∑–±–µ–≥–∞–π –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –≤—Å–µ—Ö —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥ ‚Äî —Ü–∏—Ç–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –¥–ª—è –∞—Ä–≥—É–º–µ–Ω—Ç–∞."
        "\n–ü—Ä–∞–≤–∏–ª–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏:"
        "\n- –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ < 12%."
        "\n- –î–æ–ª—è –Ω–µ–ª–∏–∫–≤–∏–¥–∞ > 30% ‚Äî –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ —Å–∫–ª–∞–¥–∞."
        "\n- –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å < 15% –ø—Ä–∏ —Ä–æ—Å—Ç–µ –≤—ã–¥–∞—á ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Å—Ä–æ—á–∫—É."
        "\n- –†–µ–∑–∫–∏–π —Ä–æ—Å—Ç –≤—ã—Ä—É—á–∫–∏ –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ –Ω–∞—Ü–µ–Ω–∫–∏ ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã–π –¥–µ–º–ø–∏–Ω–≥."
    )
    text = (
        f"–ü–µ—Ä–∏–æ–¥: {period_label}, –≥–æ–¥: {year}. –†–µ–≥–∏–æ–Ω–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ: {len(region_list)}."
        f"\n–°–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤: {', '.join(region_list[:8])}{'...' if len(region_list) > 8 else ''}."
        f"\n–î–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫:\n{metrics_lines}"
    )
    if regional_lines:
        text += f"\n\n–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ä–µ–∑—ã:\n{regional_lines}"
    if monthly_context:
        text += f"\n\n–ü–æ–º–µ—Å—è—á–Ω—ã–µ —Ä—è–¥—ã:\n{monthly_context}"
    text += f"\n\n–°—ã—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π): {raw_values}"
    text += f"\n–¶–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∞: {forecast_target}"
    text += f"\n\n{instructions}"
    return text


def _build_compare_prompt(year_a: int, year_b: int, period_label: str, region_list: List[str], metrics_a: Dict[str, float | None], metrics_b: Dict[str, float | None], *, df_a: pd.DataFrame, df_b: pd.DataFrame, months_range: List[str], monthly_a: str, monthly_b: str, forecast_target: str) -> str:
    def fmt_pair(metric: str) -> str:
        v_a, v_b = metrics_a.get(metric), metrics_b.get(metric)
        if v_a is None and v_b is None:
            return f"{metric}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        delta = None
        if v_a is not None and v_b is not None:
            delta = v_b - v_a
        base = f"{_format_metric_for_prompt(metric, v_a)} ‚Üí {year_b}: {_format_metric_for_prompt(metric, v_b)}"
        if delta is None:
            return base
        if is_percent_metric(metric):
            return base + f" (Œî={delta:.2f} –ø.–ø.)"
        if "—Ä—É–±" in metric:
            return base + f" (Œî={delta:,.0f} —Ä—É–±)".replace(",", " ")
        return base + f" (Œî={delta:,.0f})".replace(",", " ")

    lines = "\n".join(fmt_pair(m) for m in AI_METRICS_FOCUS)
    raw_block = {
        metric: {
            str(year_a): None if metrics_a.get(metric) is None else float(metrics_a[metric]),
            str(year_b): None if metrics_b.get(metric) is None else float(metrics_b[metric]),
        }
        for metric in AI_METRICS_FOCUS
    }
    regional_a = _regional_context_block(df_a, region_list, months_range, AI_REGION_METRICS)
    regional_b = _regional_context_block(df_b, region_list, months_range, AI_REGION_METRICS)
    instructions = (
        f"–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫. –ü–æ–¥–≥–æ—Ç–æ–≤—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤, –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—è—Å—å –Ω–∞ —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è:\n"
        "1. **–ò—Ç–æ–≥–∏** ‚Äî 3‚Äì4 –∫–ª—é—á–µ–≤—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å –∫—Ä–∞—Ç–∫–∏–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —Ü–∏—Ñ—Ä—ã).\n"
        "2. **–ü–æ–º–µ—Å—è—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ** ‚Äî –æ–±—ä—è—Å–Ω–∏ 2‚Äì3 –Ω–∞–∏–±–æ–ª—å—à–∏—Ö —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –∏—Ö –ø—Ä–∏—á–∏–Ω—ã.\n"
        "3. **–†–∏—Å–∫–∏ –∏ —Å–∏–≥–Ω–∞–ª—ã** ‚Äî 3 –ø—É–Ω–∫—Ç–∞ —Å –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º–∏ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞.\n"
        f"4. **–î–µ–π—Å—Ç–≤–∏—è –∏ –ø—Ä–æ–≥–Ω–æ–∑** ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –æ–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç) –∏ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –ø–µ—Ä–∏–æ–¥ {forecast_target} –¥–ª—è {year_b}.\n"
        "–ò–∑–±–µ–≥–∞–π –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –≤—Å–µ—Ö —á–∏—Å–µ–ª –ø–æ–¥—Ä—è–¥; —É–ø–æ–º–∏–Ω–∞–π —Ç–æ–ª—å–∫–æ —Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è, –±–µ–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–≤–æ–¥ –Ω–µ—É–±–µ–¥–∏—Ç–µ–ª–µ–Ω."
    )
    text = (
        f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ {year_b} –ø—Ä–æ—Ç–∏–≤ {year_a}, –ø–µ—Ä–∏–æ–¥: {period_label}. –†–µ–≥–∏–æ–Ω–æ–≤: {len(region_list)}."
        f"\n–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {', '.join(region_list[:8])}{'...' if len(region_list) > 8 else ''}."
        f"\n–ú–µ—Ç—Ä–∏–∫–∏:\n{lines}"
    )
    if regional_a:
        text += f"\n\n{year_a}:\n{regional_a}"
    if regional_b:
        text += f"\n\n{year_b}:\n{regional_b}"
    if monthly_a:
        text += f"\n\n{year_a} –ø–æ–º–µ—Å—è—á–Ω–æ:\n{monthly_a}"
    if monthly_b:
        text += f"\n\n{year_b} –ø–æ–º–µ—Å—è—á–Ω–æ:\n{monthly_b}"
    text += f"\n\n–°—ã—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {raw_block}"
    text += f"\n–¶–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∞: {forecast_target}"
    text += f"\n\n{instructions}"
    return text


GEMINI_ENDPOINT_BASE = "https://generativelanguage.googleapis.com/v1beta/models"
GEMINI_DEFAULT_MODEL = "gemini-2.0-flash"
GEMINI_MODELS = [
    "gemini-2.0-flash",
    "gemini-1.5-flash",
    "gemini-1.5-pro",
]


def _call_gemini(api_key: str, prompt: str, model: str = GEMINI_DEFAULT_MODEL, *, timeout: int = 40) -> str:
    api_key = api_key.strip()
    if not api_key:
        raise RuntimeError("Gemini API-–∫–ª—é—á –ø—É—Å—Ç–æ–π.")
    url = f"{GEMINI_ENDPOINT_BASE}/{model}:generateContent"
    headers = {"Content-Type": "application/json", "X-Goog-Api-Key": api_key}
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": str(prompt)}
                ]
            }
        ]
    }
    resp = requests.post(url, headers=headers, json=payload, timeout=timeout)
    if resp.status_code != 200:
        raise RuntimeError(f"Gemini API –≤–µ—Ä–Ω—É–ª {resp.status_code}: {resp.text[:200]}")
    try:
        data = resp.json()
        candidates = data.get("candidates") or []
        if not candidates:
            raise KeyError("candidates")
        parts = candidates[0].get("content", {}).get("parts") or []
        if not parts:
            raise KeyError("parts")
        texts = [p.get("text", "") for p in parts if isinstance(p, dict)]
        joined = "\n".join(t for t in texts if t)
        return joined.strip() or "(Gemini –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç)"
    except (KeyError, ValueError, TypeError) as exc:
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç Gemini: {resp.text[:200]}") from exc


def _resolve_gemini_key() -> str:
    cached = st.session_state.get("ai_gemini_key")
    if cached:
        return cached
    try:
        return st.secrets["GEMINI_API_KEY"]
    except Exception:
        return ""


def _save_gemini_key(value: str) -> None:
    if value:
        st.session_state["ai_gemini_key"] = value.strip()


def ai_analysis_block_single_year(df_scope: pd.DataFrame, regions: List[str], months_range: List[str], year_selected: int) -> None:
    st.subheader("ü§ñ AI-–∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–∏–æ–¥–∞")
    st.caption("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Gemini. –ü–µ—Ä–µ–¥–∞–≤–∞–π—Ç–µ –æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

    if "ai_gemini_key_input" not in st.session_state:
        st.session_state["ai_gemini_key_input"] = _resolve_gemini_key()
    gemini_key = st.text_input(
        "Gemini API-–∫–ª—é—á",
        type="password",
        key="ai_gemini_key_input",
        help="–°–æ–∑–¥–∞–π—Ç–µ –∫–ª—é—á –≤ Google AI Studio –∏ —Ö—Ä–∞–Ω–∏—Ç–µ –µ–≥–æ –≤ —Å–µ–∫—Ä–µ—Ç–µ."
    )
    _save_gemini_key(gemini_key)
    default_index = GEMINI_MODELS.index(GEMINI_DEFAULT_MODEL) if GEMINI_DEFAULT_MODEL in GEMINI_MODELS else 0
    model_id = st.selectbox(
        "–ú–æ–¥–µ–ª—å Gemini",
        options=GEMINI_MODELS,
        index=default_index,
        key="ai_gemini_model_single",
        help="–í—ã–∑–æ–≤—ã –∏–¥—É—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ Google Generative Language API."
    )

    period_label = months_range[0] if len(months_range) == 1 else f"{months_range[0]} ‚Äì {months_range[-1]}"
    metrics = _collect_period_metrics(df_scope, regions, months_range)

    metrics_df = pd.DataFrame(
        {
            "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": list(metrics.keys()),
            "–ó–Ω–∞—á–µ–Ω–∏–µ": [
                fmt_pct(v) if is_percent_metric(k) else (
                    fmt_days(v) if "–¥–Ω–µ–π" in k else format_rub(v) if "—Ä—É–±" in k else ("‚Äî" if v is None else f"{v:,.0f}".replace(",", " "))
                )
                for k, v in metrics.items()
            ],
        }
    )
    st.dataframe(metrics_df, use_container_width=True, hide_index=True)

    cache = st.session_state.setdefault("ai_analysis_cache", {})
    cache_key = (
        "single",
        model_id,
        year_selected,
        tuple(sorted(regions)),
        tuple(months_range),
        tuple(sorted((k, None if metrics[k] is None else round(float(metrics[k]), 4)) for k in metrics))
    )

    monthly_context = _monthly_context_block(df_scope, regions, months_range, AI_METRICS_FOCUS)
    forecast_target = _forecast_target_label(months_range[-1]) if months_range else "–°–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥"

    prompt = _build_single_year_prompt(
        year_selected,
        period_label,
        regions,
        metrics,
        df_source=df_scope,
        months_range=months_range,
        monthly_context=monthly_context,
        forecast_target=forecast_target,
    )
    with st.expander("–ü—Ä–æ–º–ø—Ç (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)", expanded=False):
        st.code(prompt)

    result_placeholder = st.empty()
    if cache_key in cache:
        result_placeholder.markdown(cache[cache_key])

    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary"):
        if not gemini_key:
            st.error("–í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á Gemini.")
            return
        call_func = lambda: _call_gemini(gemini_key, prompt, model=model_id)
        with st.spinner("–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –º–æ–¥–µ–ª—å‚Ä¶"):
            try:
                ai_text = call_func()
                cache[cache_key] = ai_text
                result_placeholder.markdown(ai_text)
            except Exception as exc:
                st.error(str(exc))


def ai_analysis_block_comparison(df_a: pd.DataFrame, df_b: pd.DataFrame, regions: List[str], months_range: List[str], year_a: int, year_b: int) -> None:
    st.subheader("ü§ñ AI-–∞–Ω–∞–ª–∏–∑ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤)")
    st.caption("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Google Gemini ‚Äî –∫–ª—é—á —Ö—Ä–∞–Ω–∏—Ç–µ –≤ —Å–µ–∫—Ä–µ—Ç–µ.")

    if "ai_gemini_key_input" not in st.session_state:
        st.session_state["ai_gemini_key_input"] = _resolve_gemini_key()
    gemini_key = st.text_input(
        "Gemini API-–∫–ª—é—á",
        type="password",
        key="ai_gemini_key_input",
        help="–°–æ–∑–¥–∞–π—Ç–µ –∫–ª—é—á –≤ Google AI Studio –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –µ–≥–æ —Å—é–¥–∞."
    )
    _save_gemini_key(gemini_key)
    default_index = GEMINI_MODELS.index(GEMINI_DEFAULT_MODEL) if GEMINI_DEFAULT_MODEL in GEMINI_MODELS else 0
    model_id = st.selectbox(
        "–ú–æ–¥–µ–ª—å Gemini",
        options=GEMINI_MODELS,
        index=default_index,
        key="ai_gemini_model_compare",
        help="–í—ã–∑–æ–≤—ã –∏–¥—É—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ Google Generative Language API."
    )

    period_label = months_range[0] if len(months_range) == 1 else f"{months_range[0]} ‚Äì {months_range[-1]}"
    metrics_a, metrics_b = _collect_comparison_metrics(df_a, df_b, regions, months_range)

    df_display = pd.DataFrame(
        {
            "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": AI_METRICS_FOCUS,
            f"{year_a}": [metrics_a.get(m) for m in AI_METRICS_FOCUS],
            f"{year_b}": [metrics_b.get(m) for m in AI_METRICS_FOCUS],
        }
    )
    for col in [f"{year_a}", f"{year_b}"]:
        df_display[col] = [
            fmt_pct(v) if is_percent_metric(metric) else (
                fmt_days(v) if "–¥–Ω–µ–π" in metric else format_rub(v) if "—Ä—É–±" in metric else ("‚Äî" if v is None else f"{v:,.0f}".replace(",", " "))
            )
            for metric, v in zip(AI_METRICS_FOCUS, [metrics_a.get(metric) if col == f"{year_a}" else metrics_b.get(metric) for metric in AI_METRICS_FOCUS])
        ]
    st.dataframe(df_display, use_container_width=True, hide_index=True)

    cache = st.session_state.setdefault("ai_analysis_cache", {})
    cache_key = (
        "compare",
        model_id,
        year_a,
        year_b,
        tuple(sorted(regions)),
        tuple(months_range),
        tuple(sorted((metric, None if metrics_a.get(metric) is None else round(float(metrics_a[metric]), 4)) for metric in AI_METRICS_FOCUS)),
        tuple(sorted((metric, None if metrics_b.get(metric) is None else round(float(metrics_b[metric]), 4)) for metric in AI_METRICS_FOCUS))
    )

    monthly_a = _monthly_context_block(df_a, regions, months_range, AI_METRICS_FOCUS)
    monthly_b = _monthly_context_block(df_b, regions, months_range, AI_METRICS_FOCUS)
    forecast_target = _forecast_target_label(months_range[-1]) if months_range else "–°–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥"

    prompt = _build_compare_prompt(
        year_a,
        year_b,
        period_label,
        regions,
        metrics_a,
        metrics_b,
        df_a=df_a,
        df_b=df_b,
        months_range=months_range,
        monthly_a=monthly_a,
        monthly_b=monthly_b,
        forecast_target=forecast_target,
    )
    with st.expander("–ü—Ä–æ–º–ø—Ç (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)", expanded=False):
        st.code(prompt)

    result_placeholder = st.empty()
    if cache_key in cache:
        result_placeholder.markdown(cache[cache_key])

    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary"):
        if not gemini_key:
            st.error("–í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á Gemini.")
            return
        call_func = lambda: _call_gemini(gemini_key, prompt, model=model_id)
        with st.spinner("–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –º–æ–¥–µ–ª—å‚Ä¶"):
            try:
                ai_text = call_func()
                cache[cache_key] = ai_text
                result_placeholder.markdown(ai_text)
            except Exception as exc:
                st.error(str(exc))

def y_fmt_for_metric(m: str) -> tuple[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (plotly tickformat, suffix_for_hover)"""
    if ("—Ä—É–±" in m) or (m == Metrics.DEBT.value):
        return ",.0f", " ‚ÇΩ"
    if m == Metrics.DEBT_UNITS.value:
        return ",.0f", " —à—Ç"
    if is_percent_metric(m):
        return ".2f", "%"
    if "–¥–Ω–µ–π" in m:
        return ".2f", " –¥–Ω."
    return ",.2f", ""

def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:
    if isinstance(df.columns, pd.CategoricalIndex):
        df.columns = df.columns.astype(str)
    df.columns.name = None
    return df

def detect_category(raw_text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫ —á–µ–º—É –æ—Ç–Ω–æ—Å–∏—Ç—Å—è —Å—Ç—Ä–æ–∫–∞: –ù–Æ–ó / –Æ–ó / –û–±—â–µ–µ (–±–µ–∑ —è–≤–Ω–æ–π –º–µ—Ç–∫–∏)."""
    s = (raw_text or "").lower()
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –ù–Æ–ó / –Æ–ó (—É—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –ø—Ä–æ–±–µ–ª—ã)
    has_nuz = re.search(r"\b–Ω\s*—é\s*–∑\b|–Ω—é–∑", s) is not None
    has_yuz = re.search(r"\b—é\s*–∑\b|—é–∑", s) is not None
    if has_nuz and not has_yuz:
        return "–ù–Æ–ó"
    if has_yuz and not has_nuz:
        return "–Æ–ó"
    return "–û–±—â–µ–µ"

def normalize_metric_name(name: str) -> str:
    if name is None:
        return ""
    key = _normalize_metric_label(name)
    return METRIC_ALIAS_MAP.get(key, "")

def normalize_month_token(x) -> str | None:
    RUS_MONTHS = {
        "—è–Ω–≤–∞—Ä—å": "–Ø–Ω–≤–∞—Ä—å", "—è–Ω–≤": "–Ø–Ω–≤–∞—Ä—å", "—Ñ–µ–≤—Ä–∞–ª—å": "–§–µ–≤—Ä–∞–ª—å", "—Ñ–µ–≤": "–§–µ–≤—Ä–∞–ª—å",
        "–º–∞—Ä—Ç": "–ú–∞—Ä—Ç", "–º–∞—Ä": "–ú–∞—Ä—Ç", "–∞–ø—Ä–µ–ª—å": "–ê–ø—Ä–µ–ª—å", "–∞–ø—Ä": "–ê–ø—Ä–µ–ª—å",
        "–º–∞–π": "–ú–∞–π", "–∏—é–Ω—å": "–ò—é–Ω—å", "–∏—é–ª—å": "–ò—é–ª—å", "–∞–≤–≥—É—Å—Ç": "–ê–≤–≥—É—Å—Ç", "–∞–≤–≥": "–ê–≤–≥—É—Å—Ç",
        "—Å–µ–Ω—Ç—è–±—Ä—å": "–°–µ–Ω—Ç—è–±—Ä—å", "—Å–µ–Ω": "–°–µ–Ω—Ç—è–±—Ä—å", "–æ–∫—Ç—è–±—Ä—å": "–û–∫—Ç—è–±—Ä—å", "–æ–∫—Ç": "–û–∫—Ç—è–±—Ä—å",
        "–Ω–æ—è–±—Ä—å": "–ù–æ—è–±—Ä—å", "–Ω–æ—è": "–ù–æ—è–±—Ä—å", "–¥–µ–∫–∞–±—Ä—å": "–î–µ–∫–∞–±—Ä—å", "–¥–µ–∫": "–î–µ–∫–∞–±—Ä—å",
        "–∏—Ç–æ–≥–æ": "–ò—Ç–æ–≥–æ", "–∏—Ç–æ–≥": "–ò—Ç–æ–≥–æ"
    }
    if x is None: return None
    s = str(x).strip().lower().replace(".", "")
    s = re.sub(r"[\d\s–≥–≥–æ–¥]+$", "", s).strip()
    return RUS_MONTHS.get(s)

@st.cache_data
def consistent_color_map(keys: Tuple[str, ...]) -> Dict[str, str]:
    pal = (qcolors.Plotly + qcolors.D3 + qcolors.Set3 + qcolors.Dark24 + qcolors.Light24)
    return {k: pal[i % len(pal)] for i, k in enumerate(sorted(map(str, keys)))}

def detect_month_header(df: pd.DataFrame, max_header_rows: int = 15) -> tuple[int, list[tuple[int, str]]] | None:
    for r in range(min(max_header_rows, len(df))):
        row = df.iloc[r, :].tolist()
        month_cols = [(j, m) for j, val in enumerate(row) if (m := normalize_month_token(val)) in ORDER_WITH_TOTAL]
        if len({m for _, m in month_cols if m in ORDER}) >= 3:
            cleaned = []
            last_m = None
            for j, m in sorted(month_cols, key=lambda x: x[0]):
                if m != last_m:
                    cleaned.append((j, m))
                    last_m = m
            return r, cleaned
    return None

def guess_data_sheet(xl: pd.ExcelFile) -> str:
    if "TDSheet" in xl.sheet_names: return "TDSheet"
    best, best_score = None, -1
    for sh in xl.sheet_names:
        try:
            tmp = xl.parse(sh, header=None, nrows=15)
            det = detect_month_header(tmp)
            sc = len(det[1]) if det else 0
            if sc > best_score: best, best_score = sh, sc
        except Exception:
            continue
    return best or xl.sheet_names[0]

def _canonical_region_from_file(stem: str, df_head: pd.DataFrame) -> str:
    # 1) –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ "–ò—Ç–æ–≥–æ <–†–µ–≥–∏–æ–Ω>" –∏–∑ —Ç–µ–ª–∞ —Ñ–∞–π–ª–∞
    try:
        c0 = df_head.iloc[1, 0]
        if isinstance(c0, str) and c0.strip().lower().startswith("–∏—Ç–æ–≥–æ"):
            reg = re.sub(r"^\s*–∏—Ç–æ–≥–æ\s+", "", c0.strip(), flags=re.IGNORECASE)
            return re.sub(r"\s{2,}", " ", reg).strip(" _-¬∑.")
    except Exception:
        pass

    # 2) –ß–∏—Å—Ç–∏–º –∏–º—è —Ñ–∞–π–ª–∞
    s = stem
    # —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
    s = re.sub(r"(?i)\b(–∏—Ç–æ–≥–æ|–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏[—è–µ]|—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω\w*|–¥–∞–Ω–Ω\w*)\b", "", s)
    # —É–±–∏—Ä–∞–µ–º –ª—é–±—ã–µ –≥–æ–¥—ã 20xx
    s = re.sub(r"\b20\d{2}\b", "", s)
    # —É–±–∏—Ä–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –º–µ—Å—è—Ü–µ–≤ –≤–∏–¥–∞ "1-8", "01_08", "1‚Äì8"
    s = re.sub(r"\b\d{1,2}\s*[-‚Äì‚Äî_]\s*\d{1,2}\b", "", s)
    # —É–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ —Ö–≤–æ—Å—Ç—ã
    s = re.sub(r"[ _\-‚Äì‚Äî]*\d+\b", "", s)
    # –ø—Ä–∏–≤–æ–¥–∏–º –ø—Ä–æ–±–µ–ª—ã –∏ –æ–±—Ä–µ–∑–∞–µ–º –º—É—Å–æ—Ä
    s = re.sub(r"\s{2,}", " ", s).strip(" _-¬∑.")
    # –∫–∞—Å—Ç–æ–º–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    if re.match(r"(?i)^(–∫–∫|–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä)", s): s = "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π"
    if re.fullmatch(r"(?i)—Å–∞–Ω–∫—Ç(?:-|\s*)–ø–µ—Ç–µ—Ä–±—É—Ä–≥|—Å–∞–Ω–∫—Ç", s): s = "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"
    return s or stem

@st.cache_data(show_spinner="–ß–∏—Ç–∞—é –∏ —Ä–∞–∑–±–∏—Ä–∞—é —Ñ–∞–π–ª—ã‚Ä¶")
def parse_excel(file_bytes: bytes, region_name: str, file_year: int | None = None) -> pd.DataFrame:
    def coerce_number(x) -> float:
        if x is None or (isinstance(x, float) and np.isnan(x)): return np.nan
        s = str(x).strip()
        if s in {"", "-", "‚Äî", "NA", "NaN", "nan"}: return np.nan
        if s.endswith("%"):
            try:
                s = s[:-1].strip().replace("\u00A0","").replace(" ","").replace(",", ".")
                return float(s)
            except (ValueError, TypeError):
                return np.nan
        s = s.replace("\u00A0","").replace(" ","")
        if s.count(",") == 1 and s.count(".") > 1: s = s.replace(".", "").replace(",", ".")
        elif s.count(",") > 1 and s.count(".") <= 1: s = s.replace(",", "")
        elif s.count(",") == 1 and s.count(".") == 0: s = s.replace(",", ".")
        try: return float(s)
        except (ValueError, TypeError): return np.nan

    xl = pd.ExcelFile(BytesIO(file_bytes))
    sheet = guess_data_sheet(xl)
    df = xl.parse(sheet, header=None)

    head = df.head(5)
    canonical_region = _canonical_region_from_file(Path(region_name).stem, head)
    first_c0 = next((str(x).strip() for x in df.iloc[:,0].dropna().tolist() if str(x).strip()), "")
    is_totals_file = bool(re.match(r"(?i)^\s*–∏—Ç–æ–≥–æ\b", first_c0))

    det = detect_month_header(df)
    if not det:
        raise ValueError(f"–ù–µ –Ω–∞—à–ª–∏ —Å—Ç—Ä–æ–∫—É –º–µ—Å—è—Ü–µ–≤ –Ω–∞ –ª–∏—Å—Ç–µ '{sheet}'.")
    header_row, month_cols = det
    month_map = {j: m for j, m in sorted(month_cols, key=lambda x: x[0])}
    month_indices = list(month_map.keys())
    first_month_col = min(month_indices)

    rows = []
    current_branch = ""
    last_cat = "–û–±—â–µ–µ"
    for r in range(header_row + 1, len(df)):
        cell0 = df.iat[r, 0] if df.shape[1] > 0 else None
        if isinstance(cell0, str) and cell0.strip():
            current_branch = cell0.strip()

        metric_cell = None
        for c in range(first_month_col - 1, -1, -1):
            val = df.iat[r, c]
            if isinstance(val, str) and val.strip():
                metric_cell = val.strip()
                break
        if not metric_cell:
            continue

        metric_name = normalize_metric_name(metric_cell)
        if not metric_name:
            continue

        # ‚õîÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ –Ω–µ –∏–∑ –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞
        if metric_name not in ACCEPTED_METRICS_CANONICAL:
            continue

        # –ù–û–í–û–ï: —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –ª–µ–≤—ã—Ö —è—á–µ–µ–∫ —Å—Ç—Ä–æ–∫–∏ (–≤—Å–µ –¥–æ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –º–µ—Å—è—Ü–µ–≤)
        left_cells = []
        for c in range(0, first_month_col):
            val = df.iat[r, c]
            if isinstance(val, str) and val.strip():
                left_cells.append(val.strip())
        left_blob = " ".join(left_cells).lower()

        # –ë–∞–∑–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–µ—Ç—Ä–∏–∫–∏
        cat = detect_category(metric_cell)

        # –ï—Å–ª–∏ –º–µ—Ç–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–∞–º–æ–π –º–µ—Ç—Ä–∏–∫–µ ‚Äî –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–æ–∫–∏
        if cat == "–û–±—â–µ–µ":
            # 1) –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            cat = detect_category(current_branch)
            # 2) —Ç–µ–∫—Å—Ç –≤ –ª–µ–≤–æ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–æ–∫–∏
            if cat == "–û–±—â–µ–µ":
                if re.search(r"\b–Ω\s*—é\s*–∑\b|–Ω—é–∑", left_blob):
                    cat = "–ù–Æ–ó"
                elif re.search(r"\b—é\s*–∑\b|—é–∑", left_blob):
                    cat = "–Æ–ó"
                else:
                    cat = last_cat  # 3) –Ω–∞—Å–ª–µ–¥—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —è–≤–Ω—É—é –º–µ—Ç–∫—É –≤ –±–ª–æ–∫–µ

        override_cat = METRIC_CATEGORY_OVERRIDES.get(metric_name)
        if override_cat:
            cat = override_cat

        if NUZ_ONLY and str(cat).strip().lower() != "–Ω—é–∑":
            continue

        # –û–±–Ω–æ–≤–ª—è–µ–º ¬´–ª–∏–ø–∫—É—é¬ª –º–µ—Ç–∫—É, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —è–≤–Ω—É—é
        if cat in {"–ù–Æ–ó", "–Æ–ó"}:
            last_cat = cat

        code_match = re.search(r"‚Ññ\s*(\d+)", str(current_branch))
        code = code_match.group(1) if code_match else ""

        month_values = []
        raw_total_value = np.nan
        for j in month_indices:
            month_label = month_map[j]
            value = coerce_number(df.iat[r, j])
            if month_label == "–ò—Ç–æ–≥–æ":
                raw_total_value = value
                continue
            month_values.append((month_label, value))

        if not month_values:
            continue

        arr = np.array([val for _, val in month_values], dtype=float)
        mask_fact = ~np.isnan(arr)
        if not mask_fact.any():
            continue

        first, last = int(np.where(mask_fact)[0][0]), int(np.where(mask_fact)[0][-1])
        clean_months: list[tuple[str, float]] = []
        for idx, (month_label, value) in enumerate(month_values):
            if np.isnan(value) or ((idx < first or idx > last) and (abs(value) <= 1e-12)):
                continue
            clean_months.append((month_label, float(value)))
            rows.append({
                "–†–µ–≥–∏–æ–Ω": str(canonical_region),
                "–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞": "TOTALS_FILE" if is_totals_file else "BRANCHES_FILE",
                "–ö–æ–¥": code,
                "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ": str(current_branch),
                "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": metric_name,
                "–ú–µ—Å—è—Ü": month_label,
                "–ó–Ω–∞—á–µ–Ω–∏–µ": float(value),
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": cat,
            })

        if not clean_months:
            continue

        total_value = np.nan
        series = pd.Series([val for _, val in clean_months], index=[m for m, _ in clean_months], dtype=float)
        rule = aggregation_rule(metric_name)

        if rule == "sum":
            total_value = float(series.sum())
        elif rule == "mean":
            total_value = float(series.mean())
        elif rule == "last":
            total_value = float(series.iloc[-1])

        if np.isnan(total_value) and not np.isnan(raw_total_value):
            total_value = float(raw_total_value)

        if not np.isnan(total_value):
            rows.append({
                "–†–µ–≥–∏–æ–Ω": str(canonical_region),
                "–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞": "RECALC_TOTAL",
                "–ö–æ–¥": code,
                "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ": str(current_branch),
                "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": metric_name,
                "–ú–µ—Å—è—Ü": "–ò—Ç–æ–≥–æ",
                "–ó–Ω–∞—á–µ–Ω–∏–µ": float(total_value),
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": cat,
            })

    out = pd.DataFrame(rows)
    if out.empty:
        raise ValueError("–î–∞–Ω–Ω—ã–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã.")

    if NUZ_ONLY:
        mask_nuz = (
            out.get("–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
               .astype(str)
               .str.strip()
               .str.lower()
               .eq("–Ω—é–∑")
        )
        out = out.loc[mask_nuz].copy()
        if out.empty:
            raise ValueError("–í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ –ù–Æ–ó.")

    out["–ì–æ–¥"] = int(file_year) if file_year else pd.NA
    out["–ú–µ—Å—è—Ü"] = pd.Categorical(out["–ú–µ—Å—è—Ü"].astype(str), categories=ORDER_WITH_TOTAL, ordered=True)
    for c in ["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ö–æ–¥", "–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è"]:
        out[c] = out[c].astype("string")
    return out

def apply_economic_derivatives(df: pd.DataFrame) -> pd.DataFrame:
    # –í —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –¥–æ–ª–∂–Ω–∞ –Ω–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å, —Ç–∞–∫ –∫–∞–∫ –º—ã –Ω–µ —Å–æ–∑–¥–∞–µ–º derived –º–µ—Ç—Ä–∏–∫–∏
    if SIMPLE_MODE:
        return df

    out = df.copy()
    def div(a,b,scale=1.0):
        return (pd.to_numeric(out.get(a), errors="coerce") /
                pd.to_numeric(out.get(b), errors="coerce").replace(0, np.nan)) * scale

    if Metrics.AVG_LOAN.value not in out and {Metrics.LOAN_ISSUE.value, Metrics.LOAN_ISSUE_UNITS.value} <= set(out.columns):
        out[Metrics.AVG_LOAN.value] = div(Metrics.LOAN_ISSUE.value, Metrics.LOAN_ISSUE_UNITS.value)

    if Metrics.MARKUP_PCT.value not in out and {Metrics.MARKUP_AMOUNT.value, Metrics.REVENUE.value} <= set(out.columns):
        out[Metrics.MARKUP_PCT.value] = div(Metrics.MARKUP_AMOUNT.value, Metrics.REVENUE.value, 100.0)

    if Metrics.RISK_SHARE.value not in out and {Metrics.BELOW_LOAN.value, Metrics.REVENUE.value} <= set(out.columns):
        out[Metrics.RISK_SHARE.value] = div(Metrics.BELOW_LOAN.value, Metrics.REVENUE.value, 100.0)

    if Metrics.YIELD.value not in out and {Metrics.PENALTIES_RECEIVED.value, Metrics.LOAN_ISSUE.value} <= set(out.columns):
        out[Metrics.YIELD.value] = div(Metrics.PENALTIES_RECEIVED.value, Metrics.LOAN_ISSUE.value, 100.0)

    return out

def normalize_percent_series(s: pd.Series) -> pd.Series:
    x = pd.to_numeric(s, errors="coerce")
    clean = x.dropna()
    if not clean.empty and (clean.abs() <= 2).all(): x = x * 100.0
    return x

def strip_totals_rows(df: pd.DataFrame) -> pd.DataFrame:
    mask = ~df["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].str.contains(r"^\s*–∏—Ç–æ–≥–æ\b", case=False, na=False)
    return df.loc[mask]

@st.cache_data
def get_aggregated_data(df_raw: pd.DataFrame, regions: Tuple[str, ...], months: Tuple[str, ...]) -> pd.DataFrame:
    df = strip_totals_rows(df_raw)
    sub = df[df["–†–µ–≥–∏–æ–Ω"].isin(regions) & df["–ú–µ—Å—è—Ü"].isin(months)]
    if sub.empty: return pd.DataFrame()
    all_entities_df = (sub[["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"]].drop_duplicates().sort_values(by=["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"]).set_index(["–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"]))

    # --- —Å—É–º–º—ã ---
    df_sum = (sub[sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].isin(METRICS_SUM)]
              .groupby(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
              .sum().unstack())
    df_sum = _flatten_columns(df_sum)
    result = all_entities_df.join(df_sum, how="left")

    # --- last (—Å–Ω–∏–º–∫–∏ –Ω–∞ –∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞) ---
    if METRICS_LAST:
        snap = sub[sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].isin(METRICS_LAST)].copy()
        if not snap.empty:
            # –í–∞–∂–Ω–æ: '–ú–µ—Å—è—Ü' ‚Äî —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ
            snap['–ú–µ—Å—è—Ü'] = pd.Categorical(snap['–ú–µ—Å—è—Ü'].astype(str), categories=ORDER, ordered=True)
            snap = snap.sort_values(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å","–ú–µ—Å—è—Ü"])
            df_last = (snap.groupby(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"], observed=True)
                            .tail(1)
                            .set_index(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"])["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                            .unstack())
            df_last = _flatten_columns(df_last)
            result = result.join(df_last, how="left")

    # --- —Å—Ä–µ–¥–Ω–∏–µ ---
    metrics_to_average = METRICS_MEAN - ({Metrics.RISK_SHARE.value} if not SIMPLE_MODE else set())

    if metrics_to_average:
        df_mean = (sub[sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].isin(metrics_to_average)]
                   .groupby(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                   .mean().unstack())
        df_mean = _flatten_columns(df_mean)
        for metric in metrics_to_average:
            if metric in df_mean.columns:
                result[metric] = df_mean[metric]

    result = apply_economic_derivatives(result) # –ù–µ –±—É–¥–µ—Ç –Ω–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å –≤ SIMPLE_MODE

    return result.reset_index()


@st.cache_data
def get_monthly_pivoted_data(df_raw: pd.DataFrame, regions: Tuple[str, ...], months: Tuple[str, ...], raw_only: bool = False) -> pd.DataFrame:
    df = strip_totals_rows(df_raw)
    sub = df[df["–†–µ–≥–∏–æ–Ω"].isin(regions) & df["–ú–µ—Å—è—Ü"].isin(months)]
    if sub.empty: return pd.DataFrame()
    pivot = sub.pivot_table(index=["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–ú–µ—Å—è—Ü"], columns="–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="sum", observed=False)
    pivot = _flatten_columns(pivot).reset_index()

    if not raw_only:
        pivot = apply_economic_derivatives(pivot)

    for col in [Metrics.ILLIQUID_BY_COUNT_PCT.value, Metrics.ILLIQUID_BY_VALUE_PCT.value, Metrics.YIELD.value, Metrics.MARKUP_PCT.value]:
        if col in pivot.columns: pivot[col] = normalize_percent_series(pivot[col])
    return pivot

@st.cache_data
def month_totals_matrix(df_raw: pd.DataFrame, regions: Tuple[str, ...], metric: str) -> pd.DataFrame:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –†–µ–≥–∏–æ–Ω √ó –ú–µ—Å—è—Ü —Å –ø–æ–º–µ—Å—è—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª.
    –ù–∏–∫–∞–∫–∏—Ö —Å—É–º–º –ø–æ —Ñ–∏–ª–∏–∞–ª–∞–º ‚Äî —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –ª–µ–∂–∏—Ç –≤ —Ñ–∞–π–ª–µ –≤ —Å—Ç—Ä–æ–∫–∞—Ö ¬´–ò—Ç–æ–≥–æ¬ª.
    """
    dfm = get_monthly_totals_from_file(df_raw, regions, metric)
    if dfm.empty:
        return pd.DataFrame(columns=["–†–µ–≥–∏–æ–Ω","–ú–µ—Å—è—Ü","–ó–Ω–∞—á–µ–Ω–∏–µ"])
    return dfm.copy()

def _postprocess_monthly_df(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame(columns=["–†–µ–≥–∏–æ–Ω","–ú–µ—Å—è—Ü","–ó–Ω–∞—á–µ–Ω–∏–µ"])
    out = df.copy()
    keep = [c for c in out.columns if c in {"–†–µ–≥–∏–æ–Ω","–ú–µ—Å—è—Ü","–ó–Ω–∞—á–µ–Ω–∏–µ"}]
    out = out[keep]
    out["–†–µ–≥–∏–æ–Ω"] = out["–†–µ–≥–∏–æ–Ω"].astype("string")
    out["–ú–µ—Å—è—Ü"] = out["–ú–µ—Å—è—Ü"].astype(str)
    out = out[out["–ú–µ—Å—è—Ü"].isin(ORDER)]
    out = (out.groupby(["–†–µ–≥–∏–æ–Ω","–ú–µ—Å—è—Ü"], as_index=False)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum())
    return out

@st.cache_data
def number_column_config(title: str, money=False, percent=False, days=False):
    if money: return st.column_config.NumberColumn(f"{title}, ‚ÇΩ", help="–î–µ–Ω–µ–∂–Ω–∞—è —Å—É–º–º–∞", format="%.0f")
    if percent: return st.column_config.NumberColumn(f"{title}, %", help="–ü—Ä–æ—Ü–µ–Ω—Ç—ã/–¥–æ–ª–∏", format="%.2f%%")
    if days: return st.column_config.NumberColumn(f"{title}, –¥–Ω.", help="–î–Ω–∏", format="%.2f")
    return st.column_config.NumberColumn(title, format="%.2f")

def default_column_config(df: pd.DataFrame) -> dict:
    cfg = {}
    for c in df.columns:
        s = str(c)
        is_money = "—Ä—É–±" in s
        is_percent = s.endswith("(%)") or "–Ω–∞—Ü–µ–Ω–∫" in s.lower() or "–¥–æ–ª—è" in s.lower() or s == Metrics.YIELD.value
        is_days = "–¥–Ω–µ–π" in s
        if pd.api.types.is_numeric_dtype(df[c]):
            cfg[s] = number_column_config(s, money=is_money, percent=is_percent, days=is_days)
    return cfg

def kpi_block(df_all: pd.DataFrame, regions: list[str], months_range: list[str], all_available_months: list[str], strict_mode: bool):
    st.markdown("## üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (KPI) <span class='badge'>–ö–∞–∫ –≤ —Ñ–∞–π–ª–µ</span>", unsafe_allow_html=True)
    st.caption("–ü–µ—Ä–∏–æ–¥ —Å—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–≥–æ –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª: —Å—É–º–º—ã ‚Äî —Å—É–º–º–∏—Ä—É–µ–º, –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ —Å—Ä–µ–¥–Ω–∏–µ ‚Äî —É—Å—Ä–µ–¥–Ω—è–µ–º, —Å–Ω–∏–º–∫–∏ ‚Äî –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü.")

    def _render_metric_if_value(col, title, value, *, kind="money", delta=None, delta_color="normal"):
        if value is None or pd.isna(value) or (isinstance(value, (int,float)) and abs(value) < 1e-12):
            return  # –Ω–µ —Ä–∏—Å—É–µ–º –∫–∞—Ä—Ç–æ—á–∫—É
        if kind == "money":
            txt = format_rub(value)
        elif kind == "pct":
            txt = fmt_pct(value)
        elif kind == "days":
            txt = fmt_days(value)
        else:
            txt = f"{value:,.0f}".replace(",", " ")
        col.metric(title, txt, delta=delta, delta_color=delta_color)

    sub_df = df_all[(df_all["–†–µ–≥–∏–æ–Ω"].isin(regions)) & (df_all["–ú–µ—Å—è—Ü"].astype(str).isin(months_range))]
    
    # –∫–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ KPI-—Ç–∞–±–ª–∏—Ü–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
    KPI_SET_MONEY = [Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value]
    KPI_SET_RATE  = [Metrics.MARKUP_PCT.value, Metrics.YIELD.value]
    KPI_COLUMNS   = KPI_SET_MONEY + KPI_SET_RATE  # –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å

    mode_view = st.radio("–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ", ["–ü–æ —Ä–µ–≥–∏–æ–Ω–∞–º", "–°–æ–≤–æ–∫—É–ø–Ω–æ (–ø–æ –≤—ã–±–æ—Ä–∫–µ)"], horizontal=True)

    if mode_view == "–ü–æ —Ä–µ–≥–∏–æ–Ω–∞–º":
        regs_sorted = sorted(map(str, sub_df["–†–µ–≥–∏–æ–Ω"].unique()))
        rows = []
        for reg in regs_sorted:
            r = {"–†–µ–≥–∏–æ–Ω": reg}
            for m in KPI_COLUMNS:
                # –¥–ª—è KPI –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –¥–ª—è —Å–Ω–∏–º–∫–æ–≤ –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ –ø–µ—Ä–∏–æ–¥
                r[m] = period_value_from_itogo_for_region(df_all, reg, m, months_range, snapshots_mode="mean")
            rows.append(r)

        kpi_table = pd.DataFrame(rows).set_index("–†–µ–≥–∏–æ–Ω")
        # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ
        sort_col = Metrics.REVENUE.value if Metrics.REVENUE.value in kpi_table.columns else kpi_table.columns[0]
        kpi_table = kpi_table.sort_values(by=sort_col, ascending=False)

        # –∫–æ–Ω—Ñ–∏–≥ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (‚ÇΩ/%, –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –¥–ª—è –¥–µ–Ω–µ–≥)
        cfg = {}
        for c in kpi_table.columns:
            if "—Ä—É–±" in c:
                cfg[c] = st.column_config.NumberColumn(f"{c}", format="%.0f")
            elif is_percent_metric(c):
                cfg[c] = st.column_config.NumberColumn(f"{c}", format="%.2f%%")
            elif "–¥–Ω–µ–π" in c:
                cfg[c] = st.column_config.NumberColumn(f"{c}", format="%.2f")
            else:
                cfg[c] = st.column_config.NumberColumn(f"{c}", format="%.0f")

        st.dataframe(kpi_table, use_container_width=True, column_config=cfg)
        insight_lines = []
        for metric in KPI_COLUMNS:
            if metric in kpi_table.columns:
                insight = _describe_metric_series(kpi_table[metric], metric)
                if insight:
                    insight_lines.append(insight)
        _render_insights("–ö–æ—Ä–æ—Ç–∫–æ –ø–æ KPI", insight_lines)
        action_lines: List[str] = []
        for metric in KPI_COLUMNS:
            if metric in kpi_table.columns:
                action_lines.extend(_generate_actions_for_series(kpi_table[metric], metric))
        _render_plan("–ß—Ç–æ –¥–µ–ª–∞–µ–º –ø–æ KPI", action_lines[:4])
        st.caption("–ü–µ—Ä–∏–æ–¥: —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è %-–º–µ—Ç—Ä–∏–∫ –∏ –º–µ—Ç—Ä–∏–∫-—Å–Ω–∏–º–∫–æ–≤; –¥–µ–Ω–µ–∂–Ω—ã–µ/—à—Ç ‚Äî —Å—É–º–º–∏—Ä—É—é—Ç—Å—è –∑–∞ –ø–µ—Ä–∏–æ–¥.")
        return  # –≤—ã—Ö–æ–¥–∏–º, –∫–∞—Ä—Ç–æ—á–∫–∏ –Ω–∏–∂–µ –Ω–µ —Ä–∏—Å—É–µ–º –≤ —ç—Ç–æ–º —Ä–µ–∂–∏–º–µ

    if sub_df.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    def pv(metric):
        return period_value_from_itogo(df_all, regions, metric, months_range)

    lbl_cur = f"{months_range[0]}‚Äì{months_range[-1]}" if len(months_range) > 1 else months_range[0]

    v_rev = pv(Metrics.REVENUE.value)
    v_issue = pv(Metrics.LOAN_ISSUE.value)
    v_markup_pct = pv(Metrics.MARKUP_PCT.value)
    v_yield = pv(Metrics.YIELD.value)
    v_avg_term = pv(Metrics.AVG_LOAN_TERM.value)
    v_avg_loan = pv(Metrics.AVG_LOAN.value)
    v_branches = pv(Metrics.BRANCH_COUNT.value)
    v_redeemed = pv(Metrics.REDEEMED_ITEMS_COUNT.value)

    cA, cB, cC, cD = st.columns(4)
    _render_metric_if_value(cA, f"–í—ã—Ä—É—á–∫–∞ ({lbl_cur})", v_rev, kind="money")
    _render_metric_if_value(cB, f"–í—ã–¥–∞–Ω–æ –∑–∞–π–º–æ–≤ ({lbl_cur})", v_issue, kind="money")
    _render_metric_if_value(cC, f"–ü—Ä–æ—Ü–µ–Ω—Ç –Ω–∞—Ü–µ–Ω–∫–∏ ({lbl_cur})", v_markup_pct, kind="pct")
    _render_metric_if_value(cD, f"–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å ({lbl_cur})", v_yield, kind="pct")

    st.markdown("<br>", unsafe_allow_html=True)
    cE, cF, cG, cH = st.columns(4)
    _render_metric_if_value(cE, f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤ ({lbl_cur})", v_branches, kind="num")

    insight_lines: List[str] = []
    action_lines: List[str] = []

    if len(regions) == 1:
        _render_metric_if_value(cF, f"–°—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –∑–∞–π–º–∞ ({lbl_cur})", v_avg_term, kind="days")
    else:
        per_reg = period_values_by_region_from_itogo(df_all, regions, Metrics.AVG_LOAN_TERM.value, months_range)
        if per_reg:
            with cF:
                st.markdown("**–°—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –∑–∞–π–º–∞ (–¥–Ω–µ–π)**")
                st.dataframe(
                    pd.DataFrame(sorted(per_reg.items()), columns=["–†–µ–≥–∏–æ–Ω", "–¥–Ω."]).set_index("–†–µ–≥–∏–æ–Ω"),
                    use_container_width=True,
                    column_config={"–¥–Ω.": st.column_config.NumberColumn("–¥–Ω.", format="%.2f")}
                )
            insight = _describe_metric_series(pd.Series(per_reg), Metrics.AVG_LOAN_TERM.value)
            if insight:
                insight_lines.append(insight)
            action_lines.extend(_generate_actions_for_series(pd.Series(per_reg), Metrics.AVG_LOAN_TERM.value))

    if len(regions) == 1:
        _render_metric_if_value(cG, f"–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –∑–∞–π–º–∞ ({lbl_cur})", v_avg_loan, kind="money")
    else:
        per_reg_avg_loan = period_values_by_region_from_itogo(df_all, regions, Metrics.AVG_LOAN.value, months_range)
        if per_reg_avg_loan:
            with cG:
                st.markdown("**–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –∑–∞–π–º–∞ (—Ä—É–±)**")
                st.dataframe(
                    pd.DataFrame(sorted(per_reg_avg_loan.items()), columns=["–†–µ–≥–∏–æ–Ω", "‚ÇΩ"]).set_index("–†–µ–≥–∏–æ–Ω"),
                    use_container_width=True,
                    column_config={"‚ÇΩ": st.column_config.NumberColumn("‚ÇΩ", format="%.0f")}
                )
            insight = _describe_metric_series(pd.Series(per_reg_avg_loan), Metrics.AVG_LOAN.value)
            if insight:
                insight_lines.append(insight)
            action_lines.extend(_generate_actions_for_series(pd.Series(per_reg_avg_loan), Metrics.AVG_LOAN.value))

    _render_metric_if_value(cH, f"–í—ã–∫—É–ø–ª–µ–Ω–Ω—ã–µ –∑–∞–ª–æ–≥–∏ ({lbl_cur})", v_redeemed, kind="num")

    # –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    monthly_focus_metrics = [Metrics.REVENUE.value, Metrics.MARKUP_PCT.value, Metrics.RISK_SHARE.value]
    for metric in monthly_focus_metrics:
        series = _monthly_series_for_metric(df_all, regions, metric, months_range)
        if series is None or series.empty or len(series.dropna()) < 2:
            continue
        first, last = series.dropna().iloc[0], series.dropna().iloc[-1]
        delta = last - first
        direction = "–≤—ã—Ä–æ—Å" if delta > 0 else "—Å–Ω–∏–∑–∏–ª—Å—è"
        if abs(delta) < 1e-6:
            continue
        insight_lines.append(
            f"{metric}: {direction} —Å {_format_value_for_metric(metric, first)} –¥–æ {_format_value_for_metric(metric, last)} ({_format_delta(metric, delta)})."
        )
        action_lines.extend(_generate_actions_for_deltas([(f"–≤—ã–±–æ—Ä–∫–∞", delta)], metric))

    _render_insights("–í—ã–≤–æ–¥—ã –ø–æ –ø–µ—Ä–∏–æ–¥—É", insight_lines)
    _render_plan("–ë–ª–∏–∂–∞–π—à–∏–µ –¥–µ–π—Å—Ç–≤–∏—è", action_lines[:4])

    with st.expander("üßÆ –ö–∞–∫ –ø–æ—Å—á–∏—Ç–∞–Ω–æ (–ø—Ä–∞–≤–∏–ª–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏)"):
        raw_metric_names = set(sub_df["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
        rows = []
        for m in sorted(raw_metric_names):
            rows.append({"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": m, "–ü—Ä–∞–≤–∏–ª–æ": aggregation_rule(m)})
        if rows:
            st.dataframe(pd.DataFrame(rows), use_container_width=True)
        else:
            st.info("–ù–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª.")

def summary_block(agg_data, df_all, regions, months_range, all_available_months, strict_mode):
    st.subheader("üìã –°–≤–æ–¥–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∑–∞ –ø–µ—Ä–∏–æ–¥")
    st.caption("–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî —Ä–æ–≤–Ω–æ –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö. –ù–∏–∫–∞–∫–∏—Ö —Ñ–æ—Ä–º—É–ª.")

    sub = df_all[df_all["–†–µ–≥–∏–æ–Ω"].isin(regions)]
    raw_metrics = [m for m in sorted(sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique()) if m not in HIDDEN_METRICS]

    # —Å–æ–±–µ—Ä—ë–º —Ç–∞–±–ª–∏—Ü—É: —Å—Ç—Ä–æ–∫–∏ ‚Äî —Ä–µ–≥–∏–æ–Ω—ã; —Å—Ç–æ–ª–±—Ü—ã ‚Äî –º–µ—Ç—Ä–∏–∫–∏
    rows = []
    for reg in sorted(map(str, sub["–†–µ–≥–∏–æ–Ω"].unique())):
        row = {"–†–µ–≥–∏–æ–Ω": reg}
        for m in raw_metrics:
            row[m] = period_value_from_itogo_for_region(df_all, reg, m, months_range, snapshots_mode="mean")
        rows.append(row)

    if not rows:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–≤–æ–¥–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")
        return

    region_summary = pd.DataFrame(rows).set_index("–†–µ–≥–∏–æ–Ω")

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
    if Metrics.REVENUE.value in region_summary.columns:
        region_summary = region_summary.sort_values(by=Metrics.REVENUE.value, ascending=False)

    st.dataframe(
        region_summary,
        use_container_width=True,
        column_config=default_column_config(region_summary)
    )

    key_metrics = [
        m for m in [Metrics.REVENUE.value, Metrics.MARKUP_PCT.value, Metrics.RISK_SHARE.value, Metrics.ILLIQUID_BY_VALUE_PCT.value]
        if m in region_summary.columns
    ]
    insight_lines = []
    for metric in key_metrics:
        insight = _describe_metric_series(region_summary[metric], metric)
        if insight:
            insight_lines.append(insight)
    _render_insights("–ì–ª–∞–≤–Ω–æ–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", insight_lines)

    action_lines: List[str] = []
    for metric in key_metrics:
        action_lines.extend(_generate_actions_for_series(region_summary[metric], metric))
    _render_plan("–®–∞–≥–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", action_lines[:4])

def nuz_active_branches(df_all: pd.DataFrame,
                        regions: list[str] | Tuple[str, ...],
                        months: list[str]) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –†–µ–≥–∏–æ–Ω/–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∏–ª–∏–∞–ª–æ–≤,
    –≥–¥–µ –µ—Å—Ç—å –Ω–µ–Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –ù–Æ–ó-–º–µ—Ç—Ä–∏–∫–∞–º –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –æ–∫–Ω–µ."""
    sub = strip_totals_rows(df_all)
    sub = sub[(sub["–†–µ–≥–∏–æ–Ω"].isin(regions)) & (sub["–ú–µ—Å—è—Ü"].astype(str).isin(months))]
    if sub.empty:
        return pd.DataFrame(columns=["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"])
    nuz = sub[sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].isin(NUZ_ACTIVITY_METRICS)].copy()
    nuz["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(nuz["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").fillna(0).abs()
    act = (nuz.groupby(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
              .sum().reset_index())
    return act[act["–ó–Ω–∞—á–µ–Ω–∏–µ"] > 0][["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"]]

def leaderboard_block(
    df_all: pd.DataFrame,
    regions: list[str],
    available_months: list[str],
    *,
    default_metric: str | None = None,
    selection_key: str = "leaderboard_metric",
    period_slider_key: str = "leaderboard_period"
) -> None:
    st.subheader("üèÜ –õ–∏–¥–µ—Ä—ã –∏ –∞—É—Ç—Å–∞–π–¥–µ—Ä—ã")
    st.caption("–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ñ–∏–ª–∏–∞–ª—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ: —Å–ª–µ–≤–∞ ‚Äî –ª–∏–¥–µ—Ä—ã, —Å–ø—Ä–∞–≤–∞ ‚Äî —Ç–µ, –∫—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è.")

    if df_all.empty or not available_months:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    last_quarter = available_months[max(0, len(available_months)-3):]
    start_m, end_m = st.select_slider(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞:", options=available_months,
        value=(last_quarter[0], last_quarter[-1]),
        key=period_slider_key
    )
    leaderboard_months = ORDER[ORDER.index(start_m): ORDER.index(end_m) + 1]

    agg_data = get_aggregated_data(df_all, tuple(regions), tuple(leaderboard_months))
    if agg_data.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        return

    activity_cols = [Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value, Metrics.LOAN_ISSUE_UNITS.value]
    have = [c for c in activity_cols if c in agg_data.columns and c in df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].unique()]
    if have:
        mask = (agg_data[have].fillna(0).sum(axis=1) > 0)
        agg_data = agg_data[mask]
    if agg_data.empty:
        st.warning("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å.")
        return

    # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—É–ª –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ç–æ–ª—å–∫–æ –∏–∑ —Ç–µ—Ö, —á—Ç–æ –µ—Å—Ç—å –≤ —Ñ–∞–π–ª–µ
    raw_metric_names = set(df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
    numeric_cols = [c for c in agg_data.columns if pd.api.types.is_numeric_dtype(agg_data[c]) and c != "–ö–æ–¥"]
    metric_options = sorted([c for c in numeric_cols if c in raw_metric_names and c not in HIDDEN_METRICS])

    if not metric_options:
        st.warning("–í –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞.")
        return

    default_idx = 0
    if default_metric and default_metric in metric_options:
        default_idx = metric_options.index(default_metric)
    elif Metrics.REVENUE.value in metric_options:
        default_idx = metric_options.index(Metrics.REVENUE.value)
    chosen_metric = st.selectbox(
        "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å",
        options=metric_options,
        index=default_idx,
        key=selection_key
    )
    st.caption(METRIC_HELP.get(chosen_metric, ""))

    # –æ–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–∞–≤–∏–ª–æ ¬´—á–µ–º –±–æ–ª—å—à–µ ‚Äî —Ç–µ–º –ª—É—á—à–µ¬ª
    percent_metric = is_percent_metric(chosen_metric)
    is_money = "—Ä—É–±" in chosen_metric.lower()
    is_days = "–¥–Ω–µ–π" in chosen_metric.lower()
    if chosen_metric in METRICS_BIGGER_IS_BETTER:
        ascending = False
    elif chosen_metric in METRICS_SMALLER_IS_BETTER:
        ascending = True
    else:
        ascending = False

    sorted_data = agg_data.dropna(subset=[chosen_metric]).sort_values(by=chosen_metric, ascending=ascending)
    metric_series = sorted_data[chosen_metric]
    if not metric_series.empty:
        if not percent_metric:
            total_val = float(metric_series.abs().sum())
            if total_val > 1e-9:
                sorted_data["–î–æ–ª—è, %"] = (metric_series / total_val) * 100
        mean_val = float(metric_series.mean()) if not metric_series.empty else 0.0
        sorted_data["–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ"] = metric_series - mean_val
    top_limit = min(20, len(sorted_data)) if not sorted_data.empty else 0
    if top_limit == 0:
        st.warning("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")
        return
    min_slider = 5 if top_limit >= 5 else 1
    default_val = min(10, top_limit)
    default_val = default_val if default_val >= min_slider else top_limit
    top_n = st.slider(
        "–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏",
        min_value=min_slider,
        max_value=top_limit,
        value=default_val,
        step=1,
        key=f"{selection_key}_topn"
    )

    if chosen_metric in METRICS_SMALLER_IS_BETTER:
        title_best = f"‚úÖ –¢–æ–ø-{top_n} –ª—É—á—à–∏—Ö (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)"
        title_worst = f"‚ùå –¢–æ–ø-{top_n} —Ö—É–¥—à–∏—Ö (–±–æ–ª—å—à–µ = —Ö—É–∂–µ)"
    else:
        title_best = f"‚úÖ –¢–æ–ø-{top_n} –ª—É—á—à–∏—Ö"
        title_worst = f"‚ùå –¢–æ–ø-{top_n} —Ö—É–¥—à–∏—Ö"

    c1, c2 = st.columns(2)
    display_cols = ["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–†–µ–≥–∏–æ–Ω",chosen_metric]
    if "–î–æ–ª—è, %" in sorted_data.columns:
        display_cols.append("–î–æ–ª—è, %")
    if "–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ" in sorted_data.columns:
        display_cols.append("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ")

    col_cfg = default_column_config(sorted_data)
    if "–î–æ–ª—è, %" in display_cols:
        col_cfg["–î–æ–ª—è, %"] = st.column_config.NumberColumn("–î–æ–ª—è –æ—Ç –∏—Ç–æ–≥–∞, %", format="%.1f%%")
    if "–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ" in display_cols:
        format_label = "–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –ø.–ø." if percent_metric else ("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –¥–Ω." if is_days else "–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ")
        fmt = "%.2f"
        if is_money and not percent_metric and not is_days:
            fmt = "%.0f"
        col_cfg["–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ"] = st.column_config.NumberColumn(format_label, format=fmt)

    with c1:
        st.markdown(f"**{title_best} –ø–æ _{chosen_metric}_**")
        st.dataframe(sorted_data.head(top_n)[display_cols], use_container_width=True, column_config=col_cfg)
    with c2:
        st.markdown(f"**{title_worst} –ø–æ _{chosen_metric}_**")
        worst5 = sorted_data.tail(top_n)
        worst5 = worst5.iloc[::-1].copy()
        st.dataframe(worst5[display_cols], use_container_width=True, column_config=col_cfg)
    st.caption("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–æ–ª—é –∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –≤–∫–ª–∞–¥ —Ñ–∏–ª–∏–∞–ª–∞ –∏ –µ–≥–æ –¥–∏—Å—Ç–∞–Ω—Ü–∏—é –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è.")

    insight_lines = []
    if not sorted_data.empty:
        top_row = sorted_data.iloc[0]
        best_name = f"{top_row['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']} ({top_row['–†–µ–≥–∏–æ–Ω']})"
        best_val = _format_value_for_metric(chosen_metric, top_row[chosen_metric])
        extra = ""
        if "–î–æ–ª—è, %" in sorted_data.columns:
            extra = f" ‚Äî –¥–æ–ª—è {top_row['–î–æ–ª—è, %']:.1f}%"
        insight_lines.append(f"–õ–∏–¥–∏—Ä—É–µ—Ç {best_name}: {best_val}{extra}.")
        bottom_row = sorted_data.iloc[-1]
        if bottom_row.name != top_row.name:
            worst_name = f"{bottom_row['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']} ({bottom_row['–†–µ–≥–∏–æ–Ω']})"
            worst_val = _format_value_for_metric(chosen_metric, bottom_row[chosen_metric])
            extra_w = ""
            if "–î–æ–ª—è, %" in sorted_data.columns:
                extra_w = f" ‚Äî –¥–æ–ª—è {bottom_row['–î–æ–ª—è, %']:.1f}%"
            insight_lines.append(f"–ù–∞–∏–º–µ–Ω—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —É {worst_name}: {worst_val}{extra_w}.")
    _render_insights("–ß—Ç–æ –≤–∞–∂–Ω–æ –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ", insight_lines)
    series_for_actions = sorted_data.set_index(["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–†–µ–≥–∏–æ–Ω"])[chosen_metric]
    action_lines = _generate_actions_for_series(series_for_actions, chosen_metric)
    _render_plan("–ü–ª–∞–Ω –ø–æ —Ñ–∏–ª–∏–∞–ª–∞–º", action_lines[:4])


def comparison_block(
    df_all: pd.DataFrame,
    regions: list[str],
    available_months: list[str],
    *,
    default_metric: str | None = None,
    selection_key: str = "comparison_metric",
    period_a_key: str = "comparison_period_a",
    period_b_key: str = "comparison_period_b"
) -> None:
    st.subheader("‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–æ–≤")
    st.caption("–í—ã–±–µ—Ä–∏—Ç–µ –¥–≤–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –º–µ—Å—è—Ü–µ–≤: –ø–µ—Ä–∏–æ–¥ A ‚Äî –±–∞–∑–∞, –ø–µ—Ä–∏–æ–¥ B ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ. –¢–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∂–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∏–ª–∏–∞–ª—É.")
    if df_all.empty or not available_months: st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."); return
    c1, c2 = st.columns(2)
    with c1:
        start_a, end_a = st.select_slider(
            "–ü–µ—Ä–∏–æ–¥ A (–±–∞–∑–æ–≤—ã–π):",
            options=available_months,
            value=(available_months[0], available_months[0]),
            key=period_a_key
        )
    with c2:
        start_b, end_b = st.select_slider(
            "–ü–µ—Ä–∏–æ–¥ B (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–π):",
            options=available_months,
            value=(available_months[-1], available_months[-1]),
            key=period_b_key
        )
    months_a = ORDER[ORDER.index(start_a): ORDER.index(end_a)+1]
    months_b = ORDER[ORDER.index(start_b): ORDER.index(end_b)+1]
    data_a = get_aggregated_data(df_all, tuple(regions), tuple(months_a))
    data_b = get_aggregated_data(df_all, tuple(regions), tuple(months_b))
    if data_a.empty or data_b.empty: st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –æ–±–æ–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤."); return
    comparison_df = pd.merge(data_a, data_b, on=["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], how="outer", suffixes=("_A","_B"))

    raw_metric_names = set(df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
    all_metrics = sorted([c for c in data_a.columns if pd.api.types.is_numeric_dtype(data_a[c]) and c != "–ö–æ–¥"])
    metric_options = [m for m in all_metrics if m in raw_metric_names and m not in HIDDEN_METRICS]
    if not metric_options:
        st.warning("–ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
        return

    default_idx = 0
    if default_metric and default_metric in metric_options:
        default_idx = metric_options.index(default_metric)
    chosen_metric = st.selectbox(
        "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
        options=metric_options,
        index=default_idx,
        key=selection_key,
        help=METRIC_HELP.get(metric_options[default_idx], "")
    )
    col_a, col_b = f"{chosen_metric}_A", f"{chosen_metric}_B"
    if col_a not in comparison_df.columns: comparison_df[col_a] = np.nan
    if col_b not in comparison_df.columns: comparison_df[col_b] = np.nan
    comparison_df["–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"] = comparison_df[col_b] - comparison_df[col_a]
    comparison_df["–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ, %"] = (comparison_df["–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"] / comparison_df[col_a].replace(0, np.nan)) * 100
    is_money, is_percent, is_days = "—Ä—É–±" in chosen_metric, "%" in chosen_metric or "–Ω–∞—Ü–µ–Ω–∫" in chosen_metric.lower() or "–¥–æ–ª—è" in chosen_metric.lower() or chosen_metric == Metrics.YIELD.value, "–¥–Ω–µ–π" in chosen_metric
    cfg = {
        col_a: number_column_config(f"{chosen_metric} (A: {start_a}-{end_a})", money=is_money, percent=is_percent, days=is_days),
        col_b: number_column_config(f"{chosen_metric} (B: {start_b}-{end_b})", money=is_money, percent=is_percent, days=is_days),
        "–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ": number_column_config("–ò–∑–º. (–∞–±—Å.)", money=is_money and not is_percent and not is_days, percent=False, days=False),
        "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ, %": st.column_config.NumberColumn("–ò–∑–º. (%)", format="%.1f%%"),
    }
    st.dataframe(
        comparison_df[["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–†–µ–≥–∏–æ–Ω",col_a,col_b,"–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ","–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ, %"]]
        .sort_values("–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ", ascending=False)
        .dropna(subset=["–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"]),
        use_container_width=True,
        column_config=cfg
    )
    st.caption("–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–æ–≤–æ—Ä–∏—Ç –æ —Ä–æ—Å—Ç–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑—ã, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ ‚Äî –æ –ø—Ä–æ—Å–∞–¥–∫–µ. –û—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏—Ç—å –º–∞—Å—à—Ç–∞–±." )

    insight_lines = []
    delta_series = comparison_df.dropna(subset=["–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"]).set_index(["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ","–†–µ–≥–∏–æ–Ω"])["–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"]
    if not delta_series.empty:
        inc = delta_series.idxmax()
        dec = delta_series.idxmin()
        inc_val = delta_series.loc[inc]
        dec_val = delta_series.loc[dec]
        if inc_val != 0:
            inc_name = f"{inc[0]} ({inc[1]})"
            insight_lines.append(f"–ù–∞–∏–±–æ–ª—å—à–∏–π —Ä–æ—Å—Ç –ø–æ {chosen_metric}: {inc_name} ({_format_delta(chosen_metric, inc_val)}).")
        if dec_val != 0 and dec != inc:
            dec_name = f"{dec[0]} ({dec[1]})"
            insight_lines.append(f"–°–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –ø—Ä–æ—Å–µ–ª {dec_name}: {_format_delta(chosen_metric, dec_val)}." )
    _render_insights("–ò—Ç–æ–≥–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", insight_lines)
    delta_pairs = [(_label_from_index(idx), val) for idx, val in delta_series.items() if not pd.isna(val) and val != 0]
    action_lines = _generate_actions_for_deltas(delta_pairs, chosen_metric)
    _render_plan("–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è", action_lines[:4])

def dynamics_block(
    df_all: pd.DataFrame,
    regions: list[str],
    months_range: list[str],
    color_map: Dict[str, str],
    *,
    default_metrics: List[str] | None = None,
    widget_prefix: str = "dyn"
) -> None:
    st.subheader("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")

    raw_metric_names = sorted(set(df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique()))
    if not raw_metric_names:
        st.warning("–í —Ñ–∞–π–ª–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏.")
        return

    base_defaults = [Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value, Metrics.MARKUP_PCT.value]
    if default_metrics:
        default_selection = [m for m in default_metrics if m in raw_metric_names]
    else:
        default_selection = [m for m in base_defaults if m in raw_metric_names]
    if not default_selection:
        default_selection = raw_metric_names[:3]

    metrics = st.multiselect(
        "–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
        options=raw_metric_names,
        default=default_selection[:3],
        key=f"{widget_prefix}_metrics"
    )

    if not metrics:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏.");
        return

    c1, c2, c3, c4 = st.columns(4)
    only_actual = c1.checkbox("–¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Å—è—Ü—ã", True, key=f"{widget_prefix}_actual")
    show_trend = c2.checkbox("–õ–∏–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞", True, key=f"{widget_prefix}_trend")
    fast_plot = c3.checkbox("–û–±–ª–µ–≥—á–∏—Ç—å –æ—Ç—Ä–∏—Å–æ–≤–∫—É", False, key=f"{widget_prefix}_fast")
    use_log = c4.checkbox("–õ–æ–≥. –æ—Å—å Y", False, key=f"{widget_prefix}_log")

    for met in metrics:
        gp = get_monthly_totals_from_file(df_all, tuple(regions), met)
        gp = gp[gp["–ú–µ—Å—è—Ü"].astype(str).isin(months_range)]
        if gp.empty:
            st.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ ¬´{met}¬ª.");
            continue

        x_domain = months_range if not only_actual else sorted_months_safe(gp["–ú–µ—Å—è—Ü"])
        if not x_domain:
            st.info(f"–ù–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Å—è—Ü–µ–≤ –¥–ª—è ¬´{met}¬ª."); continue
        fig = go.Figure()

        # –ø–æ—Ä—è–¥–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤: –∫–∞–∫ –≤—ã–±—Ä–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –≤ —Å–∞–π–¥–±–∞—Ä–µ (–µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ ‚Äî –∞–ª—Ñ–∞–≤–∏—Ç)
        region_order = [r for r in regions if r in gp["–†–µ–≥–∏–æ–Ω"].astype(str).unique()]
        # —Ä–µ–∑–µ—Ä–≤: –¥–æ–±–∞–≤–∏–º —Ç–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ (–Ω–∞ —Å–ª—É—á–∞–π —Ñ–∏–ª—å—Ç—Ä–æ–≤)
        region_order += [r for r in sorted(gp["–†–µ–≥–∏–æ–Ω"].astype(str).unique()) if r not in region_order]

        # —á—Ç–æ–±—ã –ª–µ–≥–µ–Ω–¥–∞ –Ω–µ –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–ª–∞ –ø–æ—Ä—è–¥–æ–∫
        fig.update_layout(
            legend=dict(traceorder="normal"),
            hovermode="x unified",
        )

        tickfmt, suf = y_fmt_for_metric(met)
        def fmt_hover(v):
            if v is None or (isinstance(v, float) and np.isnan(v)): return "‚Äî"
            if tickfmt == ",.0f": return f"{v:,.0f}{suf}".replace(",", " ")
            if tickfmt == ".2f": return f"{v:.2f}{suf}"
            return f"{v:,.2f}{suf}".replace(",", " ")

        hovertemplate = (
            "<b>–†–µ–≥–∏–æ–Ω: %{customdata[0]}</b><br>"
            "–ú–µ—Å—è—Ü: %{x}<br>"
            "–ó–Ω–∞—á–µ–Ω–∏–µ: %{customdata[1]}<extra></extra>"
        )

        any_drawn = False
        deltas: List[tuple[str, float]] = []
        for rank, reg in enumerate(region_order):
            t = gp[gp["–†–µ–≥–∏–æ–Ω"].astype(str) == reg].groupby("–ú–µ—Å—è—Ü", as_index=False)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum()
            series = t.set_index("–ú–µ—Å—è—Ü")["–ó–Ω–∞—á–µ–Ω–∏–µ"].reindex(x_domain)
            if series.isna().all(): 
                continue
            any_drawn = True

            series_vals = series.values.astype(float)
            hover_vals  = [fmt_hover(v) for v in series_vals]

            fig.add_trace(go.Scatter(
                x=series.index, y=series_vals,
                mode="lines" if fast_plot else "lines+markers",
                name=reg,
                connectgaps=False,
                line=dict(color=color_map.get(reg)),
                legendgroup=reg,
                legendrank=rank,                  # ‚¨ÖÔ∏è –ø–æ—Ä—è–¥–æ–∫ –≤ –ª–µ–≥–µ–Ω–¥–µ/—Ö–æ–≤–µ—Ä–µ
                customdata=np.column_stack([np.full(len(series), reg), hover_vals]),
                hovertemplate=hovertemplate
            ))

            if (not fast_plot) and show_trend:
                y_vals = series.values.astype(float); mask = ~np.isnan(y_vals)
                if mask.sum() >= 2:
                    x_pos = np.arange(len(series.index))
                    k, b = np.polyfit(x_pos[mask], y_vals[mask], 1)
                    fig.add_trace(go.Scatter(
                        x=series.index, y=k * x_pos + b,
                        mode="lines",
                        name=f"{reg} ¬∑ —Ç—Ä–µ–Ω–¥",
                        line=dict(dash="dot", width=2, color=color_map.get(reg)),
                        showlegend=False,
                        hoverinfo="skip",           # ‚¨ÖÔ∏è —Ç—Ä–µ–Ω–¥—ã –≤ —Ö–æ–≤–µ—Ä –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç
                        legendgroup=reg,
                        legendrank=rank
                    ))
            clean_series = series.dropna()
            if len(clean_series) >= 2:
                delta_val = float(clean_series.iloc[-1] - clean_series.iloc[0])
                deltas.append((str(reg), delta_val))
        if not any_drawn:
            st.info(f"–î–ª—è ¬´{met}¬ª –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å, –Ω–æ –ø–æ—Å–ª–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—é –≤—Å–µ —Å–µ—Ä–∏–∏ –ø—É—Å—Ç—ã–µ (—Ä–∞–∑–Ω—ã–µ –º–µ—Å—è—Ü—ã —É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤). –í—ã–±–µ—Ä–∏—Ç–µ ¬´–¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Å—è—Ü—ã¬ª –∏–ª–∏ —Å—É–∑—å—Ç–µ –ø–µ—Ä–∏–æ–¥.")
            continue

        rule = aggregation_rule(met)
        rule_text = '–°—É–º–º–∞' if rule=='sum' else '–°—Ä–µ–¥–Ω–µ–µ' if rule=='mean' else '–ü–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü'
        subtitle = f"–ò—Å—Ç–æ—á–Ω–∏–∫: —Å—Ç—Ä–æ–∫–∏ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥: {rule_text}."
        fig.update_layout(title={'text': f"{met}<br><sup>{subtitle}</sup>", 'x':0}, hovermode="x unified", margin=dict(t=70,l=0,r=0,b=0))
        fig.update_yaxes(tickformat=tickfmt, ticksuffix=suf.strip(), title_text=suf.strip() or None)
        fig.update_yaxes(type="log" if use_log else "linear")

        st.plotly_chart(fig, use_container_width=True)
        insight = _describe_deltas(deltas, met)
        if insight:
            _render_insights(f"–í—ã–≤–æ–¥—ã –ø–æ {met}", [insight])
        with st.expander(f"–î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ ¬´{met}¬ª"):
            st.dataframe(
                gp.pivot_table(index="–ú–µ—Å—è—Ü", columns="–†–µ–≥–∏–æ–Ω", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="sum", observed=False)
                  .reindex(x_domain),
                use_container_width=True
            )
        action_lines = _generate_actions_for_deltas(deltas, met)
        _render_plan(f"–î–µ–π—Å—Ç–≤–∏—è –ø–æ {met}", action_lines[:3])


def dynamics_compare_block(
    df_a: pd.DataFrame,
    df_b: pd.DataFrame,
    regions: list[str],
    months_range: list[str],
    color_map: Dict[str, str],
    year_a: int,
    year_b: int,
    *,
    default_metrics: List[str] | None = None,
    widget_prefix: str = "dyncmp"
) -> None:
    st.subheader(f"üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º: {year_b} vs {year_a}")

    raw_metric_names = sorted(set(pd.concat([df_a, df_b])["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique()))

    base_defaults = [Metrics.REVENUE.value, Metrics.LOAN_ISSUE.value, Metrics.MARKUP_PCT.value]
    if default_metrics:
        default_selection = [m for m in default_metrics if m in raw_metric_names]
    else:
        default_selection = [m for m in base_defaults if m in raw_metric_names]
    if not default_selection:
        default_selection = raw_metric_names[:3]

    metrics = st.multiselect(
        "–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
        options=raw_metric_names,
        default=default_selection,
        key=f"{widget_prefix}_metrics"
    )
    c1, c2, c3 = st.columns(3)
    only_actual = c1.checkbox("–¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Å—è—Ü—ã", True, key=f"{widget_prefix}_actual")
    show_trend = c2.checkbox("–õ–∏–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞", False, key=f"{widget_prefix}_trend")
    use_log = c3.checkbox("–õ–æ–≥. –æ—Å—å Y", False, key=f"{widget_prefix}_log")
    if not metrics or not months_range:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –ø–µ—Ä–∏–æ–¥."); return

    for met in metrics:
        rule = aggregation_rule(met)
        rule_text = '–°—É–º–º–∞' if rule=='sum' else '–°—Ä–µ–¥–Ω–µ–µ' if rule=='mean' else '–ü–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü'
        st.caption(f"–î–∞–Ω–Ω—ã–µ ‚Äî –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥: **{rule_text}**.")

        gp_a = get_monthly_totals_from_file(df_a, tuple(regions), met)
        gp_b = get_monthly_totals_from_file(df_b, tuple(regions), met)
        if gp_a.empty and gp_b.empty:
            st.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ ¬´{met}¬ª."); continue

        xA = sorted_months_safe(gp_a["–ú–µ—Å—è—Ü"]) if not gp_a.empty else []
        xB = sorted_months_safe(gp_b["–ú–µ—Å—è—Ü"]) if not gp_b.empty else []
        x_domain = [m for m in months_range if (m in xA or m in xB)] if only_actual else months_range
        if not x_domain:
            st.info(f"–ù–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Å—è—Ü–µ–≤ –¥–ª—è ¬´{met}¬ª."); continue

        fig = go.Figure()
        fig.update_layout(
            hovermode="x unified",
            legend=dict(
                traceorder="normal",   # –Ω–µ –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å
                tracegroupgap=10       # –≤–∏–∑—É–∞–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—è—Ç—å —Ä–µ–≥–∏–æ–Ω—ã
            )
        )

        def clean_region_label(reg: str) -> str:
            s = str(reg)
            s = re.sub(r"\b20\d{2}\b", "", s)         # –≤—ã–∫–∏–Ω—É—Ç—å ¬´2024/2025¬ª –∏–∑ –∏–º–µ–Ω–∏ —Ä–µ–≥–∏–æ–Ω–∞
            s = re.sub(r"\b\d{1,2}\s*-\s*\d{1,2}\b", "", s)  # ¬´1-8¬ª
            s = re.sub(r"[_\.\-‚Äì‚Äî]", " ", s)
            s = re.sub(r"\s{2,}", " ", s).strip()
            return s

        all_regs = set(gp_a["–†–µ–≥–∏–æ–Ω"].astype(str)).union(set(gp_b["–†–µ–≥–∏–æ–Ω"].astype(str)))
        region_order = [r for r in regions if r in all_regs] + [r for r in sorted(all_regs) if r not in regions]
        label_map = {r: clean_region_label(r) for r in all_regs}

        year_order = [year_a, year_b]          # –ø–æ—Ä—è–¥–æ–∫ –∏ –≤ –ª–µ–≥–µ–Ω–¥–µ, –∏ –≤ —Ö–æ–≤–µ—Ä–µ
        dash_map   = {year_a: "dot", year_b: "solid"}  # ¬´–±–∞–∑–∞¬ª = –ø—É–Ω–∫—Ç–∏—Ä, ¬´—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ¬ª = —Å–ø–ª–æ—à–Ω–∞—è

        tickfmt, suf = y_fmt_for_metric(met)
        def fmt_hover(v):
            if v is None or (isinstance(v, float) and np.isnan(v)): return "‚Äî"
            if tickfmt == ",.0f": return f"{v:,.0f}{suf}".replace(",", " ")
            if tickfmt == ".2f": return f"{v:.2f}{suf}"
            return f"{v:,.2f}{suf}".replace(",", " ")

        hovertemplate = (
            "<b>%{customdata[0]}</b><br>"
            "–ì–æ–¥: %{customdata[1]}<br>"
            "–ú–µ—Å—è—Ü: %{x}<br>"
            "–ó–Ω–∞—á–µ–Ω–∏–µ: %{customdata[2]}<extra></extra>"
        )

        delta_records: List[tuple[str, float]] = []
        for r_rank, reg in enumerate(region_order):
            for y in year_order:
                gp = gp_a if y == year_a else gp_b
                if gp.empty: 
                    continue
                t = gp[gp["–†–µ–≥–∏–æ–Ω"].astype(str) == reg].groupby("–ú–µ—Å—è—Ü", as_index=False)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum()
                s = t.set_index("–ú–µ—Å—è—Ü")["–ó–Ω–∞—á–µ–Ω–∏–µ"].reindex(x_domain)
                if s.isna().all():
                    continue

                vals = s.values.astype(float)
                fig.add_trace(go.Scatter(
                    x=s.index,
                    y=vals,
                    mode="lines+markers",
                    name=f"{label_map.get(reg, reg)} ¬∑ {y}",
                    line=dict(color=color_map.get(reg), dash=dash_map[y]),
                    legendgroup=label_map.get(reg, reg),     # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ª–µ–≥–µ–Ω–¥–æ–π –ø–æ —Ä–µ–≥–∏–æ–Ω—É
                    legendrank=r_rank * 10 + (0 if y == year_a else 1),  # —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
                    customdata=np.column_stack([
                        np.full(len(s), label_map.get(reg, reg)),
                        np.full(len(s), y),
                        [fmt_hover(v) for v in vals]
                    ]),
                    hovertemplate=hovertemplate
                ))

                if show_trend:
                    mask = ~np.isnan(vals)
                    if mask.sum() >= 2:
                        xp = np.arange(len(vals))
                        k, b = np.polyfit(xp[mask], vals[mask], 1)
                        fig.add_trace(go.Scatter(
                            x=s.index, y=k * xp + b,
                            mode="lines",
                            line=dict(color=color_map.get(reg), dash="dash"),
                            name=f"{label_map.get(reg, reg)} ¬∑ —Ç—Ä–µ–Ω–¥ ¬∑ {y}",
                            showlegend=False,
                            hoverinfo="skip",                # —Ç—Ä–µ–Ω–¥ –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ —Ö–æ–≤–µ—Ä
                            legendgroup=label_map.get(reg, reg),
                            legendrank=r_rank * 10 + (0 if y == year_a else 1)
                        ))
                clean_s = s.dropna()
                if len(clean_s) >= 2:
                    delta_records.append((f"{reg} ¬∑ {y}", float(clean_s.iloc[-1] - clean_s.iloc[0])))
        subtitle = f"–ò—Å—Ç–æ—á–Ω–∏–∫: —Å—Ç—Ä–æ–∫–∏ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥: {rule_text}."
        fig.update_layout(title={'text': f"{met}<br><sup>{subtitle}</sup>", 'x': 0},
                          hovermode="x unified", margin=dict(t=70, l=0, r=0, b=0))
        fig.update_yaxes(tickformat=tickfmt, ticksuffix=suf.strip(), title_text=suf.strip() or None)
        fig.update_yaxes(type="log" if use_log else "linear")
        st.plotly_chart(fig, use_container_width=True)
        insight = _describe_deltas(delta_records, met)
        if insight:
            _render_insights(f"–í—ã–≤–æ–¥—ã –ø–æ {met}", [insight])

def _aggregate_period(df_year: pd.DataFrame, regions: list[str], metric: str, months: list[str]) -> dict[str, float]:
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç—Ä–æ–≥–æ –∏–∑ —Å—Ç—Ä–æ–∫ '–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É' –ø–æ –ø—Ä–∞–≤–∏–ª—É –º–µ—Ç—Ä–∏–∫–∏."""
    dfm = get_monthly_totals_from_file(df_year, tuple(regions), metric)
    if dfm.empty:
        return {}
    part = dfm[dfm["–ú–µ—Å—è—Ü"].astype(str).isin(months)].copy()
    if part.empty:
        return {}
    rule = aggregation_rule(metric)
    out = {}
    for reg, g in part.groupby("–†–µ–≥–∏–æ–Ω"):
        vals = pd.to_numeric(g["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").dropna()
        if vals.empty:
            continue
        if rule == "sum":
            out[str(reg)] = float(vals.sum())
        elif rule == "mean":
            out[str(reg)] = float(vals.mean())
        elif rule == "last":
            out[str(reg)] = float(vals.iloc[-1])
        else:
            out[str(reg)] = float(vals.mean())
    return out


def treemap_heatmap_block(
    df_all: pd.DataFrame,
    regions: list[str],
    months_range: list[str],
    color_map: Dict[str, str],
    *,
    default_metric: str | None = None,
    metric_key: str = "treemap_metric",
    month_key: str = "treemap_month",
    mode_key: str = "treemap_mode",
    heat_metric_key: str = "heatmap_metric"
) -> None:
    st.subheader("üó∫Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –º–µ—Å—è—Ü–∞–º")
    st.caption("Treemap ‚Äî –≤–∫–ª–∞–¥ —Ñ–∏–ª–∏–∞–ª–æ–≤; —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç–∞ ‚Äî –ø–æ–º–µ—Å—è—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤.")

    sub = strip_totals_rows(df_all)
    sub = sub[(sub["–†–µ–≥–∏–æ–Ω"].isin(regions)) & (sub["–ú–µ—Å—è—Ü"].astype(str).isin(months_range))]
    if sub.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."); return

    raw_metric_names = sorted(set(df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique()))
    if not raw_metric_names:
        st.warning("–ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    # ==== –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (Treemap) ====
    st.markdown("**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º (–∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü)**")
    default_idx = 0
    default_candidate = default_metric or (Metrics.REVENUE.value if Metrics.REVENUE.value in raw_metric_names else None)
    if default_candidate and default_candidate in raw_metric_names:
        default_idx = raw_metric_names.index(default_candidate)
    metric = st.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –ø–ª–æ—â–∞–¥–∏",
        options=raw_metric_names,
        index=default_idx,
        key=metric_key,
        help=METRIC_HELP.get(default_candidate, "")
    )

    months_present = sorted_months_safe(sub["–ú–µ—Å—è—Ü"])
    if not months_present:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥."); return
    month_for_tree = st.selectbox("–ú–µ—Å—è—Ü –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã", options=months_present, index=len(months_present)-1, key=month_key)

    tree_base = sub[(sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric) & (sub["–ú–µ—Å—è—Ü"].astype(str) == month_for_tree)]
    tree_data = (tree_base.groupby(["–†–µ–≥–∏–æ–Ω","–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"], observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                       .sum().reset_index().rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "Size"}))

    if not tree_data.empty and pd.to_numeric(tree_data["Size"], errors="coerce").fillna(0).abs().sum() > 0:
        fig_t = px.treemap(
            tree_data, path=[px.Constant("–í—Å–µ"), "–†–µ–≥–∏–æ–Ω", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"],
            values="Size", color="–†–µ–≥–∏–æ–Ω", color_discrete_map=color_map
        )
        if "—Ä—É–±" in metric:
            fig_t.update_traces(texttemplate="%{label}<br>%{value:,.0f}".replace(",", " "),
                                hovertemplate="%{label}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{value:,.0f} ‚ÇΩ".replace(",", " "))
        elif is_percent_metric(metric):
            fig_t.update_traces(texttemplate="%{label}<br>%{value:.2f}%",
                                hovertemplate="%{label}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{value:.2f}%")
        else:
            fig_t.update_traces(texttemplate="%{label}<br>%{value:,.0f}".replace(",", " "),
                                hovertemplate="%{label}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{value:,.0f}".replace(",", " "))
        fig_t.update_layout(margin=dict(t=40,l=0,r=0,b=0), title=f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞: {metric} ¬∑ {month_for_tree}")
        st.plotly_chart(fig_t, use_container_width=True)
        insight_lines = []
        region_series = tree_data.groupby("–†–µ–≥–∏–æ–Ω")[["Size"]].sum()["Size"]
        insight = _describe_metric_series(region_series, metric)
        if insight:
            insight_lines.append(insight)
        top_branch = tree_data.sort_values("Size", ascending=False).iloc[0]
        top_name = f"{top_branch['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']} ({top_branch['–†–µ–≥–∏–æ–Ω']})"
        insight_lines.append(f"–ö—Ä—É–ø–Ω–µ–π—à–∏–π –≤–∫–ª–∞–¥ –¥–∞—ë—Ç {top_name}: {_format_value_for_metric(metric, top_branch['Size'])}.")
        _render_insights("–ß—Ç–æ –≤–∏–¥–Ω–æ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ", insight_lines)
        action_lines = _generate_actions_for_series(region_series, metric)
        _render_plan("–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π", action_lines[:3])
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.")

    st.divider()

    # ==== –¢–µ–ø–ª–æ–∫–∞—Ä—Ç–∞ ====
    st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –º–µ—Å—è—Ü–∞–º (—Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞)**")
    st.caption("–ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–æ–∫ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª. –î–ª—è –º–µ—Ç—Ä–∏–∫-—Å–Ω–∏–º–∫–æ–≤ (–∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å, –∫–æ–ª-–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤) –Ω–∏—á–µ–≥–æ –Ω–µ —Å—É–º–º–∏—Ä—É–µ–º ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Å—è—á–Ω—ã–π —Å–Ω–∏–º–æ–∫.")

    heat_default_idx = raw_metric_names.index(metric) if metric in raw_metric_names else 0
    heat_metric = st.selectbox(
        "–ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—ã",
        options=raw_metric_names,
        index=heat_default_idx,
        key=heat_metric_key,
        help=METRIC_HELP.get(metric, "")
    )
    by_subdiv = st.checkbox(
        "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º (–≤ —Å—Ç—Ä–æ–∫–∞—Ö)",
        value=False,
        key=mode_key,
        help="–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª. –í —Ä–µ–∂–∏–º–µ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º –¥–ª—è –º–µ—Ç—Ä–∏–∫-—Å–Ω–∏–º–∫–æ–≤ –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª–∏–∞–ª–∞."
    )

    if by_subdiv:
        df_loc = sub[sub["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == heat_metric].copy()
        df_loc["RowLabel"] = df_loc["–†–µ–≥–∏–æ–Ω"].astype(str) + " ¬∑ " + df_loc["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].astype(str)
        df_loc['–ú–µ—Å—è—Ü'] = pd.Categorical(df_loc['–ú–µ—Å—è—Ü'].astype(str), categories=ORDER, ordered=True)
        
        df_loc['__prio__'] = np.where(df_loc.get("–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞", pd.Series(index=df_loc.index, dtype=object)).eq("TOTALS_FILE"), 1, 2)
        df_loc.sort_values(["RowLabel", "–ú–µ—Å—è—Ü", "__prio__"], inplace=True)

        # –ø—Ä–∞–≤–∏–ª–æ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        rule = agg_of_metric(heat_metric)
        if heat_metric in METRICS_LAST or rule == "last":
            # —Å–Ω–∏–º–æ–∫: –Ω–∏–∫–∞–∫–∏—Ö —Å—É–º–º ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –æ–¥–Ω–æ (–ø–µ—Ä–≤–æ–µ –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É) –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ (—Ñ–∏–ª–∏–∞–ª, –º–µ—Å—è—Ü)
            df_loc = df_loc.drop_duplicates(["RowLabel", "–ú–µ—Å—è—Ü"], keep="first")
            aggfunc = "first"
        else:
            aggfunc = "sum" if rule == "sum" else "mean"

        hm = df_loc.pivot_table(index="RowLabel", columns="–ú–µ—Å—è—Ü", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc=aggfunc, observed=False)
    else:
        # —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: —É–∂–µ –±–µ—Ä—ë–º —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –≤ ¬´–ò—Ç–æ–≥–æ –ø–æ –º–µ—Å—è—Ü—É¬ª
        mat = month_totals_matrix(df_all, tuple(regions), heat_metric)
        hm = mat.pivot_table(index="–†–µ–≥–∏–æ–Ω", columns="–ú–µ—Å—è—Ü", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="first", observed=False)

    if 'hm' in locals() and not hm.empty:
        hm = hm.reindex(columns=[m for m in months_range if m in hm.columns])
        hm = hm.loc[hm.mean(axis=1, numeric_only=True).sort_values(ascending=False).index]

        text_fmt = ".2f" if is_percent_metric(heat_metric) else ".0f"
        fig_h = px.imshow(hm, text_auto=text_fmt, aspect="auto", color_continuous_scale="RdYlGn",
                        title=f"–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: {heat_metric}")

        # –ø–æ–Ω—è—Ç–Ω—ã–π —Ö–æ–≤–µ—Ä —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏
        if "—Ä—É–±" in heat_metric:
            fig_h.update_traces(hovertemplate="–°—Ç—Ä–æ–∫–∞: %{y}<br>–ú–µ—Å—è—Ü: %{x}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{z:,.0f} ‚ÇΩ<extra></extra>".replace(",", " "))
        elif is_percent_metric(heat_metric):
            fig_h.update_traces(hovertemplate="–°—Ç—Ä–æ–∫–∞: %{y}<br>–ú–µ—Å—è—Ü: %{x}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{z:.2f}%<extra></extra>")
        elif "–¥–Ω–µ–π" in heat_metric:
            fig_h.update_traces(hovertemplate="–°—Ç—Ä–æ–∫–∞: %{y}<br>–ú–µ—Å—è—Ü: %{x}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{z:.2f} –¥–Ω.<extra></extra>")
        else:
            fig_h.update_traces(hovertemplate="–°—Ç—Ä–æ–∫–∞: %{y}<br>–ú–µ—Å—è—Ü: %{x}<br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{z:,.0f}<extra></extra>".replace(",", " "))

        fig_h.update_layout(margin=dict(t=40,l=0,r=0,b=0), coloraxis_colorbar_title="–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å")
        st.plotly_chart(fig_h, use_container_width=True)
        insight_lines = []
        stack_vals = hm.stack().dropna()
        if not stack_vals.empty:
            if heat_metric in METRICS_SMALLER_IS_BETTER:
                target = stack_vals.idxmin()
            else:
                target = stack_vals.idxmax()
            row_label, month_label = target
            insight_lines.append(
                f"–ü–∏–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {row_label} / {month_label} ({_format_value_for_metric(heat_metric, stack_vals.loc[target])})."
            )
        row_means = hm.mean(axis=1, numeric_only=True)
        if not row_means.dropna().empty:
            insight = _describe_metric_series(row_means, heat_metric)
            if insight:
                insight_lines.append(insight)
        _render_insights("–í—ã–≤–æ–¥—ã –ø–æ —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç–µ", insight_lines)
        action_lines = _generate_actions_for_series(row_means, heat_metric)
        _render_plan("–î–µ–π—Å—Ç–≤–∏—è –ø–æ —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç–µ", action_lines[:3])
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–ø–ª–æ–∫–∞—Ä—Ç—ã.")




def monthly_totals_table(df_raw: pd.DataFrame, regions: list[str], months_range: list[str], all_available_months: list[str]) -> pd.DataFrame:
    if df_raw.empty or not months_range:
        return pd.DataFrame()

    filtered = df_raw[
        df_raw["–†–µ–≥–∏–æ–Ω"].isin(regions) &
        df_raw["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].str.contains(r"^\s*–∏—Ç–æ–≥–æ\b", case=False, na=False)
    ].copy()
    if filtered.empty:
        filtered = df_raw[df_raw["–†–µ–≥–∏–æ–Ω"].isin(regions)].copy()

    all_metrics = sorted(filtered["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique().tolist())
    rows = []

    for metric in all_metrics:
        dfm = get_monthly_totals_from_file(df_raw, tuple(regions), metric)
        if dfm.empty:
            fallback = df_raw[
                df_raw["–†–µ–≥–∏–æ–Ω"].isin(regions) &
                (df_raw["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] == metric) &
                (df_raw["–ú–µ—Å—è—Ü"].astype(str) != "–ò—Ç–æ–≥–æ")
            ]
            dfm = fallback.groupby("–ú–µ—Å—è—Ü", observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum().reset_index()
        else:
            dfm = dfm.groupby("–ú–µ—Å—è—Ü", observed=True)["–ó–Ω–∞—á–µ–Ω–∏–µ"].sum().reset_index()
        row = {"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": metric}
        rule = aggregation_rule(metric)

        for m in months_range:
            mask = dfm["–ú–µ—Å—è—Ü"].astype(str) == m
            vals = pd.to_numeric(dfm.loc[mask, "–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
            if vals.empty:
                row[m] = np.nan
            else:
                if rule == "mean":
                    row[m] = float(vals.mean())
                else:
                    row[m] = float(vals.sum())

        avail = [m for m in months_range if pd.notna(row.get(m))]
        if not avail:
            row["–ò—Ç–æ–≥–æ"] = np.nan
        else:
            series = pd.Series([row[m] for m in avail], index=avail)
            if rule == "sum":
                row["–ò—Ç–æ–≥–æ"] = float(series.sum())
            elif rule == "mean":
                row["–ò—Ç–æ–≥–æ"] = float(series.mean())
            elif rule == "last":
                row["–ò—Ç–æ–≥–æ"] = float(series.iloc[-1])
            else:
                row["–ò—Ç–æ–≥–æ"] = np.nan
        rows.append(row)

    dfw = pd.DataFrame(rows, columns=["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] + months_range + ["–ò—Ç–æ–≥–æ"])

    priority_map = {
        Metrics.DEBT_NO_SALE.value: 0,
        Metrics.DEBT.value: 1,
        Metrics.DEBT_UNITS.value: 2,
    }

    def row_order(s):
        return s.map(lambda name: priority_map.get(name, 3 if "—Ä—É–±" in name or "—à—Ç" in name else 4))

    return dfw.sort_values(by="–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", key=row_order).reset_index(drop=True)

def provided_totals_from_files(df_all: pd.DataFrame, regions: list[str], months_range: list[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    df_tot = df_all[
        (df_all["–†–µ–≥–∏–æ–Ω"].isin(regions)) &
        df_all["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].str.contains(r"^\s*–∏—Ç–æ–≥–æ\b", case=False, na=False) &
        (df_all["–ú–µ—Å—è—Ü"].astype(str).isin(months_range + ["–ò—Ç–æ–≥–æ"]))
    ].copy()
    if df_tot.empty:
        return pd.DataFrame(), pd.DataFrame()

    priority_map = {"RECALC_TOTAL": 0, "TOTALS_FILE": 1}
    src = df_tot.get("–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞", pd.Series(index=df_tot.index, dtype=object))
    df_tot["__prio__"] = src.map(priority_map).fillna(2).astype(int)
    df_tot.sort_values(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å","–ú–µ—Å—è—Ü","__prio__"], inplace=True)
    best = df_tot.groupby(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å","–ú–µ—Å—è—Ü"], observed=True).first().reset_index()

    totals_row = best.pivot_table(index="–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", columns="–ú–µ—Å—è—Ü", values="–ó–Ω–∞—á–µ–Ω–∏–µ", aggfunc="first", observed=False).reset_index()
    cols_ordered = ["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] + [m for m in months_range if m in totals_row.columns] + (["–ò—Ç–æ–≥–æ"] if "–ò—Ç–æ–≥–æ" in totals_row.columns else [])
    totals_row = totals_row.reindex(columns=cols_ordered)

    totals_col = pd.DataFrame()
    if "–ò—Ç–æ–≥–æ" in best["–ú–µ—Å—è—Ü"].astype(str).unique():
        it_col = best[best["–ú–µ—Å—è—Ü"].astype(str) == "–ò—Ç–æ–≥–æ"][["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"]].rename(columns={"–ó–Ω–∞—á–µ–Ω–∏–µ": "–ò—Ç–æ–≥–æ"})
        totals_col = it_col.groupby("–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å")["–ò—Ç–æ–≥–æ"].first().reset_index()

    return totals_row, totals_col


def month_check_block(df_all: pd.DataFrame, regions: list[str], months_range: list[str], all_available_months: list[str]):
    st.subheader("üìÖ –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –º–µ—Å—è—Ü–∞–º")
    st.caption("–ò—Ç–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–π –º–µ—Ç–æ–¥–∏–∫–µ.")
    if df_all.empty or not months_range: st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."); return
    table = monthly_totals_table(df_all, regions, months_range, all_available_months)
    if table.empty: st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã."); return
    colcfg = {c: st.column_config.NumberColumn(c, format="%.0f") for c in table.columns if c != "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"}
    colcfg["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"] = st.column_config.TextColumn("–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å")
    st.dataframe(table, use_container_width=True, column_config=colcfg)

def export_block(df_long: pd.DataFrame):
    st.subheader("üì• –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö"); st.caption("–î–ª–∏–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: –†–µ–≥–∏–æ–Ω ¬∑ –ì–æ–¥ ¬∑ –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ ¬∑ –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å ¬∑ –ú–µ—Å—è—Ü ¬∑ –ó–Ω–∞—á–µ–Ω–∏–µ.")
    csv_bytes = df_long.to_csv(index=False).encode("utf-8-sig")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (CSV)", data=csv_bytes, file_name="NUZ_combined_Long.csv", mime="text/csv")

def info_block():
    st.header("‚ÑπÔ∏è –°–ø—Ä–∞–≤–∫–∞ –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ")
    st.markdown("""
### –ö–ª—é—á —Ä–∞—Å—á—ë—Ç–∞
- **–í —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ –≤—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –±–µ—Ä—É—Ç—Å—è —Å—Ç—Ä–æ–≥–æ –∏–∑ —Ñ–∞–π–ª–∞.**
- **–í –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π –ù–Æ–ó (–Æ–ó –∏ ¬´–û–±—â–µ–µ¬ª –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ).**
- **–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—ë–º –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Å–ª–æ–≤–∞—Ä—é –ù–Æ–ó-–º–µ—Ç—Ä–∏–∫; —Å—Ç—Ä–æ–∫–∏ –≤–Ω–µ —Å–ª–æ–≤–∞—Ä—è –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.**
- **–°—É–º–º—ã (—Ä—É–±, —à—Ç):** –∞–≥—Ä–µ–≥–∏—Ä—É—é—Ç—Å—è –∫–∞–∫ **—Å—É–º–º–∞** –º–µ—Å—è—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∑–∞ –ø–µ—Ä–∏–æ–¥.
- **–ü—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –¥–æ–ª–∏ (%):** –∞–≥—Ä–µ–≥–∏—Ä—É—é—Ç—Å—è –∫–∞–∫ **–ø—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ** –º–µ—Å—è—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∑–∞ –ø–µ—Ä–∏–æ–¥.
- **–°—Å—É–¥–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å:** –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ **–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ** –∑–∞ –ø–µ—Ä–∏–æ–¥ (—Å–Ω–∏–º–æ–∫ –Ω–∞ –∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞).
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–º–±–∞—Ä–¥–æ–≤:** –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ **–ø–æ—Å–ª–µ–¥–Ω–µ–µ** –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞ –ø–µ—Ä–∏–æ–¥ (—Å–Ω–∏–º–æ–∫ –Ω–∞ –∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞).

### –°–æ–≤–µ—Ç—ã –ø–æ –∞–Ω–∞–ª–∏–∑—É
- **–ï—Å–ª–∏ –¥–æ–ª—è –ø—Ä–æ–¥–∞–∂ –Ω–∏–∂–µ –∑–∞–π–º–∞ —Ä–∞—Å—Ç–µ—Ç**, –æ–∂–∏–¥–∞–π—Ç–µ —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞—Ü–µ–Ω–∫–∏ –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —É–≤–µ–ª–∏—á–µ–Ω–∏—è –æ–±—ä–µ–º–∞ –Ω–µ–ª–∏–∫–≤–∏–¥–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –æ—Ü–µ–Ω–∫–∏ –∑–∞–ª–æ–≥–æ–≤ –≤ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è—Ö —Å –≤—ã—Å–æ–∫–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º —ç—Ç–æ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è.
- **–í—ã—Å–æ–∫–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (–ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è) –Ω–µ –≤—Å–µ–≥–¥–∞ —Ö–æ—Ä–æ—à–æ**, –µ—Å–ª–∏ –ø—Ä–∏ —ç—Ç–æ–º –º–Ω–æ–≥–æ –∑–∞–ª–æ–≥–æ–≤ —É—Ö–æ–¥–∏—Ç –≤ –ø—Ä–æ–¥–∞–∂—É. –ò—â–∏—Ç–µ –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–º –¥–æ—Ö–æ–¥–æ–º –∏ –∫–∞—á–µ—Å—Ç–≤–æ–º –∑–∞–ª–æ–≥–æ–≤: –∏–¥–µ–∞–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ ‚Äì —É–º–µ—Ä–µ–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –¥–æ–ª–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂.
- **–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∑–∞–π–º–∞ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞ –∏–∑–¥–µ–ª–∏–π**. –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —Å—Ä–µ–¥–Ω–∏–µ —Å—É–º–º—ã –º–æ–≥—É—Ç –æ–∑–Ω–∞—á–∞—Ç—å, —á—Ç–æ —Ñ–∏–ª–∏–∞–ª –≤—ã–¥–∞–µ—Ç –∑–∞–π–º—ã –ø–æ–¥ –¥–æ—Ä–æ–≥–∏–µ —Ç–æ–≤–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–ª–∏–µ–Ω—Ç–∞–º —Å–ª–æ–∂–Ω–µ–µ –≤—ã–∫—É–ø–∏—Ç—å, —á—Ç–æ –ø–æ–≤—ã—à–∞–µ—Ç —Ä–∏—Å–∫ –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ —Ä–∞—Å–ø—Ä–æ–¥–∞–∂—É.
""")

def main():
    st.markdown(f"# üìä –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—à–±–æ—Ä–¥: –ù–Æ–ó  \n<span class='badge'>–í–µ—Ä—Å–∏—è {APP_VERSION}</span>", unsafe_allow_html=True)
    sidebar = st.sidebar.container()
    with sidebar:
        st.markdown("<p class='sidebar-title'>–§–∞–π–ª—ã</p>", unsafe_allow_html=True)
        region_prefix = st.text_input(
            "–ü—Ä–µ—Ñ–∏–∫—Å —Ä–µ–≥–∏–æ–Ω–∞",
            value="",
            placeholder="–ü—Ä–µ—Ñ–∏–∫—Å —Ä–µ–≥–∏–æ–Ω–∞",
            label_visibility="collapsed"
        )
        uploads = st.file_uploader(
            "–§–∞–π–ª—ã Excel",
            type=["xlsx", "xls"],
            accept_multiple_files=True,
            label_visibility="collapsed"
        )
        st.caption("–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ .xlsx/.xls." )
    if not uploads: st.info("‚¨ÖÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ Excel –¥–ª—è —Å—Ç–∞—Ä—Ç–∞."); st.stop()
    # strict_mode —Ç–µ–ø–µ—Ä—å –Ω–µ –Ω—É–∂–µ–Ω –∫–∞–∫ –æ–ø—Ü–∏—è, –æ–Ω –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≥–ª–æ–±–∞–ª—å–Ω—ã–º —Ñ–ª–∞–≥–æ–º SIMPLE_MODE
    strict_mode = SIMPLE_MODE

    dfs, errors = [], []
    with st.spinner("–ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤..."):
        for up in uploads:
            try:
                stem = Path(up.name).stem
                region_name = f"{region_prefix.strip()}: {stem}" if region_prefix.strip() else stem
                year_guess = guess_year_from_filename(up.name)

                key_year = f"year_for_{up.name}"
                if year_guess is None:
                    st.sidebar.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–æ–¥ –∏–∑ –∏–º–µ–Ω–∏: {up.name}")
                    st.sidebar.caption("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–¥ –≤—Ä—É—á–Ω—É—é.")
                    year_guess = st.sidebar.selectbox(
                        f"–ì–æ–¥ –¥–ª—è —Ñ–∞–π–ª–∞: {up.name}",
                        options=[2023, 2024, 2025, 2026],
                        index=1,
                        key=key_year
                    )
                dfs.append(parse_excel(up.getvalue(), region_name, file_year=year_guess))
            except Exception as e:
                errors.append(f"**{up.name}**: {e}")

    if errors: st.error("–û—à–∏–±–∫–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤:\n\n" + "\n\n".join(errors))
    if not dfs: st.stop()
    df_all = pd.concat(dfs, ignore_index=True)
    df_all = append_risk_share_metric(df_all)

    # –¥–æ–ø. –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—è "–†–µ–≥–∏–æ–Ω"
    df_all["–†–µ–≥–∏–æ–Ω"] = (df_all["–†–µ–≥–∏–æ–Ω"]
        .str.replace(r"\s{2,}", " ", regex=True)
        .str.replace(r"[¬∑.]+$", "", regex=True)
        .str.strip()
        .astype("string")
    )

    df_all["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(df_all["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce")
    df_all["–ì–æ–¥"] = pd.to_numeric(df_all["–ì–æ–¥"], errors="coerce").astype("Int64")
    for c in ["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ö–æ–¥", "–ú–µ—Å—è—Ü", "–ò—Å—Ç–æ—á–Ω–∏–∫–§–∞–π–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è"]:
        if c == "–ú–µ—Å—è—Ü":
            df_all[c] = df_all[c].astype(pd.CategoricalDtype(categories=ORDER_WITH_TOTAL, ordered=True))
        else:
            df_all[c] = df_all[c].astype("string")

    years_all = sorted([int(y) for y in pd.Series(df_all["–ì–æ–¥"].dropna().unique()).astype(int)])
    if not years_all:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–æ–¥ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑ —Ñ–∞–π–ª–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ–¥ –≤—Ä—É—á–Ω—É—é.")
        st.stop()

    mask_pct = df_all["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].apply(is_percent_metric)
    df_all.loc[mask_pct, "–ó–Ω–∞—á–µ–Ω–∏–µ"] = normalize_percent_series(df_all.loc[mask_pct, "–ó–Ω–∞—á–µ–Ω–∏–µ"])

    scenario_options = list(SCENARIO_CONFIGS.keys())
    with sidebar:
        st.markdown("<hr class='sidebar-divider'>", unsafe_allow_html=True)
        st.markdown("<p class='sidebar-title'>–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞</p>", unsafe_allow_html=True)
        scenario_name = st.selectbox(
            "–°—Ü–µ–Ω–∞—Ä–∏–π",
            options=scenario_options,
            index=0,
            label_visibility="collapsed"
        )
        st.caption("–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤—ã–≤–æ–¥—ã –±—É–¥—É—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º–∏.")
        mode_year = st.radio(
            "–†–µ–∂–∏–º",
            options=["–û–¥–∏–Ω –≥–æ–¥", "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤"],
            index=0,
            horizontal=True,
            label_visibility="collapsed",
            key="analysis_mode"
        )
        st.caption("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤ –ø–æ–∑–≤–æ–ª–∏—Ç —É–≤–∏–¥–µ—Ç—å –¥–∏–Ω–∞–º–∏–∫—É –≥–æ–¥-–∫-–≥–æ–¥—É.")

    if mode_year == "–û–¥–∏–Ω –≥–æ–¥":
        with sidebar:
            st.markdown("<p class='sidebar-title'>–ì–æ–¥</p>", unsafe_allow_html=True)
            year_current = st.selectbox(
                "–ì–æ–¥",
                options=years_all,
                index=len(years_all) - 1,
                label_visibility="collapsed",
                key="single_year_select"
            )
        df_current = df_all[df_all["–ì–æ–¥"] == year_current].copy()
        months_in_data = sorted_months_safe(df_current["–ú–µ—Å—è—Ü"])
        if not months_in_data:
            st.error("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–º –≥–æ–¥—É –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–º–∏ –º–µ—Å—è—Ü–∞–º–∏."); st.stop()
        df_previous = None
        year_previous = None
    else:
        with sidebar:
            st.markdown("<p class='sidebar-title'>–ì–æ–¥—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è</p>", unsafe_allow_html=True)
            col_a, col_b = st.columns(2)
            year_previous = col_a.selectbox("–ì–æ–¥ A", options=years_all, index=max(0, len(years_all) - 2), key="year_a", label_visibility="collapsed")
            year_current = col_b.selectbox("–ì–æ–¥ B", options=years_all, index=len(years_all) - 1, key="year_b", label_visibility="collapsed")
        df_previous = df_all[df_all["–ì–æ–¥"] == year_previous].copy()
        df_current = df_all[df_all["–ì–æ–¥"] == year_current].copy()
        months_a = sorted_months_safe(df_previous["–ú–µ—Å—è—Ü"])
        months_b = sorted_months_safe(df_current["–ú–µ—Å—è—Ü"])
        months_in_data = [m for m in ORDER if m in months_a and m in months_b]
        if not months_in_data:
            st.error("–í –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥–æ–¥–æ–≤ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Å—è—Ü—É."); st.stop()

    with sidebar:
        st.markdown("<hr class='sidebar-divider'>", unsafe_allow_html=True)
        st.markdown("<p class='sidebar-title'>–ë—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–∏–æ–¥</p>", unsafe_allow_html=True)
    if "global_period" not in st.session_state:
        st.session_state["global_period"] = (months_in_data[0], months_in_data[-1])

    preset = st.radio(
        "–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä",
        options=["–í–µ—Å—å –ø–µ—Ä–∏–æ–¥", "–ö–≤–∞—Ä—Ç–∞–ª", "2 –º–µ—Å.", "–¢–µ–∫—É—â–∏–π –º–µ—Å."],
        index=0,
        horizontal=True,
        key="period_preset",
        label_visibility="collapsed"
    )
    if preset == "–í–µ—Å—å –ø–µ—Ä–∏–æ–¥":
        st.session_state["global_period"] = (months_in_data[0], months_in_data[-1])
    elif preset == "–ö–≤–∞—Ä—Ç–∞–ª":
        rng = months_in_data[-3:] if len(months_in_data) >= 3 else months_in_data
        st.session_state["global_period"] = (rng[0], rng[-1])
    elif preset == "2 –º–µ—Å.":
        rng = months_in_data[-2:] if len(months_in_data) >= 2 else months_in_data
        st.session_state["global_period"] = (rng[0], rng[-1])
    else:
        last_month = months_in_data[-1]
        st.session_state["global_period"] = (last_month, last_month)

    start_default, end_default = st.session_state.get("global_period", (months_in_data[0], months_in_data[-1]))
    if start_default not in months_in_data or end_default not in months_in_data:
        start_default, end_default = months_in_data[0], months_in_data[-1]

    with sidebar:
        start_m, end_m = st.select_slider(
            "–ü–µ—Ä–∏–æ–¥",
            options=months_in_data,
            value=(start_default, end_default),
            key="period_slider",
            label_visibility="collapsed"
        )
        st.caption(f"–ü–µ—Ä–∏–æ–¥: {start_m} ‚Äì {end_m}")
    months_range = ORDER[ORDER.index(start_m): ORDER.index(end_m) + 1]

    with sidebar:
        st.markdown("<hr class='sidebar-divider'>", unsafe_allow_html=True)
        st.markdown("<p class='sidebar-title'>–ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è</p>", unsafe_allow_html=True)
        thresholds_state = st.session_state.get("thresholds_config", {"min_markup": 45.0, "max_risk": 25.0, "loss_cap": 5.0})
        min_markup_threshold = st.number_input(
            "–ú–∏–Ω. –Ω–∞—Ü–µ–Ω–∫–∞, %",
            min_value=0.0,
            max_value=200.0,
            value=float(thresholds_state.get("min_markup", 45.0)),
            step=1.0,
            key="threshold_min_markup"
        )
        max_risk_threshold = st.number_input(
            "–ú–∞–∫—Å. —Ä–∏—Å–∫, %",
            min_value=0.0,
            max_value=100.0,
            value=float(thresholds_state.get("max_risk", 25.0)),
            step=1.0,
            key="threshold_max_risk"
        )
        loss_cap_threshold = st.number_input(
            "–õ–∏–º–∏—Ç —É–±—ã—Ç–∫–∞, –º–ª–Ω ‚ÇΩ",
            min_value=0.0,
            max_value=500.0,
            value=float(thresholds_state.get("loss_cap", 5.0)),
            step=0.5,
            key="threshold_loss_cap"
        )

    thresholds_config = {
        "min_markup": float(min_markup_threshold),
        "max_risk": float(max_risk_threshold),
        "loss_cap": float(loss_cap_threshold),
    }
    st.session_state["thresholds_config"] = thresholds_config

    with sidebar:
        st.markdown("<hr class='sidebar-divider'>", unsafe_allow_html=True)
        st.markdown("<p class='sidebar-title'>–î–µ–π—Å—Ç–≤–∏—è</p>", unsafe_allow_html=True)
        col_reset, col_restart = st.columns(2)
        reset_trigger = col_reset.button("–°–±—Ä–æ—Å", use_container_width=True, key="btn_reset")
        restart_trigger = col_restart.button("–ù–æ–≤—ã–π —Å—Ç–∞—Ä—Ç", use_container_width=True, key="btn_restart")

    if reset_trigger:
        st.session_state.clear()
        st.rerun()

    if restart_trigger:
        st.cache_data.clear()
        st.session_state.clear()
        st.rerun()

    tab_specs = [
        ("üìä", "–ì–ª–∞–≤–Ω–∞—è", render_home_page),
        ("üöÄ", "–í—ã–¥–∞—á–∏", render_issuance_page),
        ("üí∞", "–ü—Ä–æ—Ü–µ–Ω—Ç—ã", render_interest_page),
        ("üõçÔ∏è", "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", render_sales_page),
        ("üß≠", "–°—Ä–∞–≤–Ω–µ–Ω–∏—è", render_comparison_page),
        ("üë•", "–ö–æ–≥–æ—Ä—Ç—ã", render_cohort_page),
        ("üß™", "–°—Ü–µ–Ω–∞—Ä–∏–∏+", render_market_lab_page),
        ("üîÆ", "–ü—Ä–æ–≥–Ω–æ–∑", render_forecast_page),
        ("‚ö†Ô∏è", "–†–∏—Å–∫–∏", render_risk_page),
        ("üìÅ", "–î–∞–Ω–Ω—ã–µ", render_data_page),
        ("ü§ñ", "AI", render_ai_page),
    ]

    if mode_year == "–û–¥–∏–Ω –≥–æ–¥":
        regions_all = sorted(map(str, df_current["–†–µ–≥–∏–æ–Ω"].unique()))
        with sidebar:
            st.markdown("<p class='sidebar-title'>–†–µ–≥–∏–æ–Ω—ã</p>", unsafe_allow_html=True)
            pending_key = "single_regions_pending"
            if pending_key in st.session_state:
                st.session_state["single_regions"] = st.session_state.pop(pending_key)
            if "single_regions" not in st.session_state:
                st.session_state["single_regions"] = regions_all
            regions = st.multiselect(
                "–†–µ–≥–∏–æ–Ω—ã",
                options=regions_all,
                default=regions_all,
                label_visibility="collapsed",
                placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã",
                key="single_regions"
            )
            st.caption(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(regions)} –∏–∑ {len(regions_all)} —Ä–µ–≥–∏–æ–Ω–æ–≤.")
            preset_cols = st.columns(3)
            top_revenue_regions = _top_regions_by_metric(df_current, regions_all, months_range, Metrics.REVENUE.value, top_n=5)
            high_risk_regions = _top_regions_by_metric(df_current, regions_all, months_range, Metrics.RISK_SHARE.value, top_n=5)
            branch_map = period_values_by_region_from_itogo(df_current, regions_all, Metrics.BRANCH_NEW_COUNT.value, months_range)
            new_branch_regions = [reg for reg, val in sorted(branch_map.items(), key=lambda kv: kv[1] if kv[1] is not None else 0, reverse=True) if val and not pd.isna(val) and val > 0][:5] if branch_map else []
            def _queue_single_regions(values: list[str]) -> None:
                st.session_state[pending_key] = values

            preset_cols[0].button(
                "–¢–û–ü-5 –≤—ã—Ä—É—á–∫–∞",
                use_container_width=True,
                key="single_preset_revenue",
                disabled=not top_revenue_regions,
                on_click=_queue_single_regions,
                args=(top_revenue_regions,),
            )
            preset_cols[1].button(
                "–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫",
                use_container_width=True,
                key="single_preset_risk",
                disabled=not high_risk_regions,
                on_click=_queue_single_regions,
                args=(high_risk_regions,),
            )
            preset_cols[2].button(
                "–ù–æ–≤—ã–µ —Ñ–∏–ª–∏–∞–ª—ã",
                use_container_width=True,
                key="single_preset_new",
                disabled=not new_branch_regions,
                on_click=_queue_single_regions,
                args=(new_branch_regions,),
            )
        if not regions:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–µ–≥–∏–æ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            st.stop()

        color_map = consistent_color_map(tuple(regions_all))
        agg_current = get_aggregated_data(df_current, tuple(regions), tuple(months_range))

        meta = f"{len(regions)} –∏–∑ {len(regions_all)} —Ä–µ–≥–∏–æ–Ω–æ–≤ ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {months_range[0]} ‚Äì {months_range[-1]}"
        st.markdown(
            f"""
            <div class="hero">
                <span class="hero-pill">{scenario_name}</span>
                <div class="hero__title">–ê–Ω–∞–ª–∏–∑ {year_current}</div>
                <div class="hero__meta">{meta}</div>
            </div>
            """,
            unsafe_allow_html=True,
        )

        stats_cols = st.columns(4)
        stats_cols[0].metric("–§–∞–π–ª–æ–≤", len(uploads))
        stats_cols[1].metric("–†–µ–≥–∏–æ–Ω–æ–≤", len(regions_all))
        stats_cols[2].metric("–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π", strip_totals_rows(df_current)["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].nunique())
        stats_cols[3].metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", f"{months_in_data[0]} ‚Äì {months_in_data[-1]}")
        st.divider()

        ctx = PageContext(
            mode="single",
            df_current=df_current,
            df_previous=None,
            agg_current=agg_current,
            regions=regions,
            months_range=months_range,
            months_available=months_in_data,
            scenario_name=scenario_name,
            year_current=year_current,
            year_previous=None,
            color_map=color_map,
            strict_mode=strict_mode,
            thresholds=thresholds_config,
        )

        tabs = st.tabs([f"{icon} {title}" for icon, title, _ in tab_specs])
        for tab, (_, _, renderer) in zip(tabs, tab_specs):
            with tab:
                renderer(ctx)
    else:
        combined = pd.concat([df_previous, df_current], ignore_index=True)
        regions_all = sorted(map(str, combined["–†–µ–≥–∏–æ–Ω"].unique()))
        with sidebar:
            st.markdown("<p class='sidebar-title'>–†–µ–≥–∏–æ–Ω—ã</p>", unsafe_allow_html=True)
            pending_key = "compare_regions_pending"
            if pending_key in st.session_state:
                st.session_state["compare_regions"] = st.session_state.pop(pending_key)
            if "compare_regions" not in st.session_state:
                st.session_state["compare_regions"] = regions_all
            regions = st.multiselect(
                "–†–µ–≥–∏–æ–Ω—ã",
                options=regions_all,
                default=regions_all,
                label_visibility="collapsed",
                placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã",
                key="compare_regions"
            )
            st.caption(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(regions)} –∏–∑ {len(regions_all)} —Ä–µ–≥–∏–æ–Ω–æ–≤.")
            preset_cols = st.columns(3)
            top_revenue_regions = _top_regions_by_metric(df_current, regions_all, months_range, Metrics.REVENUE.value, top_n=5)
            high_risk_regions = _top_regions_by_metric(df_current, regions_all, months_range, Metrics.RISK_SHARE.value, top_n=5)
            branch_map_cmp = period_values_by_region_from_itogo(df_current, regions_all, Metrics.BRANCH_NEW_COUNT.value, months_range)
            new_branch_regions = [reg for reg, val in sorted(branch_map_cmp.items(), key=lambda kv: kv[1] if kv[1] is not None else 0, reverse=True) if val and not pd.isna(val) and val > 0][:5] if branch_map_cmp else []
            def _queue_compare_regions(values: list[str]) -> None:
                st.session_state[pending_key] = values

            preset_cols[0].button(
                "–¢–û–ü-5 –≤—ã—Ä—É—á–∫–∞",
                use_container_width=True,
                key="compare_preset_revenue",
                disabled=not top_revenue_regions,
                on_click=_queue_compare_regions,
                args=(top_revenue_regions,),
            )
            preset_cols[1].button(
                "–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫",
                use_container_width=True,
                key="compare_preset_risk",
                disabled=not high_risk_regions,
                on_click=_queue_compare_regions,
                args=(high_risk_regions,),
            )
            preset_cols[2].button(
                "–ù–æ–≤—ã–µ —Ñ–∏–ª–∏–∞–ª—ã",
                use_container_width=True,
                key="compare_preset_new",
                disabled=not new_branch_regions,
                on_click=_queue_compare_regions,
                args=(new_branch_regions,),
            )
        if not regions:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–µ–≥–∏–æ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            st.stop()

        color_map = consistent_color_map(tuple(regions_all))
        agg_current = get_aggregated_data(df_current, tuple(regions), tuple(months_range))

        meta = f"{len(regions)} –∏–∑ {len(regions_all)} —Ä–µ–≥–∏–æ–Ω–æ–≤ ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {months_range[0]} ‚Äì {months_range[-1]}"
        st.markdown(
            f"""
            <div class="hero">
                <span class="hero-pill">{scenario_name}</span>
                <div class="hero__title">–°—Ä–∞–≤–Ω–µ–Ω–∏–µ {year_current} vs {year_previous}</div>
                <div class="hero__meta">{meta}</div>
            </div>
            """,
            unsafe_allow_html=True,
        )

        stats_cols = st.columns(4)
        stats_cols[0].metric("–§–∞–π–ª–æ–≤", len(uploads))
        stats_cols[1].metric("–†–µ–≥–∏–æ–Ω–æ–≤", len(regions_all))
        stats_cols[2].metric("–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π", strip_totals_rows(combined)["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"].nunique())
        stats_cols[3].metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", f"{months_in_data[0]} ‚Äì {months_in_data[-1]}")
        st.divider()

        ctx = PageContext(
            mode="compare",
            df_current=df_current,
            df_previous=df_previous,
            agg_current=agg_current,
            regions=regions,
            months_range=months_range,
            months_available=months_in_data,
            scenario_name=scenario_name,
            year_current=year_current,
            year_previous=year_previous,
            color_map=color_map,
            strict_mode=strict_mode,
            thresholds=thresholds_config,
        )

        tabs = st.tabs([f"{icon} {title}" for icon, title, _ in tab_specs])
        for tab, (_, _, renderer) in zip(tabs, tab_specs):
            with tab:
                renderer(ctx)


def render_home_page(ctx: PageContext) -> None:
    available_metrics = set(ctx.df_current["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"].dropna().unique())
    missing_core = [m for m in KEY_DECISION_METRICS if m not in available_metrics]
    tab_hints = {
        name: [metric for metric in metrics if metric not in available_metrics]
        for name, metrics in TAB_METRIC_DEPENDENCIES.items()
    }
    if missing_core or any(tab_hints.values()):
        st.warning("–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —á–∞—Å—Ç–∏ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π. –î–æ–±–∞–≤—å—Ç–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, —á—Ç–æ–±—ã —Ä–∞—Å–∫—Ä—ã—Ç—å –ø–æ–ª–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª.")
        if missing_core:
            st.markdown("**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä:**")
            st.markdown("\n".join(f"- {metric}" for metric in missing_core))
        actionable = [(tab, metrics) for tab, metrics in tab_hints.items() if metrics]
        if actionable:
            st.markdown("**–î–ª—è –≤–∫–ª–∞–¥–æ–∫:**")
            st.markdown("\n".join(f"- {tab}: {', '.join(metrics)}" for tab, metrics in actionable))

    metrics_sequence = KEY_DECISION_METRICS + SUPPORT_DECISION_METRICS
    stats_current = {
        metric: compute_metric_stats(ctx.df_current, ctx.regions, ctx.months_range, metric)
        for metric in metrics_sequence
    }
    stats_previous = None
    if ctx.mode == "compare" and ctx.df_previous is not None:
        stats_previous = {
            metric: compute_metric_stats(ctx.df_previous, ctx.regions, ctx.months_range, metric)
            for metric in metrics_sequence
        }

    if ctx.mode == "single":
        scenario_overview_block_single(
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.scenario_name,
            ctx.year_current,
            stats_map=stats_current,
        )
    else:
        scenario_overview_block_compare(
            ctx.df_previous,
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.scenario_name,
            ctx.year_previous,
            ctx.year_current,
            stats_current=stats_current,
            stats_previous=stats_previous,
        )

    render_executive_summary(ctx, stats_current, stats_previous)
    st.divider()
    title_suffix = f" ({ctx.year_current})" if ctx.mode == "compare" else ""
    st.markdown(f"### üîç –û—Å–Ω–æ–≤–Ω—ã–µ KPI{title_suffix}")
    kpi_block(ctx.df_current, ctx.regions, ctx.months_range, ctx.months_available, ctx.strict_mode)
    st.divider()
    st.markdown("### üåç –ö–∞—Ä—Ç–∏–Ω–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
    summary_block(ctx.agg_current, ctx.df_current, ctx.regions, ctx.months_range, ctx.months_available, ctx.strict_mode)
    st.divider()
    render_scenario_simulator(ctx)
    st.divider()
    render_margin_capacity_planner(ctx, widget_prefix="home_margin")
    st.divider()
    render_management_tools(ctx, stats_current, stats_previous)


def render_issuance_page(ctx: PageContext) -> None:
    suffix = "_cmp" if ctx.mode == "compare" else ""
    title = "### üöÄ –í—ã–¥–∞—á–∏ –∏ –ø–æ—Ä—Ç—Ñ–µ–ª—å"
    if ctx.mode == "compare":
        title += f" ({ctx.year_current})"
    st.markdown(title)
    render_tab_summary(ctx, TAB_METRIC_SETS["issuance"], title="#### üß≠ Executive summary ‚Äî –≤—ã–¥–∞—á–∏")
    st.divider()
    _render_metric_trend_section(
        "–î–∏–Ω–∞–º–∏–∫–∞ –≤—ã–¥–∞—á" if ctx.mode == "single" else "–î–∏–Ω–∞–º–∏–∫–∞ –≤—ã–¥–∞—á (–≥–æ–¥ B)",
        [
            Metrics.LOAN_ISSUE.value,
            Metrics.LOAN_ISSUE_UNITS.value,
            Metrics.AVG_LOAN.value
        ],
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        widget_key=f"issuance_trend{suffix}"
    )
    st.divider()
    leaderboard_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_available,
        default_metric=Metrics.LOAN_ISSUE.value,
        selection_key=f"issuance_leader_metric{suffix}",
        period_slider_key=f"issuance_period{suffix}"
    )
    st.divider()
    comparison_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_available,
        default_metric=Metrics.LOAN_ISSUE.value,
        selection_key=f"issuance_comparison_metric{suffix}",
        period_a_key=f"issuance_period_a{suffix}",
        period_b_key=f"issuance_period_b{suffix}"
    )
    st.divider()
    if ctx.mode == "compare":
        dynamics_compare_block(
            ctx.df_previous,
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            year_a=ctx.year_previous,
            year_b=ctx.year_current,
            default_metrics=[Metrics.LOAN_ISSUE.value, Metrics.LOAN_ISSUE_UNITS.value],
            widget_prefix="issuance_dyn_cmp"
        )
    else:
        dynamics_block(
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            default_metrics=[Metrics.LOAN_ISSUE.value, Metrics.LOAN_ISSUE_UNITS.value, Metrics.AVG_LOAN.value],
            widget_prefix="issuance_dyn"
        )


def render_interest_page(ctx: PageContext) -> None:
    suffix = "_cmp" if ctx.mode == "compare" else ""
    title = "### üí∞ –ü—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –ø–æ–≥–∞—à–µ–Ω–∏—è"
    if ctx.mode == "compare":
        title += f" ({ctx.year_current})"
    st.markdown(title)
    render_tab_summary(ctx, TAB_METRIC_SETS["interest"], title="#### üß≠ Executive summary ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç—ã")
    st.divider()
    _render_metric_trend_section(
        "–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π" if ctx.mode == "single" else "–ü—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –ø–æ–≥–∞—à–µ–Ω–∏—è (–≥–æ–¥ B)",
        [
            Metrics.PENALTIES_RECEIVED.value,
            Metrics.YIELD.value,
            Metrics.LOAN_REPAYMENT_SUM.value
        ],
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        widget_key=f"interest_trend{suffix}"
    )
    st.divider()
    leaderboard_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_available,
        default_metric=Metrics.PENALTIES_RECEIVED.value,
        selection_key=f"interest_leader_metric{suffix}",
        period_slider_key=f"interest_period{suffix}"
    )
    st.divider()
    comparison_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_available,
        default_metric=Metrics.PENALTIES_RECEIVED.value,
        selection_key=f"interest_comparison_metric{suffix}",
        period_a_key=f"interest_period_a{suffix}",
        period_b_key=f"interest_period_b{suffix}"
    )
    st.divider()
    if ctx.mode == "compare":
        dynamics_compare_block(
            ctx.df_previous,
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            year_a=ctx.year_previous,
            year_b=ctx.year_current,
            default_metrics=[Metrics.PENALTIES_RECEIVED.value, Metrics.YIELD.value, Metrics.LOAN_REPAYMENT_SUM.value],
            widget_prefix="interest_dyn_cmp"
        )
    else:
        dynamics_block(
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            default_metrics=[Metrics.PENALTIES_RECEIVED.value, Metrics.YIELD.value, Metrics.LOAN_REPAYMENT_SUM.value],
            widget_prefix="interest_dyn"
        )


def render_sales_page(ctx: PageContext) -> None:
    suffix = "_cmp" if ctx.mode == "compare" else ""
    title = "### üõçÔ∏è –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –∏ –º–∞—Ä–∂–∞"
    if ctx.mode == "compare":
        title = "### üõçÔ∏è –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞" + f" ({ctx.year_current})"
    st.markdown(title)
    render_tab_summary(ctx, TAB_METRIC_SETS["sales"], title="#### üß≠ Executive summary ‚Äî —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞")
    st.divider()
    _render_metric_trend_section(
        "–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂" if ctx.mode == "single" else "–ü—Ä–æ–¥–∞–∂–∏ –∏ –º–∞—Ä–∂–∞ (–≥–æ–¥ B)",
        [
            Metrics.REVENUE.value,
            Metrics.MARKUP_PCT.value,
            Metrics.PENALTIES_PLUS_MARKUP.value
        ],
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        widget_key=f"sales_trend{suffix}"
    )
    st.divider()
    treemap_heatmap_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        ctx.color_map,
        default_metric=Metrics.REVENUE.value,
        metric_key=f"sales_treemap_metric{suffix}",
        month_key=f"sales_treemap_month{suffix}",
        mode_key=f"sales_treemap_mode{suffix}",
        heat_metric_key=f"sales_heat_metric{suffix}"
    )
    st.divider()
    render_revenue_waterfall(ctx)
    st.divider()
    sales_intelligence_block(ctx, ctx.thresholds)
    st.divider()
    render_margin_capacity_planner(ctx, widget_prefix="sales_margin")
    st.divider()
    if ctx.mode == "compare":
        dynamics_compare_block(
            ctx.df_previous,
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            year_a=ctx.year_previous,
            year_b=ctx.year_current,
            default_metrics=[Metrics.REVENUE.value, Metrics.MARKUP_PCT.value, Metrics.PENALTIES_PLUS_MARKUP.value],
            widget_prefix="sales_dyn_cmp"
        )
    else:
        dynamics_block(
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            default_metrics=[Metrics.REVENUE.value, Metrics.MARKUP_PCT.value, Metrics.PENALTIES_PLUS_MARKUP.value],
            widget_prefix="sales_dyn"
        )


def render_risk_page(ctx: PageContext) -> None:
    suffix = "_cmp" if ctx.mode == "compare" else ""
    title = "### ‚ö†Ô∏è –†–∏—Å–∫–∏ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å" if ctx.mode == "single" else "### ‚ö†Ô∏è –†–∏—Å–∫–∏ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–¥–æ–≤)"
    st.markdown(title)
    st.caption("–ö–ª—é—á–µ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä ‚Äî ¬´–î–æ–ª—è –Ω–∏–∂–µ –∑–∞–π–º–∞, %¬ª: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è —á–∞—Å—Ç—å –≤—ã—Ä—É—á–∫–∏ –æ—Ç —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏ –ø–æ–ª—É—á–µ–Ω–∞ –ø–æ —Ç–æ–≤–∞—Ä–∞–º, –ø—Ä–æ–¥–∞–Ω–Ω—ã–º –¥–µ—à–µ–≤–ª–µ —Å—É–º–º—ã –∑–∞–π–º–∞. –†–æ—Å—Ç –æ–∑–Ω–∞—á–∞–µ—Ç —É—Å–∏–ª–µ–Ω–∏–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂.")
    render_tab_summary(ctx, TAB_METRIC_SETS["risk"], title="#### üß≠ Executive summary ‚Äî —Ä–∏—Å–∫–∏")
    st.divider()
    alert_config = risk_alerts_block(ctx)
    st.divider()
    _render_metric_trend_section(
        "–î–∏–Ω–∞–º–∏–∫–∞ —Ä–∏—Å–∫–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π" if ctx.mode == "single" else "–î–∏–Ω–∞–º–∏–∫–∞ —Ä–∏—Å–∫–æ–≤ (–≥–æ–¥ B)",
        [
            Metrics.RISK_SHARE.value,
            Metrics.ILLIQUID_BY_VALUE_PCT.value,
            Metrics.PLAN_ISSUE_PCT.value
        ],
        ctx.df_current,
        ctx.regions,
        ctx.months_range,
        widget_key=f"risk_trend{suffix}"
    )
    st.divider()
    leaderboard_block(
        ctx.df_current,
        ctx.regions,
        ctx.months_available,
        default_metric=Metrics.RISK_SHARE.value,
        selection_key=f"risk_leader_metric{suffix}",
        period_slider_key=f"risk_period{suffix}"
    )
    st.divider()
    risk_markup_heatmap_block(ctx)
    st.divider()
    render_risk_dependency(ctx)
    st.divider()
    risk_failure_forecast_block(ctx, alert_config.get("risk_threshold") if alert_config else None)
    st.divider()
    if ctx.mode == "compare":
        dynamics_compare_block(
            ctx.df_previous,
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            year_a=ctx.year_previous,
            year_b=ctx.year_current,
            default_metrics=[Metrics.RISK_SHARE.value, Metrics.ILLIQUID_BY_VALUE_PCT.value, Metrics.PLAN_REVENUE_PCT.value],
            widget_prefix="risk_dyn_cmp"
        )
    else:
        dynamics_block(
            ctx.df_current,
            ctx.regions,
            ctx.months_range,
            ctx.color_map,
            default_metrics=[Metrics.RISK_SHARE.value, Metrics.ILLIQUID_BY_VALUE_PCT.value, Metrics.PLAN_ISSUE_PCT.value],
            widget_prefix="risk_dyn"
        )


def render_data_page(ctx: PageContext) -> None:
    title = "### üìÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –¥–∞–Ω–Ω—ã–µ" if ctx.mode == "single" else "### üìÖ –í–∞–ª–∏–¥–∞—Ü–∏—è (–≥–æ–¥ B)"
    st.markdown(title)
    render_health_check(ctx)
    st.divider()
    month_check_block(ctx.df_current, ctx.regions, ctx.months_range, ctx.months_available)
    st.divider()
    render_correlation_block(ctx.df_current, ctx.regions, ctx.months_range, default_metrics=FORECAST_METRICS)
    st.divider()
    if ctx.mode == "compare" and ctx.df_previous is not None:
        export_source = pd.concat([ctx.df_previous, ctx.df_current], ignore_index=True)
    else:
        export_source = ctx.df_current
    export_filtered = export_source[
        (export_source["–†–µ–≥–∏–æ–Ω"].isin(ctx.regions))
        & (export_source["–ú–µ—Å—è—Ü"].astype(str).isin(ctx.months_range))
    ]
    export_block(export_filtered)
    info_block()
    render_faq_block()


def render_ai_page(ctx: PageContext) -> None:
    if ctx.mode == "single":
        ai_analysis_block_single_year(ctx.df_current, ctx.regions, ctx.months_range, ctx.year_current)
    else:
        ai_analysis_block_comparison(ctx.df_previous, ctx.df_current, ctx.regions, ctx.months_range, ctx.year_previous, ctx.year_current)


if __name__ == "__main__":
    main()
